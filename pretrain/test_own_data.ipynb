{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import List\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import dist\n",
    "import encoder\n",
    "from decoder import LightDecoder\n",
    "from models import build_sparse_encoder\n",
    "from sampler import DistInfiniteBatchSampler, worker_init_fn\n",
    "from spark import SparK\n",
    "from utils import arg_util, misc, lamb\n",
    "from utils.imagenet import build_imagenet_pretrain\n",
    "from utils.lr_control import lr_wd_annealing, get_param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/chong.tian/hc701/HC701-PROJECT')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from hc701fed.dataset.EyePACS_and_APTOS import Eye_APTOS\n",
    "from hc701fed.dataset.messidor import MESSIDOR\n",
    "\n",
    "from hc701fed.transform.transforms import compose\n",
    "from hc701fed.dataset.messidor import MESSIDOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_flip {'p': 0.5}\n",
      "random_rotation {'degrees': [-10, 10]}\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = '/home/chong.tian/hc701'\n",
    "\n",
    "transforms_file = open(os.path.join(PATH_DATA, \"HC701-PROJECT/hc701fed/params/transforms.yaml\"), \"r\")\n",
    "transforms_params = yaml.load(transforms_file, Loader=yaml.FullLoader)\n",
    "train_transforms = compose(\n",
    "    transforms_strs=transforms_params[\"train\"],\n",
    ")\n",
    "\n",
    "Eye_APTOS_data_dir_options = {\n",
    "    'EyePACS': os.path.join(PATH_DATA, 'preprocessed/eyepacs'),\n",
    "    'APTOS': os.path.join(PATH_DATA, 'preprocessed/aptos'),\n",
    "}\n",
    "\n",
    "MESSIDOR_data_dir_options = {\n",
    "    'messidor2': os.path.join(PATH_DATA, 'preprocessed/messidor2'),\n",
    "    'messidor_pairs' : os.path.join(PATH_DATA, 'preprocessed/messidor/messidor_pairs'),\n",
    "    'messidor_Etienne' : os.path.join(PATH_DATA, 'preprocessed/messidor/messidor_Etienne'),\n",
    "    'messidor_Brest-without_dilation' : os.path.join(PATH_DATA, 'preprocessed/messidor/messidor_Brest-without_dilation')\n",
    "}\n",
    "\n",
    "APTOS_train = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['APTOS'], mode='train', transform_=train_transforms)\n",
    "EyePACS_train = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['EyePACS'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_2_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor2'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_pairs_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_Etienne_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_Brest_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], mode='train', transform_=train_transforms)\n",
    "\n",
    "APTOS_Val = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['APTOS'], mode='val', transform_=None)\n",
    "EyePACS_Val = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['EyePACS'], mode='val', transform_=None)\n",
    "MESSIDOR_2_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor2'], mode='val', transform_=None)\n",
    "MESSIDOR_pairs_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], mode='val', transform_=None)\n",
    "MESSIDOR_Etienne_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], mode='val', transform_=None)\n",
    "MESSIDOR_Brest_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], mode='val', transform_=None)\n",
    "\n",
    "train_datasets = ConcatDataset([APTOS_train, EyePACS_train, MESSIDOR_2_train, MESSIDOR_pairs_train, MESSIDOR_Etienne_train, MESSIDOR_Brest_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "data_loader_train = DataLoader(dataset=train_datasets, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "itrt_train, iters_train = iter(data_loader_train), len(data_loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[build_sparse_encoder] model kwargs={'drop_path_rate': 0.05, 'pretrained': False, 'num_classes': 0, 'global_pool': ''}\n"
     ]
    }
   ],
   "source": [
    "enc: encoder.SparseEncoder = build_sparse_encoder('resnet50', input_size=224, sbn=True, drop_path_rate=0.0, verbose=False)\n",
    "dec = LightDecoder(enc.downsample_raito, sbn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparK.__init__, densify 1/4]: densify_proj(ksz=1, #para=1.57M)\n",
      "[SparK.__init__, densify 2/4]: densify_proj(ksz=3, #para=3.54M)\n",
      "[SparK.__init__, densify 3/4]: densify_proj(ksz=3, #para=0.88M)\n",
      "[SparK.__init__, densify 4/4]: densify_proj(ksz=3, #para=0.22M)\n",
      "[SparK.__init__] dims of mask_tokens=(2048, 1024, 512, 256)\n"
     ]
    }
   ],
   "source": [
    "model_without_ddp = SparK(\n",
    "        sparse_encoder=enc, dense_decoder=dec, mask_ratio=0.6,\n",
    "        densify_norm='', sbn=True, hierarchy=4,\n",
    "    )\n",
    "\n",
    "model_without_ddp = model_without_ddp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['imn_m', 'imn_s', 'norm_black', 'sparse_encoder.sp_cnn.conv1.weight', 'sparse_encoder.sp_cnn.bn1.weight', 'sparse_encoder.sp_cnn.bn1.bias', 'sparse_encoder.sp_cnn.bn1.running_mean', 'sparse_encoder.sp_cnn.bn1.running_var', 'sparse_encoder.sp_cnn.layer1.0.conv1.weight', 'sparse_encoder.sp_cnn.layer1.0.bn1.weight', 'sparse_encoder.sp_cnn.layer1.0.bn1.bias', 'sparse_encoder.sp_cnn.layer1.0.bn1.running_mean', 'sparse_encoder.sp_cnn.layer1.0.bn1.running_var', 'sparse_encoder.sp_cnn.layer1.0.conv2.weight', 'sparse_encoder.sp_cnn.layer1.0.bn2.weight', 'sparse_encoder.sp_cnn.layer1.0.bn2.bias', 'sparse_encoder.sp_cnn.layer1.0.bn2.running_mean', 'sparse_encoder.sp_cnn.layer1.0.bn2.running_var', 'sparse_encoder.sp_cnn.layer1.0.conv3.weight', 'sparse_encoder.sp_cnn.layer1.0.bn3.weight', 'sparse_encoder.sp_cnn.layer1.0.bn3.bias', 'sparse_encoder.sp_cnn.layer1.0.bn3.running_mean', 'sparse_encoder.sp_cnn.layer1.0.bn3.running_var', 'sparse_encoder.sp_cnn.layer1.0.downsample.0.weight', 'sparse_encoder.sp_cnn.layer1.0.downsample.1.weight', 'sparse_encoder.sp_cnn.layer1.0.downsample.1.bias', 'sparse_encoder.sp_cnn.layer1.0.downsample.1.running_mean', 'sparse_encoder.sp_cnn.layer1.0.downsample.1.running_var', 'sparse_encoder.sp_cnn.layer1.1.conv1.weight', 'sparse_encoder.sp_cnn.layer1.1.bn1.weight', 'sparse_encoder.sp_cnn.layer1.1.bn1.bias', 'sparse_encoder.sp_cnn.layer1.1.bn1.running_mean', 'sparse_encoder.sp_cnn.layer1.1.bn1.running_var', 'sparse_encoder.sp_cnn.layer1.1.conv2.weight', 'sparse_encoder.sp_cnn.layer1.1.bn2.weight', 'sparse_encoder.sp_cnn.layer1.1.bn2.bias', 'sparse_encoder.sp_cnn.layer1.1.bn2.running_mean', 'sparse_encoder.sp_cnn.layer1.1.bn2.running_var', 'sparse_encoder.sp_cnn.layer1.1.conv3.weight', 'sparse_encoder.sp_cnn.layer1.1.bn3.weight', 'sparse_encoder.sp_cnn.layer1.1.bn3.bias', 'sparse_encoder.sp_cnn.layer1.1.bn3.running_mean', 'sparse_encoder.sp_cnn.layer1.1.bn3.running_var', 'sparse_encoder.sp_cnn.layer1.2.conv1.weight', 'sparse_encoder.sp_cnn.layer1.2.bn1.weight', 'sparse_encoder.sp_cnn.layer1.2.bn1.bias', 'sparse_encoder.sp_cnn.layer1.2.bn1.running_mean', 'sparse_encoder.sp_cnn.layer1.2.bn1.running_var', 'sparse_encoder.sp_cnn.layer1.2.conv2.weight', 'sparse_encoder.sp_cnn.layer1.2.bn2.weight', 'sparse_encoder.sp_cnn.layer1.2.bn2.bias', 'sparse_encoder.sp_cnn.layer1.2.bn2.running_mean', 'sparse_encoder.sp_cnn.layer1.2.bn2.running_var', 'sparse_encoder.sp_cnn.layer1.2.conv3.weight', 'sparse_encoder.sp_cnn.layer1.2.bn3.weight', 'sparse_encoder.sp_cnn.layer1.2.bn3.bias', 'sparse_encoder.sp_cnn.layer1.2.bn3.running_mean', 'sparse_encoder.sp_cnn.layer1.2.bn3.running_var', 'sparse_encoder.sp_cnn.layer2.0.conv1.weight', 'sparse_encoder.sp_cnn.layer2.0.bn1.weight', 'sparse_encoder.sp_cnn.layer2.0.bn1.bias', 'sparse_encoder.sp_cnn.layer2.0.bn1.running_mean', 'sparse_encoder.sp_cnn.layer2.0.bn1.running_var', 'sparse_encoder.sp_cnn.layer2.0.conv2.weight', 'sparse_encoder.sp_cnn.layer2.0.bn2.weight', 'sparse_encoder.sp_cnn.layer2.0.bn2.bias', 'sparse_encoder.sp_cnn.layer2.0.bn2.running_mean', 'sparse_encoder.sp_cnn.layer2.0.bn2.running_var', 'sparse_encoder.sp_cnn.layer2.0.conv3.weight', 'sparse_encoder.sp_cnn.layer2.0.bn3.weight', 'sparse_encoder.sp_cnn.layer2.0.bn3.bias', 'sparse_encoder.sp_cnn.layer2.0.bn3.running_mean', 'sparse_encoder.sp_cnn.layer2.0.bn3.running_var', 'sparse_encoder.sp_cnn.layer2.0.downsample.0.weight', 'sparse_encoder.sp_cnn.layer2.0.downsample.1.weight', 'sparse_encoder.sp_cnn.layer2.0.downsample.1.bias', 'sparse_encoder.sp_cnn.layer2.0.downsample.1.running_mean', 'sparse_encoder.sp_cnn.layer2.0.downsample.1.running_var', 'sparse_encoder.sp_cnn.layer2.1.conv1.weight', 'sparse_encoder.sp_cnn.layer2.1.bn1.weight', 'sparse_encoder.sp_cnn.layer2.1.bn1.bias', 'sparse_encoder.sp_cnn.layer2.1.bn1.running_mean', 'sparse_encoder.sp_cnn.layer2.1.bn1.running_var', 'sparse_encoder.sp_cnn.layer2.1.conv2.weight', 'sparse_encoder.sp_cnn.layer2.1.bn2.weight', 'sparse_encoder.sp_cnn.layer2.1.bn2.bias', 'sparse_encoder.sp_cnn.layer2.1.bn2.running_mean', 'sparse_encoder.sp_cnn.layer2.1.bn2.running_var', 'sparse_encoder.sp_cnn.layer2.1.conv3.weight', 'sparse_encoder.sp_cnn.layer2.1.bn3.weight', 'sparse_encoder.sp_cnn.layer2.1.bn3.bias', 'sparse_encoder.sp_cnn.layer2.1.bn3.running_mean', 'sparse_encoder.sp_cnn.layer2.1.bn3.running_var', 'sparse_encoder.sp_cnn.layer2.2.conv1.weight', 'sparse_encoder.sp_cnn.layer2.2.bn1.weight', 'sparse_encoder.sp_cnn.layer2.2.bn1.bias', 'sparse_encoder.sp_cnn.layer2.2.bn1.running_mean', 'sparse_encoder.sp_cnn.layer2.2.bn1.running_var', 'sparse_encoder.sp_cnn.layer2.2.conv2.weight', 'sparse_encoder.sp_cnn.layer2.2.bn2.weight', 'sparse_encoder.sp_cnn.layer2.2.bn2.bias', 'sparse_encoder.sp_cnn.layer2.2.bn2.running_mean', 'sparse_encoder.sp_cnn.layer2.2.bn2.running_var', 'sparse_encoder.sp_cnn.layer2.2.conv3.weight', 'sparse_encoder.sp_cnn.layer2.2.bn3.weight', 'sparse_encoder.sp_cnn.layer2.2.bn3.bias', 'sparse_encoder.sp_cnn.layer2.2.bn3.running_mean', 'sparse_encoder.sp_cnn.layer2.2.bn3.running_var', 'sparse_encoder.sp_cnn.layer2.3.conv1.weight', 'sparse_encoder.sp_cnn.layer2.3.bn1.weight', 'sparse_encoder.sp_cnn.layer2.3.bn1.bias', 'sparse_encoder.sp_cnn.layer2.3.bn1.running_mean', 'sparse_encoder.sp_cnn.layer2.3.bn1.running_var', 'sparse_encoder.sp_cnn.layer2.3.conv2.weight', 'sparse_encoder.sp_cnn.layer2.3.bn2.weight', 'sparse_encoder.sp_cnn.layer2.3.bn2.bias', 'sparse_encoder.sp_cnn.layer2.3.bn2.running_mean', 'sparse_encoder.sp_cnn.layer2.3.bn2.running_var', 'sparse_encoder.sp_cnn.layer2.3.conv3.weight', 'sparse_encoder.sp_cnn.layer2.3.bn3.weight', 'sparse_encoder.sp_cnn.layer2.3.bn3.bias', 'sparse_encoder.sp_cnn.layer2.3.bn3.running_mean', 'sparse_encoder.sp_cnn.layer2.3.bn3.running_var', 'sparse_encoder.sp_cnn.layer3.0.conv1.weight', 'sparse_encoder.sp_cnn.layer3.0.bn1.weight', 'sparse_encoder.sp_cnn.layer3.0.bn1.bias', 'sparse_encoder.sp_cnn.layer3.0.bn1.running_mean', 'sparse_encoder.sp_cnn.layer3.0.bn1.running_var', 'sparse_encoder.sp_cnn.layer3.0.conv2.weight', 'sparse_encoder.sp_cnn.layer3.0.bn2.weight', 'sparse_encoder.sp_cnn.layer3.0.bn2.bias', 'sparse_encoder.sp_cnn.layer3.0.bn2.running_mean', 'sparse_encoder.sp_cnn.layer3.0.bn2.running_var', 'sparse_encoder.sp_cnn.layer3.0.conv3.weight', 'sparse_encoder.sp_cnn.layer3.0.bn3.weight', 'sparse_encoder.sp_cnn.layer3.0.bn3.bias', 'sparse_encoder.sp_cnn.layer3.0.bn3.running_mean', 'sparse_encoder.sp_cnn.layer3.0.bn3.running_var', 'sparse_encoder.sp_cnn.layer3.0.downsample.0.weight', 'sparse_encoder.sp_cnn.layer3.0.downsample.1.weight', 'sparse_encoder.sp_cnn.layer3.0.downsample.1.bias', 'sparse_encoder.sp_cnn.layer3.0.downsample.1.running_mean', 'sparse_encoder.sp_cnn.layer3.0.downsample.1.running_var', 'sparse_encoder.sp_cnn.layer3.1.conv1.weight', 'sparse_encoder.sp_cnn.layer3.1.bn1.weight', 'sparse_encoder.sp_cnn.layer3.1.bn1.bias', 'sparse_encoder.sp_cnn.layer3.1.bn1.running_mean', 'sparse_encoder.sp_cnn.layer3.1.bn1.running_var', 'sparse_encoder.sp_cnn.layer3.1.conv2.weight', 'sparse_encoder.sp_cnn.layer3.1.bn2.weight', 'sparse_encoder.sp_cnn.layer3.1.bn2.bias', 'sparse_encoder.sp_cnn.layer3.1.bn2.running_mean', 'sparse_encoder.sp_cnn.layer3.1.bn2.running_var', 'sparse_encoder.sp_cnn.layer3.1.conv3.weight', 'sparse_encoder.sp_cnn.layer3.1.bn3.weight', 'sparse_encoder.sp_cnn.layer3.1.bn3.bias', 'sparse_encoder.sp_cnn.layer3.1.bn3.running_mean', 'sparse_encoder.sp_cnn.layer3.1.bn3.running_var', 'sparse_encoder.sp_cnn.layer3.2.conv1.weight', 'sparse_encoder.sp_cnn.layer3.2.bn1.weight', 'sparse_encoder.sp_cnn.layer3.2.bn1.bias', 'sparse_encoder.sp_cnn.layer3.2.bn1.running_mean', 'sparse_encoder.sp_cnn.layer3.2.bn1.running_var', 'sparse_encoder.sp_cnn.layer3.2.conv2.weight', 'sparse_encoder.sp_cnn.layer3.2.bn2.weight', 'sparse_encoder.sp_cnn.layer3.2.bn2.bias', 'sparse_encoder.sp_cnn.layer3.2.bn2.running_mean', 'sparse_encoder.sp_cnn.layer3.2.bn2.running_var', 'sparse_encoder.sp_cnn.layer3.2.conv3.weight', 'sparse_encoder.sp_cnn.layer3.2.bn3.weight', 'sparse_encoder.sp_cnn.layer3.2.bn3.bias', 'sparse_encoder.sp_cnn.layer3.2.bn3.running_mean', 'sparse_encoder.sp_cnn.layer3.2.bn3.running_var', 'sparse_encoder.sp_cnn.layer3.3.conv1.weight', 'sparse_encoder.sp_cnn.layer3.3.bn1.weight', 'sparse_encoder.sp_cnn.layer3.3.bn1.bias', 'sparse_encoder.sp_cnn.layer3.3.bn1.running_mean', 'sparse_encoder.sp_cnn.layer3.3.bn1.running_var', 'sparse_encoder.sp_cnn.layer3.3.conv2.weight', 'sparse_encoder.sp_cnn.layer3.3.bn2.weight', 'sparse_encoder.sp_cnn.layer3.3.bn2.bias', 'sparse_encoder.sp_cnn.layer3.3.bn2.running_mean', 'sparse_encoder.sp_cnn.layer3.3.bn2.running_var', 'sparse_encoder.sp_cnn.layer3.3.conv3.weight', 'sparse_encoder.sp_cnn.layer3.3.bn3.weight', 'sparse_encoder.sp_cnn.layer3.3.bn3.bias', 'sparse_encoder.sp_cnn.layer3.3.bn3.running_mean', 'sparse_encoder.sp_cnn.layer3.3.bn3.running_var', 'sparse_encoder.sp_cnn.layer3.4.conv1.weight', 'sparse_encoder.sp_cnn.layer3.4.bn1.weight', 'sparse_encoder.sp_cnn.layer3.4.bn1.bias', 'sparse_encoder.sp_cnn.layer3.4.bn1.running_mean', 'sparse_encoder.sp_cnn.layer3.4.bn1.running_var', 'sparse_encoder.sp_cnn.layer3.4.conv2.weight', 'sparse_encoder.sp_cnn.layer3.4.bn2.weight', 'sparse_encoder.sp_cnn.layer3.4.bn2.bias', 'sparse_encoder.sp_cnn.layer3.4.bn2.running_mean', 'sparse_encoder.sp_cnn.layer3.4.bn2.running_var', 'sparse_encoder.sp_cnn.layer3.4.conv3.weight', 'sparse_encoder.sp_cnn.layer3.4.bn3.weight', 'sparse_encoder.sp_cnn.layer3.4.bn3.bias', 'sparse_encoder.sp_cnn.layer3.4.bn3.running_mean', 'sparse_encoder.sp_cnn.layer3.4.bn3.running_var', 'sparse_encoder.sp_cnn.layer3.5.conv1.weight', 'sparse_encoder.sp_cnn.layer3.5.bn1.weight', 'sparse_encoder.sp_cnn.layer3.5.bn1.bias', 'sparse_encoder.sp_cnn.layer3.5.bn1.running_mean', 'sparse_encoder.sp_cnn.layer3.5.bn1.running_var', 'sparse_encoder.sp_cnn.layer3.5.conv2.weight', 'sparse_encoder.sp_cnn.layer3.5.bn2.weight', 'sparse_encoder.sp_cnn.layer3.5.bn2.bias', 'sparse_encoder.sp_cnn.layer3.5.bn2.running_mean', 'sparse_encoder.sp_cnn.layer3.5.bn2.running_var', 'sparse_encoder.sp_cnn.layer3.5.conv3.weight', 'sparse_encoder.sp_cnn.layer3.5.bn3.weight', 'sparse_encoder.sp_cnn.layer3.5.bn3.bias', 'sparse_encoder.sp_cnn.layer3.5.bn3.running_mean', 'sparse_encoder.sp_cnn.layer3.5.bn3.running_var', 'sparse_encoder.sp_cnn.layer4.0.conv1.weight', 'sparse_encoder.sp_cnn.layer4.0.bn1.weight', 'sparse_encoder.sp_cnn.layer4.0.bn1.bias', 'sparse_encoder.sp_cnn.layer4.0.bn1.running_mean', 'sparse_encoder.sp_cnn.layer4.0.bn1.running_var', 'sparse_encoder.sp_cnn.layer4.0.conv2.weight', 'sparse_encoder.sp_cnn.layer4.0.bn2.weight', 'sparse_encoder.sp_cnn.layer4.0.bn2.bias', 'sparse_encoder.sp_cnn.layer4.0.bn2.running_mean', 'sparse_encoder.sp_cnn.layer4.0.bn2.running_var', 'sparse_encoder.sp_cnn.layer4.0.conv3.weight', 'sparse_encoder.sp_cnn.layer4.0.bn3.weight', 'sparse_encoder.sp_cnn.layer4.0.bn3.bias', 'sparse_encoder.sp_cnn.layer4.0.bn3.running_mean', 'sparse_encoder.sp_cnn.layer4.0.bn3.running_var', 'sparse_encoder.sp_cnn.layer4.0.downsample.0.weight', 'sparse_encoder.sp_cnn.layer4.0.downsample.1.weight', 'sparse_encoder.sp_cnn.layer4.0.downsample.1.bias', 'sparse_encoder.sp_cnn.layer4.0.downsample.1.running_mean', 'sparse_encoder.sp_cnn.layer4.0.downsample.1.running_var', 'sparse_encoder.sp_cnn.layer4.1.conv1.weight', 'sparse_encoder.sp_cnn.layer4.1.bn1.weight', 'sparse_encoder.sp_cnn.layer4.1.bn1.bias', 'sparse_encoder.sp_cnn.layer4.1.bn1.running_mean', 'sparse_encoder.sp_cnn.layer4.1.bn1.running_var', 'sparse_encoder.sp_cnn.layer4.1.conv2.weight', 'sparse_encoder.sp_cnn.layer4.1.bn2.weight', 'sparse_encoder.sp_cnn.layer4.1.bn2.bias', 'sparse_encoder.sp_cnn.layer4.1.bn2.running_mean', 'sparse_encoder.sp_cnn.layer4.1.bn2.running_var', 'sparse_encoder.sp_cnn.layer4.1.conv3.weight', 'sparse_encoder.sp_cnn.layer4.1.bn3.weight', 'sparse_encoder.sp_cnn.layer4.1.bn3.bias', 'sparse_encoder.sp_cnn.layer4.1.bn3.running_mean', 'sparse_encoder.sp_cnn.layer4.1.bn3.running_var', 'sparse_encoder.sp_cnn.layer4.2.conv1.weight', 'sparse_encoder.sp_cnn.layer4.2.bn1.weight', 'sparse_encoder.sp_cnn.layer4.2.bn1.bias', 'sparse_encoder.sp_cnn.layer4.2.bn1.running_mean', 'sparse_encoder.sp_cnn.layer4.2.bn1.running_var', 'sparse_encoder.sp_cnn.layer4.2.conv2.weight', 'sparse_encoder.sp_cnn.layer4.2.bn2.weight', 'sparse_encoder.sp_cnn.layer4.2.bn2.bias', 'sparse_encoder.sp_cnn.layer4.2.bn2.running_mean', 'sparse_encoder.sp_cnn.layer4.2.bn2.running_var', 'sparse_encoder.sp_cnn.layer4.2.conv3.weight', 'sparse_encoder.sp_cnn.layer4.2.bn3.weight', 'sparse_encoder.sp_cnn.layer4.2.bn3.bias', 'sparse_encoder.sp_cnn.layer4.2.bn3.running_mean', 'sparse_encoder.sp_cnn.layer4.2.bn3.running_var', 'dense_decoder.dec.0.up_sample.weight', 'dense_decoder.dec.0.up_sample.bias', 'dense_decoder.dec.0.conv.0.weight', 'dense_decoder.dec.0.conv.1.weight', 'dense_decoder.dec.0.conv.1.bias', 'dense_decoder.dec.0.conv.1.running_mean', 'dense_decoder.dec.0.conv.1.running_var', 'dense_decoder.dec.0.conv.3.weight', 'dense_decoder.dec.0.conv.4.weight', 'dense_decoder.dec.0.conv.4.bias', 'dense_decoder.dec.0.conv.4.running_mean', 'dense_decoder.dec.0.conv.4.running_var', 'dense_decoder.dec.1.up_sample.weight', 'dense_decoder.dec.1.up_sample.bias', 'dense_decoder.dec.1.conv.0.weight', 'dense_decoder.dec.1.conv.1.weight', 'dense_decoder.dec.1.conv.1.bias', 'dense_decoder.dec.1.conv.1.running_mean', 'dense_decoder.dec.1.conv.1.running_var', 'dense_decoder.dec.1.conv.3.weight', 'dense_decoder.dec.1.conv.4.weight', 'dense_decoder.dec.1.conv.4.bias', 'dense_decoder.dec.1.conv.4.running_mean', 'dense_decoder.dec.1.conv.4.running_var', 'dense_decoder.dec.2.up_sample.weight', 'dense_decoder.dec.2.up_sample.bias', 'dense_decoder.dec.2.conv.0.weight', 'dense_decoder.dec.2.conv.1.weight', 'dense_decoder.dec.2.conv.1.bias', 'dense_decoder.dec.2.conv.1.running_mean', 'dense_decoder.dec.2.conv.1.running_var', 'dense_decoder.dec.2.conv.3.weight', 'dense_decoder.dec.2.conv.4.weight', 'dense_decoder.dec.2.conv.4.bias', 'dense_decoder.dec.2.conv.4.running_mean', 'dense_decoder.dec.2.conv.4.running_var', 'dense_decoder.dec.3.up_sample.weight', 'dense_decoder.dec.3.up_sample.bias', 'dense_decoder.dec.3.conv.0.weight', 'dense_decoder.dec.3.conv.1.weight', 'dense_decoder.dec.3.conv.1.bias', 'dense_decoder.dec.3.conv.1.running_mean', 'dense_decoder.dec.3.conv.1.running_var', 'dense_decoder.dec.3.conv.3.weight', 'dense_decoder.dec.3.conv.4.weight', 'dense_decoder.dec.3.conv.4.bias', 'dense_decoder.dec.3.conv.4.running_mean', 'dense_decoder.dec.3.conv.4.running_var', 'dense_decoder.dec.4.up_sample.weight', 'dense_decoder.dec.4.up_sample.bias', 'dense_decoder.dec.4.conv.0.weight', 'dense_decoder.dec.4.conv.1.weight', 'dense_decoder.dec.4.conv.1.bias', 'dense_decoder.dec.4.conv.1.running_mean', 'dense_decoder.dec.4.conv.1.running_var', 'dense_decoder.dec.4.conv.3.weight', 'dense_decoder.dec.4.conv.4.weight', 'dense_decoder.dec.4.conv.4.bias', 'dense_decoder.dec.4.conv.4.running_mean', 'dense_decoder.dec.4.conv.4.running_var', 'dense_decoder.proj.weight', 'dense_decoder.proj.bias', 'densify_projs.0.weight', 'densify_projs.0.bias', 'densify_projs.1.weight', 'densify_projs.1.bias', 'densify_projs.2.weight', 'densify_projs.2.bias', 'densify_projs.3.weight', 'densify_projs.3.bias', 'mask_tokens.0', 'mask_tokens.1', 'mask_tokens.2', 'mask_tokens.3'], unexpected_keys=['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_without_ddp.load_state_dict(torch.load('/home/chong.tian/hc701/checkpoint_pre_train/still_pre_train/resnet50_1kpretrained_timm_style.pth'),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_ft_param_groups] param groups = \n",
      "{ 'decay': { 'lr_scale': 1.0,\n",
      "             'params': \"('sparse_encoder.sp_cnn.conv1.weight, sparse_encoder.sp_cnn.layer1.0.conv1.weight, sparse_encoder.sp_cnn.layer1.0.conv2.weight, sparse_encoder.sp_cnn.layer1.0.conv3.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer1.0.downsample.0.weight, sparse_encoder.sp_cnn.layer1.1.conv1.weight, sparse_encoder.sp_cnn.layer1.1.conv2.weight, sparse_encoder.sp_cnn.layer1.1.conv3.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer1.2.conv1.weight, sparse_encoder.sp_cnn.layer1.2.conv2.weight, sparse_encoder.sp_cnn.layer1.2.conv3.weight, sparse_encoder.sp_cnn.layer2.0.conv1.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer2.0.conv2.weight, sparse_encoder.sp_cnn.layer2.0.conv3.weight, sparse_encoder.sp_cnn.layer2.0.downsample.0.weight, sparse_encoder.sp_cnn.layer2.1.conv1.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer2.1.conv2.weight, sparse_encoder.sp_cnn.layer2.1.conv3.weight, sparse_encoder.sp_cnn.layer2.2.conv1.weight, sparse_encoder.sp_cnn.layer2.2.conv2.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer2.2.conv3.weight, sparse_encoder.sp_cnn.layer2.3.conv1.weight, sparse_encoder.sp_cnn.layer2.3.conv2.weight, sparse_encoder.sp_cnn.layer2.3.conv3.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer3.0.conv1.weight, sparse_encoder.sp_cnn.layer3.0.conv2.weight, sparse_encoder.sp_cnn.layer3.0.conv3.weight, sparse_encoder.sp_cnn.layer3.0.downsample.0.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer3.1.conv1.weight, sparse_encoder.sp_cnn.layer3.1.conv2.weight, sparse_encoder.sp_cnn.layer3.1.conv3.weight, sparse_encoder.sp_cnn.layer3.2.conv1.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer3.2.conv2.weight, sparse_encoder.sp_cnn.layer3.2.conv3.weight, sparse_encoder.sp_cnn.layer3.3.conv1.weight, sparse_encoder.sp_cnn.layer3.3.conv2.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer3.3.conv3.weight, sparse_encoder.sp_cnn.layer3.4.conv1.weight, sparse_encoder.sp_cnn.layer3.4.conv2.weight, sparse_encoder.sp_cnn.layer3.4.conv3.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer3.5.conv1.weight, sparse_encoder.sp_cnn.layer3.5.conv2.weight, sparse_encoder.sp_cnn.layer3.5.conv3.weight, sparse_encoder.sp_cnn.layer4.0.conv1.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer4.0.conv2.weight, sparse_encoder.sp_cnn.layer4.0.conv3.weight, sparse_encoder.sp_cnn.layer4.0.downsample.0.weight, sparse_encoder.sp_cnn.layer4.1.conv1.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer4.1.conv2.weight, sparse_encoder.sp_cnn.layer4.1.conv3.weight, sparse_encoder.sp_cnn.layer4.2.conv1.weight, sparse_encoder.sp_cnn.layer4.2.conv2.weight, '\\n\"\n",
      "                       \" 'sparse_encoder.sp_cnn.layer4.2.conv3.weight, dense_decoder.dec.0.up_sample.weight, dense_decoder.dec.0.conv.0.weight, dense_decoder.dec.0.conv.3.weight, dense_decoder.dec.1.up_sample.weight, '\\n\"\n",
      "                       \" 'dense_decoder.dec.1.conv.0.weight, dense_decoder.dec.1.conv.3.weight, dense_decoder.dec.2.up_sample.weight, dense_decoder.dec.2.conv.0.weight, dense_decoder.dec.2.conv.3.weight, '\\n\"\n",
      "                       \" 'dense_decoder.dec.3.up_sample.weight, dense_decoder.dec.3.conv.0.weight, dense_decoder.dec.3.conv.3.weight, dense_decoder.dec.4.up_sample.weight, dense_decoder.dec.4.conv.0.weight, '\\n\"\n",
      "                       \" 'dense_decoder.dec.4.conv.3.weight, dense_decoder.proj.weight, densify_projs.0.weight, densify_projs.1.weight, densify_projs.2.weight, densify_projs.3.weight')\",\n",
      "             'weight_decay_scale': 1.0},\n",
      "  'no_decay': { 'lr_scale': 1.0,\n",
      "                'params': \"('sparse_encoder.sp_cnn.bn1.weight, sparse_encoder.sp_cnn.bn1.bias, sparse_encoder.sp_cnn.layer1.0.bn1.weight, sparse_encoder.sp_cnn.layer1.0.bn1.bias, sparse_encoder.sp_cnn.layer1.0.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer1.0.bn2.bias, sparse_encoder.sp_cnn.layer1.0.bn3.weight, sparse_encoder.sp_cnn.layer1.0.bn3.bias, sparse_encoder.sp_cnn.layer1.0.downsample.1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer1.0.downsample.1.bias, sparse_encoder.sp_cnn.layer1.1.bn1.weight, sparse_encoder.sp_cnn.layer1.1.bn1.bias, sparse_encoder.sp_cnn.layer1.1.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer1.1.bn2.bias, sparse_encoder.sp_cnn.layer1.1.bn3.weight, sparse_encoder.sp_cnn.layer1.1.bn3.bias, sparse_encoder.sp_cnn.layer1.2.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer1.2.bn1.bias, sparse_encoder.sp_cnn.layer1.2.bn2.weight, sparse_encoder.sp_cnn.layer1.2.bn2.bias, sparse_encoder.sp_cnn.layer1.2.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer1.2.bn3.bias, sparse_encoder.sp_cnn.layer2.0.bn1.weight, sparse_encoder.sp_cnn.layer2.0.bn1.bias, sparse_encoder.sp_cnn.layer2.0.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer2.0.bn2.bias, sparse_encoder.sp_cnn.layer2.0.bn3.weight, sparse_encoder.sp_cnn.layer2.0.bn3.bias, sparse_encoder.sp_cnn.layer2.0.downsample.1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer2.0.downsample.1.bias, sparse_encoder.sp_cnn.layer2.1.bn1.weight, sparse_encoder.sp_cnn.layer2.1.bn1.bias, sparse_encoder.sp_cnn.layer2.1.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer2.1.bn2.bias, sparse_encoder.sp_cnn.layer2.1.bn3.weight, sparse_encoder.sp_cnn.layer2.1.bn3.bias, sparse_encoder.sp_cnn.layer2.2.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer2.2.bn1.bias, sparse_encoder.sp_cnn.layer2.2.bn2.weight, sparse_encoder.sp_cnn.layer2.2.bn2.bias, sparse_encoder.sp_cnn.layer2.2.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer2.2.bn3.bias, sparse_encoder.sp_cnn.layer2.3.bn1.weight, sparse_encoder.sp_cnn.layer2.3.bn1.bias, sparse_encoder.sp_cnn.layer2.3.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer2.3.bn2.bias, sparse_encoder.sp_cnn.layer2.3.bn3.weight, sparse_encoder.sp_cnn.layer2.3.bn3.bias, sparse_encoder.sp_cnn.layer3.0.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.0.bn1.bias, sparse_encoder.sp_cnn.layer3.0.bn2.weight, sparse_encoder.sp_cnn.layer3.0.bn2.bias, sparse_encoder.sp_cnn.layer3.0.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.0.bn3.bias, sparse_encoder.sp_cnn.layer3.0.downsample.1.weight, sparse_encoder.sp_cnn.layer3.0.downsample.1.bias, sparse_encoder.sp_cnn.layer3.1.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.1.bn1.bias, sparse_encoder.sp_cnn.layer3.1.bn2.weight, sparse_encoder.sp_cnn.layer3.1.bn2.bias, sparse_encoder.sp_cnn.layer3.1.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.1.bn3.bias, sparse_encoder.sp_cnn.layer3.2.bn1.weight, sparse_encoder.sp_cnn.layer3.2.bn1.bias, sparse_encoder.sp_cnn.layer3.2.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.2.bn2.bias, sparse_encoder.sp_cnn.layer3.2.bn3.weight, sparse_encoder.sp_cnn.layer3.2.bn3.bias, sparse_encoder.sp_cnn.layer3.3.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.3.bn1.bias, sparse_encoder.sp_cnn.layer3.3.bn2.weight, sparse_encoder.sp_cnn.layer3.3.bn2.bias, sparse_encoder.sp_cnn.layer3.3.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.3.bn3.bias, sparse_encoder.sp_cnn.layer3.4.bn1.weight, sparse_encoder.sp_cnn.layer3.4.bn1.bias, sparse_encoder.sp_cnn.layer3.4.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.4.bn2.bias, sparse_encoder.sp_cnn.layer3.4.bn3.weight, sparse_encoder.sp_cnn.layer3.4.bn3.bias, sparse_encoder.sp_cnn.layer3.5.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.5.bn1.bias, sparse_encoder.sp_cnn.layer3.5.bn2.weight, sparse_encoder.sp_cnn.layer3.5.bn2.bias, sparse_encoder.sp_cnn.layer3.5.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer3.5.bn3.bias, sparse_encoder.sp_cnn.layer4.0.bn1.weight, sparse_encoder.sp_cnn.layer4.0.bn1.bias, sparse_encoder.sp_cnn.layer4.0.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer4.0.bn2.bias, sparse_encoder.sp_cnn.layer4.0.bn3.weight, sparse_encoder.sp_cnn.layer4.0.bn3.bias, sparse_encoder.sp_cnn.layer4.0.downsample.1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer4.0.downsample.1.bias, sparse_encoder.sp_cnn.layer4.1.bn1.weight, sparse_encoder.sp_cnn.layer4.1.bn1.bias, sparse_encoder.sp_cnn.layer4.1.bn2.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer4.1.bn2.bias, sparse_encoder.sp_cnn.layer4.1.bn3.weight, sparse_encoder.sp_cnn.layer4.1.bn3.bias, sparse_encoder.sp_cnn.layer4.2.bn1.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer4.2.bn1.bias, sparse_encoder.sp_cnn.layer4.2.bn2.weight, sparse_encoder.sp_cnn.layer4.2.bn2.bias, sparse_encoder.sp_cnn.layer4.2.bn3.weight, '\\n\"\n",
      "                          \" 'sparse_encoder.sp_cnn.layer4.2.bn3.bias, dense_decoder.dec.0.up_sample.bias, dense_decoder.dec.0.conv.1.weight, dense_decoder.dec.0.conv.1.bias, dense_decoder.dec.0.conv.4.weight, '\\n\"\n",
      "                          \" 'dense_decoder.dec.0.conv.4.bias, dense_decoder.dec.1.up_sample.bias, dense_decoder.dec.1.conv.1.weight, dense_decoder.dec.1.conv.1.bias, dense_decoder.dec.1.conv.4.weight, '\\n\"\n",
      "                          \" 'dense_decoder.dec.1.conv.4.bias, dense_decoder.dec.2.up_sample.bias, dense_decoder.dec.2.conv.1.weight, dense_decoder.dec.2.conv.1.bias, dense_decoder.dec.2.conv.4.weight, '\\n\"\n",
      "                          \" 'dense_decoder.dec.2.conv.4.bias, dense_decoder.dec.3.up_sample.bias, dense_decoder.dec.3.conv.1.weight, dense_decoder.dec.3.conv.1.bias, dense_decoder.dec.3.conv.4.weight, '\\n\"\n",
      "                          \" 'dense_decoder.dec.3.conv.4.bias, dense_decoder.dec.4.up_sample.bias, dense_decoder.dec.4.conv.1.weight, dense_decoder.dec.4.conv.1.bias, dense_decoder.dec.4.conv.4.weight, '\\n\"\n",
      "                          \" 'dense_decoder.dec.4.conv.4.bias, dense_decoder.proj.bias, densify_projs.0.bias, densify_projs.1.bias, densify_projs.2.bias, densify_projs.3.bias, mask_tokens.0, mask_tokens.1, mask_tokens.2, '\\n\"\n",
      "                          \" 'mask_tokens.3')\",\n",
      "                'weight_decay_scale': 0.0}}\n",
      "\n",
      "[lamb1] max_grad_norm=5.0\n"
     ]
    }
   ],
   "source": [
    "param_groups: List[dict] = get_param_groups(model_without_ddp, nowd_keys={'cls_token', 'pos_embed', 'mask_token', 'gamma'})\n",
    "\n",
    "opt_clz = {\n",
    "    'sgd': partial(torch.optim.SGD, momentum=0.9, nesterov=True),\n",
    "    'adamw': partial(torch.optim.AdamW, betas=(0.9, 0.95)),\n",
    "    'lamb': partial(lamb.TheSameAsTimmLAMB, betas=(0.9, 0.95), max_grad_norm=5.0),\n",
    "}['lamb']\n",
    "\n",
    "optimizer = opt_clz(params=param_groups, lr=2e-4*batch_size/256, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train_epochs(num_epochs, tb_lg: misc.TensorboardLogger, itrt_train, iters_train, model, optimizer, device):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for ep in range(num_epochs):\n",
    "        model.train()\n",
    "        me = misc.MetricLogger(delimiter='  ')\n",
    "        me.add_meter('max_lr', misc.SmoothedValue(window_size=1, fmt='{value:.5f}'))\n",
    "        header = f'[PT] Epoch {ep}:'\n",
    "        itrt_train = iter(data_loader_train)\n",
    "        optimizer.zero_grad()\n",
    "        early_clipping = 5. > 0 and not hasattr(optimizer, 'global_grad_norm')\n",
    "        late_clipping = hasattr(optimizer, 'global_grad_norm')\n",
    "\n",
    "        if early_clipping:\n",
    "            params_req_grad = [p for p in model.parameters() if p.requires_grad]\n",
    "        # reset iterator every epoch\n",
    "\n",
    "        for it, (inp, _) in enumerate(me.log_every(iters_train, itrt_train, 3, header)):\n",
    "            # adjust lr and wd\n",
    "            min_lr, max_lr, min_wd, max_wd = lr_wd_annealing(optimizer, 2e-4*batch_size/256, 0.04, 0.2, it + ep * iters_train, 40 * iters_train, 1600 * iters_train)\n",
    "\n",
    "            # forward and backward\n",
    "            inp = inp.to(device, non_blocking=True)\n",
    "            # SparK.forward (Replace with actual forward function call)\n",
    "            loss = model(inp, active_b1ff=None, vis=False)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            loss = loss.item()\n",
    "\n",
    "            if not math.isfinite(loss):\n",
    "                print(f'Loss is {loss}, stopping training!', force=True, flush=True)\n",
    "                sys.exit(-1)\n",
    "\n",
    "            # optimize\n",
    "            grad_norm = None\n",
    "            if early_clipping: grad_norm = torch.nn.utils.clip_grad_norm_(params_req_grad, 5.).item()\n",
    "            optimizer.step()\n",
    "            if late_clipping: grad_norm = optimizer.global_grad_norm\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            # log\n",
    "            me.update(last_loss=loss)\n",
    "            me.update(max_lr=max_lr)\n",
    "            tb_lg.update(loss=me.meters['last_loss'].global_avg, head='train_loss')\n",
    "            tb_lg.update(sche_lr=max_lr, head='train_hp/lr_max')\n",
    "            tb_lg.update(sche_lr=min_lr, head='train_hp/lr_min')\n",
    "            tb_lg.update(sche_wd=max_wd, head='train_hp/wd_max')\n",
    "            tb_lg.update(sche_wd=min_wd, head='train_hp/wd_min')\n",
    "\n",
    "            if grad_norm is not None:\n",
    "                me.update(orig_norm=grad_norm)\n",
    "                tb_lg.update(orig_norm=grad_norm, head='train_hp')\n",
    "            tb_lg.set_step()\n",
    "\n",
    "        print(f'Finished training epoch {ep}')\n",
    "\n",
    "    return {k: meter.global_avg for k, meter in me.meters.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_lg = misc.TensorboardLogger('/home/chong.tian/hc701/check_tensorboard_pre_train_log', is_master=dist.is_master(), prefix='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PT] Epoch 0:  [ 0/92]  eta: 0:02:30  max_lr: 0.00000  last_loss: 0.9994 (0.9994)  orig_norm: 0.9666 (0.9666)  iter: 1.6342s  data: 0.1083s\n",
      "[PT] Epoch 0:  [45/92]  eta: 0:00:10  max_lr: 0.00000  last_loss: 0.9984 (0.9975)  orig_norm: 0.9545 (0.9546)  iter: 0.1889s  data: 0.0002s\n",
      "[PT] Epoch 0:   Total time:      0:00:10   (0.110 s / it)\n",
      "Finished training epoch 0\n",
      "[PT] Epoch 1:  [ 0/92]  eta: 0:00:23  max_lr: 0.00000  last_loss: 0.9933 (0.9933)  orig_norm: 0.9318 (0.9318)  iter: 0.2502s  data: 0.0532s\n",
      "[PT] Epoch 1:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9971 (0.9972)  orig_norm: 0.9564 (0.9516)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 1:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 1\n",
      "[PT] Epoch 2:  [ 0/92]  eta: 0:00:22  max_lr: 0.00000  last_loss: 1.0003 (1.0003)  orig_norm: 0.9904 (0.9904)  iter: 0.2456s  data: 0.0546s\n",
      "[PT] Epoch 2:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9991 (0.9968)  orig_norm: 0.9526 (0.9545)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 2:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 2\n",
      "[PT] Epoch 3:  [ 0/92]  eta: 0:00:22  max_lr: 0.00000  last_loss: 0.9918 (0.9918)  orig_norm: 0.9479 (0.9479)  iter: 0.2437s  data: 0.0521s\n",
      "[PT] Epoch 3:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9966 (0.9966)  orig_norm: 0.9628 (0.9561)  iter: 0.1809s  data: 0.0001s\n",
      "[PT] Epoch 3:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 3\n",
      "[PT] Epoch 4:  [ 0/92]  eta: 0:00:23  max_lr: 0.00000  last_loss: 0.9896 (0.9896)  orig_norm: 0.9805 (0.9805)  iter: 0.2546s  data: 0.0585s\n",
      "[PT] Epoch 4:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9955 (0.9957)  orig_norm: 0.9427 (0.9480)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 4:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 4\n",
      "[PT] Epoch 5:  [ 0/92]  eta: 0:00:23  max_lr: 0.00000  last_loss: 0.9910 (0.9910)  orig_norm: 0.9545 (0.9545)  iter: 0.2597s  data: 0.0638s\n",
      "[PT] Epoch 5:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9925 (0.9944)  orig_norm: 0.9598 (0.9565)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 5:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 5\n",
      "[PT] Epoch 6:  [ 0/92]  eta: 0:00:23  max_lr: 0.00000  last_loss: 0.9991 (0.9991)  orig_norm: 0.9802 (0.9802)  iter: 0.2550s  data: 0.0592s\n",
      "[PT] Epoch 6:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9915 (0.9931)  orig_norm: 0.9525 (0.9587)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 6:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 6\n",
      "[PT] Epoch 7:  [ 0/92]  eta: 0:00:22  max_lr: 0.00000  last_loss: 0.9948 (0.9948)  orig_norm: 0.9590 (0.9590)  iter: 0.2494s  data: 0.0599s\n",
      "[PT] Epoch 7:  [45/92]  eta: 0:00:08  max_lr: 0.00000  last_loss: 0.9904 (0.9911)  orig_norm: 0.9535 (0.9572)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 7:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 7\n",
      "[PT] Epoch 8:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9933 (0.9933)  orig_norm: 0.9791 (0.9791)  iter: 0.2521s  data: 0.0553s\n",
      "[PT] Epoch 8:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9890 (0.9898)  orig_norm: 0.9597 (0.9640)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 8:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 8\n",
      "[PT] Epoch 9:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9950 (0.9950)  orig_norm: 0.9872 (0.9872)  iter: 0.2575s  data: 0.0642s\n",
      "[PT] Epoch 9:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9835 (0.9871)  orig_norm: 0.9698 (0.9690)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 9:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 9\n",
      "[PT] Epoch 10:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9892 (0.9892)  orig_norm: 0.9821 (0.9821)  iter: 0.2551s  data: 0.0593s\n",
      "[PT] Epoch 10:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9843 (0.9850)  orig_norm: 0.9801 (0.9711)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 10:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 10\n",
      "[PT] Epoch 11:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9794 (0.9794)  orig_norm: 0.9866 (0.9866)  iter: 0.2520s  data: 0.0569s\n",
      "[PT] Epoch 11:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9808 (0.9826)  orig_norm: 1.0018 (0.9920)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 11:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 11\n",
      "[PT] Epoch 12:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9844 (0.9844)  orig_norm: 1.0334 (1.0334)  iter: 0.2519s  data: 0.0582s\n",
      "[PT] Epoch 12:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9802 (0.9787)  orig_norm: 1.0114 (1.0089)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 12:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 12\n",
      "[PT] Epoch 13:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.9765 (0.9765)  orig_norm: 0.9723 (0.9723)  iter: 0.2496s  data: 0.0526s\n",
      "[PT] Epoch 13:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9748 (0.9753)  orig_norm: 1.0379 (1.0284)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 13:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 13\n",
      "[PT] Epoch 14:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9683 (0.9683)  orig_norm: 1.0244 (1.0244)  iter: 0.2547s  data: 0.0603s\n",
      "[PT] Epoch 14:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9701 (0.9710)  orig_norm: 1.0672 (1.0577)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 14:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 14\n",
      "[PT] Epoch 15:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.9695 (0.9695)  orig_norm: 1.0673 (1.0673)  iter: 0.2443s  data: 0.0529s\n",
      "[PT] Epoch 15:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9637 (0.9667)  orig_norm: 1.1018 (1.0858)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 15:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 15\n",
      "[PT] Epoch 16:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.9664 (0.9664)  orig_norm: 1.1304 (1.1304)  iter: 0.2631s  data: 0.0662s\n",
      "[PT] Epoch 16:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9584 (0.9613)  orig_norm: 1.1479 (1.1260)  iter: 0.1839s  data: 0.0001s\n",
      "[PT] Epoch 16:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 16\n",
      "[PT] Epoch 17:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.9523 (0.9523)  orig_norm: 1.1877 (1.1877)  iter: 0.2466s  data: 0.0539s\n",
      "[PT] Epoch 17:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9563 (0.9573)  orig_norm: 1.1820 (1.1723)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 17:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 17\n",
      "[PT] Epoch 18:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.9564 (0.9564)  orig_norm: 1.1878 (1.1878)  iter: 0.2473s  data: 0.0537s\n",
      "[PT] Epoch 18:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9506 (0.9510)  orig_norm: 1.2228 (1.2238)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 18:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 18\n",
      "[PT] Epoch 19:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.9531 (0.9531)  orig_norm: 1.2003 (1.2003)  iter: 0.2499s  data: 0.0562s\n",
      "[PT] Epoch 19:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9431 (0.9449)  orig_norm: 1.3018 (1.2802)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 19:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 19\n",
      "[PT] Epoch 20:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.9369 (0.9369)  orig_norm: 1.3260 (1.3260)  iter: 0.2454s  data: 0.0513s\n",
      "[PT] Epoch 20:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9350 (0.9379)  orig_norm: 1.3661 (1.3450)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 20:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 20\n",
      "[PT] Epoch 21:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9347 (0.9347)  orig_norm: 1.3723 (1.3723)  iter: 0.2558s  data: 0.0615s\n",
      "[PT] Epoch 21:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9306 (0.9318)  orig_norm: 1.4091 (1.4003)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 21:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 21\n",
      "[PT] Epoch 22:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9309 (0.9309)  orig_norm: 1.4402 (1.4402)  iter: 0.2526s  data: 0.0578s\n",
      "[PT] Epoch 22:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9226 (0.9247)  orig_norm: 1.4842 (1.4705)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 22:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 22\n",
      "[PT] Epoch 23:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.9226 (0.9226)  orig_norm: 1.4826 (1.4826)  iter: 0.2603s  data: 0.0656s\n",
      "[PT] Epoch 23:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.9152 (0.9172)  orig_norm: 1.5475 (1.5396)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 23:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 23\n",
      "[PT] Epoch 24:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.9135 (0.9135)  orig_norm: 1.6140 (1.6140)  iter: 0.2494s  data: 0.0551s\n",
      "[PT] Epoch 24:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.9079 (0.9092)  orig_norm: 1.6342 (1.6156)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 24:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 24\n",
      "[PT] Epoch 25:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.9101 (0.9101)  orig_norm: 1.6284 (1.6284)  iter: 0.2432s  data: 0.0530s\n",
      "[PT] Epoch 25:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.9000 (0.9009)  orig_norm: 1.6909 (1.6834)  iter: 0.1839s  data: 0.0001s\n",
      "[PT] Epoch 25:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 25\n",
      "[PT] Epoch 26:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.9034 (0.9034)  orig_norm: 1.7234 (1.7234)  iter: 0.2598s  data: 0.0650s\n",
      "[PT] Epoch 26:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8927 (0.8943)  orig_norm: 1.7382 (1.7373)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 26:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 26\n",
      "[PT] Epoch 27:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.8953 (0.8953)  orig_norm: 1.7690 (1.7690)  iter: 0.2590s  data: 0.0632s\n",
      "[PT] Epoch 27:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8831 (0.8858)  orig_norm: 1.8462 (1.8074)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 27:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 27\n",
      "[PT] Epoch 28:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.8787 (0.8787)  orig_norm: 1.8818 (1.8818)  iter: 0.2440s  data: 0.0535s\n",
      "[PT] Epoch 28:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8745 (0.8765)  orig_norm: 1.8948 (1.8706)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 28:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 28\n",
      "[PT] Epoch 29:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.8640 (0.8640)  orig_norm: 1.8976 (1.8976)  iter: 0.2701s  data: 0.0729s\n",
      "[PT] Epoch 29:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8630 (0.8671)  orig_norm: 1.9387 (1.9232)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 29:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 29\n",
      "[PT] Epoch 30:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.8702 (0.8702)  orig_norm: 1.9214 (1.9214)  iter: 0.2544s  data: 0.0583s\n",
      "[PT] Epoch 30:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8559 (0.8598)  orig_norm: 2.0089 (1.9832)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 30:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 30\n",
      "[PT] Epoch 31:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.8555 (0.8555)  orig_norm: 2.0314 (2.0314)  iter: 0.2584s  data: 0.0595s\n",
      "[PT] Epoch 31:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8490 (0.8511)  orig_norm: 2.0600 (2.0413)  iter: 0.1853s  data: 0.0002s\n",
      "[PT] Epoch 31:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 31\n",
      "[PT] Epoch 32:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.8430 (0.8430)  orig_norm: 2.1089 (2.1089)  iter: 0.2497s  data: 0.0581s\n",
      "[PT] Epoch 32:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8392 (0.8419)  orig_norm: 2.1109 (2.0910)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 32:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 32\n",
      "[PT] Epoch 33:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.8361 (0.8361)  orig_norm: 2.0808 (2.0808)  iter: 0.2590s  data: 0.0642s\n",
      "[PT] Epoch 33:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8305 (0.8322)  orig_norm: 2.1618 (2.1472)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 33:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 33\n",
      "[PT] Epoch 34:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.8295 (0.8295)  orig_norm: 2.1697 (2.1697)  iter: 0.2453s  data: 0.0548s\n",
      "[PT] Epoch 34:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8221 (0.8244)  orig_norm: 2.2073 (2.1898)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 34:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 34\n",
      "[PT] Epoch 35:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.8172 (0.8172)  orig_norm: 2.2804 (2.2804)  iter: 0.2566s  data: 0.0640s\n",
      "[PT] Epoch 35:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8119 (0.8140)  orig_norm: 2.2443 (2.2398)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 35:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 35\n",
      "[PT] Epoch 36:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.8097 (0.8097)  orig_norm: 2.2460 (2.2460)  iter: 0.2488s  data: 0.0559s\n",
      "[PT] Epoch 36:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.8030 (0.8054)  orig_norm: 2.3052 (2.2901)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 36:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 36\n",
      "[PT] Epoch 37:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.8048 (0.8048)  orig_norm: 2.3397 (2.3397)  iter: 0.2562s  data: 0.0628s\n",
      "[PT] Epoch 37:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7969 (0.7975)  orig_norm: 2.3118 (2.3235)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 37:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 37\n",
      "[PT] Epoch 38:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.7952 (0.7952)  orig_norm: 2.3345 (2.3345)  iter: 0.2576s  data: 0.0631s\n",
      "[PT] Epoch 38:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7841 (0.7873)  orig_norm: 2.3752 (2.3678)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 38:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 38\n",
      "[PT] Epoch 39:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.7871 (0.7871)  orig_norm: 2.4221 (2.4221)  iter: 0.2605s  data: 0.0658s\n",
      "[PT] Epoch 39:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7748 (0.7785)  orig_norm: 2.4165 (2.4078)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 39:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 39\n",
      "[PT] Epoch 40:  [ 0/92]  eta: 0:00:23  max_lr: 0.00003  last_loss: 0.7828 (0.7828)  orig_norm: 2.3432 (2.3432)  iter: 0.2522s  data: 0.0577s\n",
      "[PT] Epoch 40:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7669 (0.7703)  orig_norm: 2.4494 (2.4363)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 40:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 40\n",
      "[PT] Epoch 41:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.7664 (0.7664)  orig_norm: 2.4413 (2.4413)  iter: 0.2570s  data: 0.0616s\n",
      "[PT] Epoch 41:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7598 (0.7626)  orig_norm: 2.4813 (2.4708)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 41:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 41\n",
      "[PT] Epoch 42:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.7611 (0.7611)  orig_norm: 2.4720 (2.4720)  iter: 0.2464s  data: 0.0538s\n",
      "[PT] Epoch 42:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7480 (0.7525)  orig_norm: 2.5135 (2.4999)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 42:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 42\n",
      "[PT] Epoch 43:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.7550 (0.7550)  orig_norm: 2.4154 (2.4154)  iter: 0.2487s  data: 0.0534s\n",
      "[PT] Epoch 43:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7436 (0.7440)  orig_norm: 2.5617 (2.5338)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 43:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 43\n",
      "[PT] Epoch 44:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.7357 (0.7357)  orig_norm: 2.5882 (2.5882)  iter: 0.2590s  data: 0.0675s\n",
      "[PT] Epoch 44:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7312 (0.7353)  orig_norm: 2.5720 (2.5667)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 44:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 44\n",
      "[PT] Epoch 45:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.7274 (0.7274)  orig_norm: 2.5494 (2.5494)  iter: 0.2576s  data: 0.0640s\n",
      "[PT] Epoch 45:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7250 (0.7277)  orig_norm: 2.5914 (2.5969)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 45:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 45\n",
      "[PT] Epoch 46:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.7282 (0.7282)  orig_norm: 2.7074 (2.7074)  iter: 0.2523s  data: 0.0589s\n",
      "[PT] Epoch 46:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7143 (0.7185)  orig_norm: 2.6295 (2.6314)  iter: 0.1877s  data: 0.0001s\n",
      "[PT] Epoch 46:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 46\n",
      "[PT] Epoch 47:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.7135 (0.7135)  orig_norm: 2.6339 (2.6339)  iter: 0.2672s  data: 0.0744s\n",
      "[PT] Epoch 47:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7092 (0.7130)  orig_norm: 2.6479 (2.6381)  iter: 0.1810s  data: 0.0001s\n",
      "[PT] Epoch 47:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 47\n",
      "[PT] Epoch 48:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.7020 (0.7020)  orig_norm: 2.6654 (2.6654)  iter: 0.2491s  data: 0.0571s\n",
      "[PT] Epoch 48:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.7042 (0.7059)  orig_norm: 2.6768 (2.6650)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 48:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 48\n",
      "[PT] Epoch 49:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6984 (0.6984)  orig_norm: 2.6659 (2.6659)  iter: 0.2557s  data: 0.0604s\n",
      "[PT] Epoch 49:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6970 (0.6973)  orig_norm: 2.7067 (2.6929)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 49:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 49\n",
      "[PT] Epoch 50:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.6923 (0.6923)  orig_norm: 2.7644 (2.7644)  iter: 0.2707s  data: 0.0753s\n",
      "[PT] Epoch 50:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6866 (0.6905)  orig_norm: 2.7449 (2.7242)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 50:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 50\n",
      "[PT] Epoch 51:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.6850 (0.6850)  orig_norm: 2.7054 (2.7054)  iter: 0.2624s  data: 0.0688s\n",
      "[PT] Epoch 51:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6818 (0.6838)  orig_norm: 2.7692 (2.7409)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 51:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 51\n",
      "[PT] Epoch 52:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.6946 (0.6946)  orig_norm: 2.5944 (2.5944)  iter: 0.2480s  data: 0.0507s\n",
      "[PT] Epoch 52:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6737 (0.6773)  orig_norm: 2.7649 (2.7579)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 52:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 52\n",
      "[PT] Epoch 53:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.6709 (0.6709)  orig_norm: 2.7550 (2.7550)  iter: 0.2415s  data: 0.0499s\n",
      "[PT] Epoch 53:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6720 (0.6725)  orig_norm: 2.7861 (2.7717)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 53:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 53\n",
      "[PT] Epoch 54:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6671 (0.6671)  orig_norm: 2.8016 (2.8016)  iter: 0.2557s  data: 0.0636s\n",
      "[PT] Epoch 54:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6642 (0.6651)  orig_norm: 2.7803 (2.8001)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 54:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 54\n",
      "[PT] Epoch 55:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6594 (0.6594)  orig_norm: 2.8422 (2.8422)  iter: 0.2547s  data: 0.0597s\n",
      "[PT] Epoch 55:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6560 (0.6583)  orig_norm: 2.8128 (2.8172)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 55:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 55\n",
      "[PT] Epoch 56:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.6536 (0.6536)  orig_norm: 2.8326 (2.8326)  iter: 0.2638s  data: 0.0706s\n",
      "[PT] Epoch 56:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6505 (0.6517)  orig_norm: 2.8276 (2.8340)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 56:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 56\n",
      "[PT] Epoch 57:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6501 (0.6501)  orig_norm: 2.8685 (2.8685)  iter: 0.2554s  data: 0.0593s\n",
      "[PT] Epoch 57:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6438 (0.6455)  orig_norm: 2.8648 (2.8545)  iter: 0.1811s  data: 0.0001s\n",
      "[PT] Epoch 57:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 57\n",
      "[PT] Epoch 58:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6392 (0.6392)  orig_norm: 2.9104 (2.9104)  iter: 0.2581s  data: 0.0633s\n",
      "[PT] Epoch 58:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6375 (0.6397)  orig_norm: 2.8832 (2.8848)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 58:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 58\n",
      "[PT] Epoch 59:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.6352 (0.6352)  orig_norm: 2.8519 (2.8519)  iter: 0.2488s  data: 0.0566s\n",
      "[PT] Epoch 59:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6347 (0.6357)  orig_norm: 2.8816 (2.8765)  iter: 0.1841s  data: 0.0001s\n",
      "[PT] Epoch 59:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 59\n",
      "[PT] Epoch 60:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.6342 (0.6342)  orig_norm: 2.9193 (2.9193)  iter: 0.2481s  data: 0.0553s\n",
      "[PT] Epoch 60:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6275 (0.6291)  orig_norm: 2.8799 (2.8935)  iter: 0.1811s  data: 0.0001s\n",
      "[PT] Epoch 60:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 60\n",
      "[PT] Epoch 61:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6191 (0.6191)  orig_norm: 2.9247 (2.9247)  iter: 0.2577s  data: 0.0640s\n",
      "[PT] Epoch 61:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6200 (0.6234)  orig_norm: 2.8981 (2.8999)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 61:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 61\n",
      "[PT] Epoch 62:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6182 (0.6182)  orig_norm: 2.8500 (2.8500)  iter: 0.2578s  data: 0.0629s\n",
      "[PT] Epoch 62:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6181 (0.6181)  orig_norm: 2.9161 (2.9129)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 62:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 62\n",
      "[PT] Epoch 63:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.6118 (0.6118)  orig_norm: 2.9386 (2.9386)  iter: 0.2497s  data: 0.0534s\n",
      "[PT] Epoch 63:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6126 (0.6139)  orig_norm: 2.9095 (2.9223)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 63:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 63\n",
      "[PT] Epoch 64:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6179 (0.6179)  orig_norm: 2.8605 (2.8605)  iter: 0.2553s  data: 0.0645s\n",
      "[PT] Epoch 64:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6064 (0.6085)  orig_norm: 2.9520 (2.9307)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 64:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 64\n",
      "[PT] Epoch 65:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6048 (0.6048)  orig_norm: 2.9307 (2.9307)  iter: 0.2596s  data: 0.0644s\n",
      "[PT] Epoch 65:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.6008 (0.6043)  orig_norm: 2.9437 (2.9317)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 65:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 65\n",
      "[PT] Epoch 66:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.6034 (0.6034)  orig_norm: 2.9309 (2.9309)  iter: 0.2564s  data: 0.0596s\n",
      "[PT] Epoch 66:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5954 (0.5980)  orig_norm: 2.9474 (2.9482)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 66:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 66\n",
      "[PT] Epoch 67:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.5978 (0.5978)  orig_norm: 2.8946 (2.8946)  iter: 0.2610s  data: 0.0650s\n",
      "[PT] Epoch 67:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5918 (0.5935)  orig_norm: 2.9643 (2.9473)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 67:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 67\n",
      "[PT] Epoch 68:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5898 (0.5898)  orig_norm: 3.0513 (3.0513)  iter: 0.2520s  data: 0.0580s\n",
      "[PT] Epoch 68:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5899 (0.5895)  orig_norm: 2.9389 (2.9468)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 68:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 68\n",
      "[PT] Epoch 69:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5964 (0.5964)  orig_norm: 2.9213 (2.9213)  iter: 0.2592s  data: 0.0668s\n",
      "[PT] Epoch 69:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5823 (0.5845)  orig_norm: 2.9645 (2.9469)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 69:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 69\n",
      "[PT] Epoch 70:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5831 (0.5831)  orig_norm: 2.9101 (2.9101)  iter: 0.2591s  data: 0.0643s\n",
      "[PT] Epoch 70:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5771 (0.5782)  orig_norm: 2.9662 (2.9637)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 70:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 70\n",
      "[PT] Epoch 71:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5748 (0.5748)  orig_norm: 2.9762 (2.9762)  iter: 0.2586s  data: 0.0638s\n",
      "[PT] Epoch 71:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5742 (0.5751)  orig_norm: 2.9817 (2.9702)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 71:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 71\n",
      "[PT] Epoch 72:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.5760 (0.5760)  orig_norm: 2.9257 (2.9257)  iter: 0.2476s  data: 0.0554s\n",
      "[PT] Epoch 72:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5691 (0.5710)  orig_norm: 2.9800 (2.9672)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 72:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 72\n",
      "[PT] Epoch 73:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.5694 (0.5694)  orig_norm: 2.9215 (2.9215)  iter: 0.2438s  data: 0.0500s\n",
      "[PT] Epoch 73:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5673 (0.5665)  orig_norm: 2.9684 (2.9826)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 73:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 73\n",
      "[PT] Epoch 74:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5599 (0.5599)  orig_norm: 2.9777 (2.9777)  iter: 0.2580s  data: 0.0638s\n",
      "[PT] Epoch 74:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5614 (0.5618)  orig_norm: 2.9549 (2.9648)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 74:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 74\n",
      "[PT] Epoch 75:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5559 (0.5559)  orig_norm: 3.0410 (3.0410)  iter: 0.2531s  data: 0.0629s\n",
      "[PT] Epoch 75:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5591 (0.5585)  orig_norm: 2.9693 (2.9632)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 75:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 75\n",
      "[PT] Epoch 76:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5587 (0.5587)  orig_norm: 2.9444 (2.9444)  iter: 0.2531s  data: 0.0648s\n",
      "[PT] Epoch 76:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5543 (0.5551)  orig_norm: 2.9621 (2.9599)  iter: 0.1811s  data: 0.0001s\n",
      "[PT] Epoch 76:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 76\n",
      "[PT] Epoch 77:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5537 (0.5537)  orig_norm: 3.0220 (3.0220)  iter: 0.2539s  data: 0.0619s\n",
      "[PT] Epoch 77:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5496 (0.5500)  orig_norm: 2.9807 (2.9811)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 77:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 77\n",
      "[PT] Epoch 78:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.5491 (0.5491)  orig_norm: 2.9512 (2.9512)  iter: 0.2716s  data: 0.0766s\n",
      "[PT] Epoch 78:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5441 (0.5461)  orig_norm: 2.9818 (2.9730)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 78:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 78\n",
      "[PT] Epoch 79:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5406 (0.5406)  orig_norm: 2.9561 (2.9561)  iter: 0.2550s  data: 0.0593s\n",
      "[PT] Epoch 79:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5416 (0.5423)  orig_norm: 2.9798 (2.9797)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 79:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 79\n",
      "[PT] Epoch 80:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.5393 (0.5393)  orig_norm: 2.9891 (2.9891)  iter: 0.2491s  data: 0.0543s\n",
      "[PT] Epoch 80:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5371 (0.5376)  orig_norm: 2.9911 (2.9860)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 80:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 80\n",
      "[PT] Epoch 81:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5426 (0.5426)  orig_norm: 3.0069 (3.0069)  iter: 0.2553s  data: 0.0612s\n",
      "[PT] Epoch 81:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5341 (0.5343)  orig_norm: 2.9549 (2.9890)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 81:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 81\n",
      "[PT] Epoch 82:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5282 (0.5282)  orig_norm: 3.0067 (3.0067)  iter: 0.2514s  data: 0.0592s\n",
      "[PT] Epoch 82:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5311 (0.5312)  orig_norm: 2.9983 (2.9830)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 82:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 82\n",
      "[PT] Epoch 83:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.5332 (0.5332)  orig_norm: 3.0132 (3.0132)  iter: 0.2465s  data: 0.0543s\n",
      "[PT] Epoch 83:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5250 (0.5270)  orig_norm: 2.9947 (2.9956)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 83:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 83\n",
      "[PT] Epoch 84:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5221 (0.5221)  orig_norm: 3.0116 (3.0116)  iter: 0.2569s  data: 0.0618s\n",
      "[PT] Epoch 84:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5220 (0.5237)  orig_norm: 2.9854 (2.9868)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 84:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 84\n",
      "[PT] Epoch 85:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5202 (0.5202)  orig_norm: 3.0130 (3.0130)  iter: 0.2593s  data: 0.0643s\n",
      "[PT] Epoch 85:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5187 (0.5197)  orig_norm: 2.9825 (2.9847)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 85:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 85\n",
      "[PT] Epoch 86:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5131 (0.5131)  orig_norm: 2.9845 (2.9845)  iter: 0.2592s  data: 0.0592s\n",
      "[PT] Epoch 86:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5161 (0.5165)  orig_norm: 2.9655 (2.9848)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 86:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 86\n",
      "[PT] Epoch 87:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5111 (0.5111)  orig_norm: 3.0345 (3.0345)  iter: 0.2576s  data: 0.0637s\n",
      "[PT] Epoch 87:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5120 (0.5126)  orig_norm: 3.0094 (2.9957)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 87:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 87\n",
      "[PT] Epoch 88:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5175 (0.5175)  orig_norm: 2.9389 (2.9389)  iter: 0.2587s  data: 0.0608s\n",
      "[PT] Epoch 88:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5089 (0.5116)  orig_norm: 2.9879 (2.9832)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 88:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 88\n",
      "[PT] Epoch 89:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5126 (0.5126)  orig_norm: 2.9724 (2.9724)  iter: 0.2571s  data: 0.0648s\n",
      "[PT] Epoch 89:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5039 (0.5074)  orig_norm: 2.9882 (2.9919)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 89:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 89\n",
      "[PT] Epoch 90:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4991 (0.4991)  orig_norm: 3.0582 (3.0582)  iter: 0.2538s  data: 0.0578s\n",
      "[PT] Epoch 90:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.5036 (0.5038)  orig_norm: 2.9818 (2.9911)  iter: 0.1838s  data: 0.0001s\n",
      "[PT] Epoch 90:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 90\n",
      "[PT] Epoch 91:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5047 (0.5047)  orig_norm: 2.9963 (2.9963)  iter: 0.2554s  data: 0.0574s\n",
      "[PT] Epoch 91:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4989 (0.5004)  orig_norm: 2.9850 (2.9863)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 91:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 91\n",
      "[PT] Epoch 92:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5020 (0.5020)  orig_norm: 2.9364 (2.9364)  iter: 0.2528s  data: 0.0593s\n",
      "[PT] Epoch 92:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4949 (0.4982)  orig_norm: 2.9999 (2.9795)  iter: 0.1827s  data: 0.0002s\n",
      "[PT] Epoch 92:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 92\n",
      "[PT] Epoch 93:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.5011 (0.5011)  orig_norm: 2.9297 (2.9297)  iter: 0.2492s  data: 0.0547s\n",
      "[PT] Epoch 93:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4913 (0.4932)  orig_norm: 2.9995 (2.9941)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 93:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 93\n",
      "[PT] Epoch 94:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.5090 (0.5090)  orig_norm: 2.9561 (2.9561)  iter: 0.2539s  data: 0.0595s\n",
      "[PT] Epoch 94:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4882 (0.4916)  orig_norm: 2.9795 (2.9832)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 94:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 94\n",
      "[PT] Epoch 95:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4821 (0.4821)  orig_norm: 3.0178 (3.0178)  iter: 0.2506s  data: 0.0570s\n",
      "[PT] Epoch 95:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4900 (0.4890)  orig_norm: 2.9886 (2.9885)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 95:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 95\n",
      "[PT] Epoch 96:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4834 (0.4834)  orig_norm: 3.0271 (3.0271)  iter: 0.2580s  data: 0.0632s\n",
      "[PT] Epoch 96:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4833 (0.4851)  orig_norm: 2.9915 (2.9945)  iter: 0.1852s  data: 0.0002s\n",
      "[PT] Epoch 96:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 96\n",
      "[PT] Epoch 97:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4841 (0.4841)  orig_norm: 2.9872 (2.9872)  iter: 0.2545s  data: 0.0586s\n",
      "[PT] Epoch 97:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4804 (0.4829)  orig_norm: 2.9858 (2.9794)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 97:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 97\n",
      "[PT] Epoch 98:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4777 (0.4777)  orig_norm: 2.9888 (2.9888)  iter: 0.2584s  data: 0.0619s\n",
      "[PT] Epoch 98:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4787 (0.4794)  orig_norm: 2.9677 (2.9863)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 98:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 98\n",
      "[PT] Epoch 99:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4754 (0.4754)  orig_norm: 2.9573 (2.9573)  iter: 0.2609s  data: 0.0660s\n",
      "[PT] Epoch 99:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4765 (0.4776)  orig_norm: 2.9925 (2.9772)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 99:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 99\n",
      "[PT] Epoch 100:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4864 (0.4864)  orig_norm: 2.9530 (2.9530)  iter: 0.2605s  data: 0.0639s\n",
      "[PT] Epoch 100:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4715 (0.4733)  orig_norm: 2.9988 (2.9880)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 100:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 100\n",
      "[PT] Epoch 101:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.4693 (0.4693)  orig_norm: 3.0423 (3.0423)  iter: 0.2475s  data: 0.0541s\n",
      "[PT] Epoch 101:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4710 (0.4711)  orig_norm: 2.9654 (2.9778)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 101:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 101\n",
      "[PT] Epoch 102:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4681 (0.4681)  orig_norm: 2.9887 (2.9887)  iter: 0.2527s  data: 0.0609s\n",
      "[PT] Epoch 102:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4678 (0.4680)  orig_norm: 2.9662 (2.9831)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 102:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 102\n",
      "[PT] Epoch 103:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.4677 (0.4677)  orig_norm: 2.9761 (2.9761)  iter: 0.2719s  data: 0.0749s\n",
      "[PT] Epoch 103:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4644 (0.4646)  orig_norm: 2.9766 (2.9724)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 103:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 103\n",
      "[PT] Epoch 104:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.4619 (0.4619)  orig_norm: 2.9367 (2.9367)  iter: 0.2494s  data: 0.0581s\n",
      "[PT] Epoch 104:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4616 (0.4622)  orig_norm: 2.9552 (2.9703)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 104:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 104\n",
      "[PT] Epoch 105:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4587 (0.4587)  orig_norm: 2.9438 (2.9438)  iter: 0.2581s  data: 0.0650s\n",
      "[PT] Epoch 105:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4576 (0.4595)  orig_norm: 2.9829 (2.9710)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 105:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 105\n",
      "[PT] Epoch 106:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4742 (0.4742)  orig_norm: 2.9016 (2.9016)  iter: 0.2504s  data: 0.0551s\n",
      "[PT] Epoch 106:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4545 (0.4565)  orig_norm: 2.9984 (2.9730)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 106:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 106\n",
      "[PT] Epoch 107:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4469 (0.4469)  orig_norm: 2.9858 (2.9858)  iter: 0.2634s  data: 0.0668s\n",
      "[PT] Epoch 107:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4532 (0.4545)  orig_norm: 3.0060 (2.9786)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 107:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 107\n",
      "[PT] Epoch 108:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4461 (0.4461)  orig_norm: 3.0081 (3.0081)  iter: 0.2647s  data: 0.0667s\n",
      "[PT] Epoch 108:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4513 (0.4520)  orig_norm: 2.9528 (2.9652)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 108:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 108\n",
      "[PT] Epoch 109:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4359 (0.4359)  orig_norm: 2.9665 (2.9665)  iter: 0.2559s  data: 0.0598s\n",
      "[PT] Epoch 109:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4484 (0.4476)  orig_norm: 2.9935 (2.9800)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 109:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 109\n",
      "[PT] Epoch 110:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4358 (0.4358)  orig_norm: 3.0044 (3.0044)  iter: 0.2554s  data: 0.0633s\n",
      "[PT] Epoch 110:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4457 (0.4468)  orig_norm: 2.9490 (2.9627)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 110:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 110\n",
      "[PT] Epoch 111:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4464 (0.4464)  orig_norm: 2.9503 (2.9503)  iter: 0.2648s  data: 0.0712s\n",
      "[PT] Epoch 111:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4418 (0.4435)  orig_norm: 2.9738 (2.9629)  iter: 0.1853s  data: 0.0002s\n",
      "[PT] Epoch 111:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 111\n",
      "[PT] Epoch 112:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4370 (0.4370)  orig_norm: 3.0006 (3.0006)  iter: 0.2649s  data: 0.0696s\n",
      "[PT] Epoch 112:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4395 (0.4407)  orig_norm: 2.9532 (2.9511)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 112:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 112\n",
      "[PT] Epoch 113:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4428 (0.4428)  orig_norm: 2.9567 (2.9567)  iter: 0.2644s  data: 0.0671s\n",
      "[PT] Epoch 113:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4357 (0.4373)  orig_norm: 2.9542 (2.9530)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 113:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 113\n",
      "[PT] Epoch 114:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4431 (0.4431)  orig_norm: 2.8608 (2.8608)  iter: 0.2600s  data: 0.0672s\n",
      "[PT] Epoch 114:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4347 (0.4363)  orig_norm: 2.9482 (2.9394)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 114:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 114\n",
      "[PT] Epoch 115:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4424 (0.4424)  orig_norm: 2.9629 (2.9629)  iter: 0.2530s  data: 0.0610s\n",
      "[PT] Epoch 115:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4318 (0.4328)  orig_norm: 2.9605 (2.9472)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 115:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 115\n",
      "[PT] Epoch 116:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.4274 (0.4274)  orig_norm: 2.9589 (2.9589)  iter: 0.2461s  data: 0.0528s\n",
      "[PT] Epoch 116:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4301 (0.4311)  orig_norm: 2.9455 (2.9377)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 116:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 116\n",
      "[PT] Epoch 117:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4341 (0.4341)  orig_norm: 2.9164 (2.9164)  iter: 0.2574s  data: 0.0610s\n",
      "[PT] Epoch 117:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4255 (0.4266)  orig_norm: 2.9322 (2.9452)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 117:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 117\n",
      "[PT] Epoch 118:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4248 (0.4248)  orig_norm: 2.9737 (2.9737)  iter: 0.2545s  data: 0.0604s\n",
      "[PT] Epoch 118:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4253 (0.4258)  orig_norm: 2.9280 (2.9301)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 118:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 118\n",
      "[PT] Epoch 119:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4296 (0.4296)  orig_norm: 2.9292 (2.9292)  iter: 0.2539s  data: 0.0644s\n",
      "[PT] Epoch 119:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4178 (0.4217)  orig_norm: 2.9426 (2.9422)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 119:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 119\n",
      "[PT] Epoch 120:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4224 (0.4224)  orig_norm: 2.9559 (2.9559)  iter: 0.2567s  data: 0.0628s\n",
      "[PT] Epoch 120:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4172 (0.4202)  orig_norm: 2.9348 (2.9331)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 120:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 120\n",
      "[PT] Epoch 121:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.4186 (0.4186)  orig_norm: 2.9254 (2.9254)  iter: 0.2626s  data: 0.0671s\n",
      "[PT] Epoch 121:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4142 (0.4175)  orig_norm: 2.9225 (2.9248)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 121:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 121\n",
      "[PT] Epoch 122:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4157 (0.4157)  orig_norm: 2.8954 (2.8954)  iter: 0.2597s  data: 0.0652s\n",
      "[PT] Epoch 122:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4129 (0.4162)  orig_norm: 2.9216 (2.9227)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 122:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 122\n",
      "[PT] Epoch 123:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4166 (0.4166)  orig_norm: 2.9139 (2.9139)  iter: 0.2577s  data: 0.0626s\n",
      "[PT] Epoch 123:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4086 (0.4120)  orig_norm: 2.9326 (2.9302)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 123:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 123\n",
      "[PT] Epoch 124:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4210 (0.4210)  orig_norm: 2.8338 (2.8338)  iter: 0.2582s  data: 0.0634s\n",
      "[PT] Epoch 124:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4092 (0.4102)  orig_norm: 2.9056 (2.9138)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 124:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 124\n",
      "[PT] Epoch 125:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4162 (0.4162)  orig_norm: 2.8424 (2.8424)  iter: 0.2518s  data: 0.0583s\n",
      "[PT] Epoch 125:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4097 (0.4092)  orig_norm: 2.8781 (2.9033)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 125:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 125\n",
      "[PT] Epoch 126:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4084 (0.4084)  orig_norm: 2.8951 (2.8951)  iter: 0.2561s  data: 0.0578s\n",
      "[PT] Epoch 126:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4050 (0.4052)  orig_norm: 2.9218 (2.9093)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 126:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 126\n",
      "[PT] Epoch 127:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4013 (0.4013)  orig_norm: 2.9138 (2.9138)  iter: 0.2591s  data: 0.0657s\n",
      "[PT] Epoch 127:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4032 (0.4032)  orig_norm: 2.8813 (2.9081)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 127:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 127\n",
      "[PT] Epoch 128:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4132 (0.4132)  orig_norm: 2.8267 (2.8267)  iter: 0.2559s  data: 0.0639s\n",
      "[PT] Epoch 128:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.4013 (0.4020)  orig_norm: 2.8785 (2.8928)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 128:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 128\n",
      "[PT] Epoch 129:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.4109 (0.4109)  orig_norm: 2.8305 (2.8305)  iter: 0.2522s  data: 0.0577s\n",
      "[PT] Epoch 129:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3985 (0.3990)  orig_norm: 2.8660 (2.8842)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 129:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 129\n",
      "[PT] Epoch 130:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3995 (0.3995)  orig_norm: 2.9096 (2.9096)  iter: 0.2463s  data: 0.0559s\n",
      "[PT] Epoch 130:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3946 (0.3968)  orig_norm: 2.8787 (2.8806)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 130:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 130\n",
      "[PT] Epoch 131:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.3915 (0.3915)  orig_norm: 2.9148 (2.9148)  iter: 0.2614s  data: 0.0670s\n",
      "[PT] Epoch 131:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3927 (0.3950)  orig_norm: 2.8840 (2.8800)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 131:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 131\n",
      "[PT] Epoch 132:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3856 (0.3856)  orig_norm: 2.9636 (2.9636)  iter: 0.2513s  data: 0.0562s\n",
      "[PT] Epoch 132:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3907 (0.3911)  orig_norm: 2.8896 (2.8961)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 132:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 132\n",
      "[PT] Epoch 133:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3919 (0.3919)  orig_norm: 2.9396 (2.9396)  iter: 0.2539s  data: 0.0566s\n",
      "[PT] Epoch 133:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3880 (0.3898)  orig_norm: 2.8575 (2.8750)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 133:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 133\n",
      "[PT] Epoch 134:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3854 (0.3854)  orig_norm: 2.9540 (2.9540)  iter: 0.2588s  data: 0.0640s\n",
      "[PT] Epoch 134:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3858 (0.3872)  orig_norm: 2.8899 (2.8844)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 134:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 134\n",
      "[PT] Epoch 135:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3858 (0.3858)  orig_norm: 2.8589 (2.8589)  iter: 0.2589s  data: 0.0642s\n",
      "[PT] Epoch 135:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3843 (0.3848)  orig_norm: 2.8776 (2.8758)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 135:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 135\n",
      "[PT] Epoch 136:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3831 (0.3831)  orig_norm: 2.9690 (2.9690)  iter: 0.2573s  data: 0.0630s\n",
      "[PT] Epoch 136:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3830 (0.3824)  orig_norm: 2.8507 (2.8725)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 136:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 136\n",
      "[PT] Epoch 137:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3842 (0.3842)  orig_norm: 2.7743 (2.7743)  iter: 0.2558s  data: 0.0612s\n",
      "[PT] Epoch 137:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3786 (0.3799)  orig_norm: 2.8692 (2.8655)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 137:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 137\n",
      "[PT] Epoch 138:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3840 (0.3840)  orig_norm: 2.8208 (2.8208)  iter: 0.2596s  data: 0.0606s\n",
      "[PT] Epoch 138:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3760 (0.3778)  orig_norm: 2.8666 (2.8618)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 138:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 138\n",
      "[PT] Epoch 139:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.3730 (0.3730)  orig_norm: 2.8982 (2.8982)  iter: 0.2685s  data: 0.0723s\n",
      "[PT] Epoch 139:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3760 (0.3760)  orig_norm: 2.8460 (2.8498)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 139:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 139\n",
      "[PT] Epoch 140:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3791 (0.3791)  orig_norm: 2.8303 (2.8303)  iter: 0.2530s  data: 0.0596s\n",
      "[PT] Epoch 140:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3726 (0.3729)  orig_norm: 2.8448 (2.8539)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 140:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 140\n",
      "[PT] Epoch 141:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3671 (0.3671)  orig_norm: 2.8276 (2.8276)  iter: 0.2474s  data: 0.0582s\n",
      "[PT] Epoch 141:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3696 (0.3718)  orig_norm: 2.8400 (2.8377)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 141:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 141\n",
      "[PT] Epoch 142:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3758 (0.3758)  orig_norm: 2.8423 (2.8423)  iter: 0.2511s  data: 0.0596s\n",
      "[PT] Epoch 142:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3707 (0.3697)  orig_norm: 2.8222 (2.8385)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 142:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 142\n",
      "[PT] Epoch 143:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3706 (0.3706)  orig_norm: 2.7583 (2.7583)  iter: 0.2585s  data: 0.0616s\n",
      "[PT] Epoch 143:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3682 (0.3683)  orig_norm: 2.8390 (2.8230)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 143:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 143\n",
      "[PT] Epoch 144:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3637 (0.3637)  orig_norm: 2.8100 (2.8100)  iter: 0.2572s  data: 0.0633s\n",
      "[PT] Epoch 144:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3667 (0.3647)  orig_norm: 2.8078 (2.8171)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 144:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 144\n",
      "[PT] Epoch 145:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3589 (0.3589)  orig_norm: 2.7704 (2.7704)  iter: 0.2594s  data: 0.0650s\n",
      "[PT] Epoch 145:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3603 (0.3618)  orig_norm: 2.8120 (2.8286)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 145:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 145\n",
      "[PT] Epoch 146:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.3690 (0.3690)  orig_norm: 2.8256 (2.8256)  iter: 0.2646s  data: 0.0673s\n",
      "[PT] Epoch 146:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3599 (0.3607)  orig_norm: 2.8097 (2.8088)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 146:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 146\n",
      "[PT] Epoch 147:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3547 (0.3547)  orig_norm: 2.8019 (2.8019)  iter: 0.2499s  data: 0.0535s\n",
      "[PT] Epoch 147:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3576 (0.3587)  orig_norm: 2.7933 (2.8195)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 147:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 147\n",
      "[PT] Epoch 148:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3595 (0.3595)  orig_norm: 2.7730 (2.7730)  iter: 0.2558s  data: 0.0610s\n",
      "[PT] Epoch 148:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3534 (0.3567)  orig_norm: 2.8029 (2.8033)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 148:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 148\n",
      "[PT] Epoch 149:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3573 (0.3573)  orig_norm: 2.7998 (2.7998)  iter: 0.2579s  data: 0.0657s\n",
      "[PT] Epoch 149:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3506 (0.3527)  orig_norm: 2.8258 (2.8177)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 149:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 149\n",
      "[PT] Epoch 150:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.3397 (0.3397)  orig_norm: 2.9027 (2.9027)  iter: 0.2619s  data: 0.0674s\n",
      "[PT] Epoch 150:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3512 (0.3521)  orig_norm: 2.8008 (2.7953)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 150:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 150\n",
      "[PT] Epoch 151:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3554 (0.3554)  orig_norm: 2.7574 (2.7574)  iter: 0.2462s  data: 0.0506s\n",
      "[PT] Epoch 151:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3461 (0.3496)  orig_norm: 2.7828 (2.7794)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 151:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 151\n",
      "[PT] Epoch 152:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3405 (0.3405)  orig_norm: 2.8204 (2.8204)  iter: 0.2570s  data: 0.0617s\n",
      "[PT] Epoch 152:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3485 (0.3474)  orig_norm: 2.7688 (2.7854)  iter: 0.1838s  data: 0.0001s\n",
      "[PT] Epoch 152:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 152\n",
      "[PT] Epoch 153:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3508 (0.3508)  orig_norm: 2.8083 (2.8083)  iter: 0.2489s  data: 0.0573s\n",
      "[PT] Epoch 153:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3452 (0.3459)  orig_norm: 2.7797 (2.7759)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 153:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 153\n",
      "[PT] Epoch 154:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3411 (0.3411)  orig_norm: 2.7118 (2.7118)  iter: 0.2586s  data: 0.0656s\n",
      "[PT] Epoch 154:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3412 (0.3432)  orig_norm: 2.7775 (2.7730)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 154:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 154\n",
      "[PT] Epoch 155:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3521 (0.3521)  orig_norm: 2.7634 (2.7634)  iter: 0.2434s  data: 0.0503s\n",
      "[PT] Epoch 155:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3378 (0.3425)  orig_norm: 2.7626 (2.7653)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 155:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 155\n",
      "[PT] Epoch 156:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3389 (0.3389)  orig_norm: 2.7554 (2.7554)  iter: 0.2503s  data: 0.0581s\n",
      "[PT] Epoch 156:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3378 (0.3404)  orig_norm: 2.7465 (2.7558)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 156:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 156\n",
      "[PT] Epoch 157:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3424 (0.3424)  orig_norm: 2.6975 (2.6975)  iter: 0.2608s  data: 0.0678s\n",
      "[PT] Epoch 157:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3330 (0.3375)  orig_norm: 2.7297 (2.7566)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 157:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 157\n",
      "[PT] Epoch 158:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3329 (0.3329)  orig_norm: 2.7855 (2.7855)  iter: 0.2561s  data: 0.0610s\n",
      "[PT] Epoch 158:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3359 (0.3361)  orig_norm: 2.7287 (2.7396)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 158:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 158\n",
      "[PT] Epoch 159:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3324 (0.3324)  orig_norm: 2.7565 (2.7565)  iter: 0.2580s  data: 0.0633s\n",
      "[PT] Epoch 159:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3333 (0.3339)  orig_norm: 2.7158 (2.7320)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 159:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 159\n",
      "[PT] Epoch 160:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3271 (0.3271)  orig_norm: 2.7906 (2.7906)  iter: 0.2449s  data: 0.0534s\n",
      "[PT] Epoch 160:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3281 (0.3302)  orig_norm: 2.7395 (2.7407)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 160:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 160\n",
      "[PT] Epoch 161:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3288 (0.3288)  orig_norm: 2.7036 (2.7036)  iter: 0.2591s  data: 0.0655s\n",
      "[PT] Epoch 161:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3298 (0.3294)  orig_norm: 2.7252 (2.7323)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 161:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 161\n",
      "[PT] Epoch 162:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3269 (0.3269)  orig_norm: 2.7879 (2.7879)  iter: 0.2596s  data: 0.0668s\n",
      "[PT] Epoch 162:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3289 (0.3291)  orig_norm: 2.7203 (2.7186)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 162:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 162\n",
      "[PT] Epoch 163:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3183 (0.3183)  orig_norm: 2.7370 (2.7370)  iter: 0.2527s  data: 0.0596s\n",
      "[PT] Epoch 163:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3251 (0.3250)  orig_norm: 2.6889 (2.7164)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 163:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 163\n",
      "[PT] Epoch 164:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.3285 (0.3285)  orig_norm: 2.6903 (2.6903)  iter: 0.2620s  data: 0.0636s\n",
      "[PT] Epoch 164:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3221 (0.3238)  orig_norm: 2.6865 (2.6976)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 164:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 164\n",
      "[PT] Epoch 165:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3237 (0.3237)  orig_norm: 2.7587 (2.7587)  iter: 0.2529s  data: 0.0611s\n",
      "[PT] Epoch 165:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3165 (0.3204)  orig_norm: 2.7109 (2.7067)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 165:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 165\n",
      "[PT] Epoch 166:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3162 (0.3162)  orig_norm: 2.7142 (2.7142)  iter: 0.2516s  data: 0.0577s\n",
      "[PT] Epoch 166:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3171 (0.3201)  orig_norm: 2.6788 (2.6946)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 166:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 166\n",
      "[PT] Epoch 167:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3258 (0.3258)  orig_norm: 2.6089 (2.6089)  iter: 0.2539s  data: 0.0586s\n",
      "[PT] Epoch 167:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3157 (0.3183)  orig_norm: 2.6844 (2.6908)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 167:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 167\n",
      "[PT] Epoch 168:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3234 (0.3234)  orig_norm: 2.7056 (2.7056)  iter: 0.2571s  data: 0.0643s\n",
      "[PT] Epoch 168:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3126 (0.3143)  orig_norm: 2.6940 (2.6910)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 168:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 168\n",
      "[PT] Epoch 169:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3102 (0.3102)  orig_norm: 2.6985 (2.6985)  iter: 0.2525s  data: 0.0602s\n",
      "[PT] Epoch 169:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3115 (0.3128)  orig_norm: 2.6836 (2.6865)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 169:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 169\n",
      "[PT] Epoch 170:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3002 (0.3002)  orig_norm: 2.7611 (2.7611)  iter: 0.2511s  data: 0.0571s\n",
      "[PT] Epoch 170:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3128 (0.3127)  orig_norm: 2.6423 (2.6641)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 170:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 170\n",
      "[PT] Epoch 171:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3255 (0.3255)  orig_norm: 2.5737 (2.5737)  iter: 0.2516s  data: 0.0580s\n",
      "[PT] Epoch 171:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3080 (0.3092)  orig_norm: 2.6740 (2.6655)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 171:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 171\n",
      "[PT] Epoch 172:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.3176 (0.3176)  orig_norm: 2.5585 (2.5585)  iter: 0.2591s  data: 0.0669s\n",
      "[PT] Epoch 172:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3075 (0.3078)  orig_norm: 2.6484 (2.6694)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 172:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 172\n",
      "[PT] Epoch 173:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3135 (0.3135)  orig_norm: 2.5818 (2.5818)  iter: 0.2450s  data: 0.0544s\n",
      "[PT] Epoch 173:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3065 (0.3065)  orig_norm: 2.6262 (2.6494)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 173:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 173\n",
      "[PT] Epoch 174:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2976 (0.2976)  orig_norm: 2.6508 (2.6508)  iter: 0.2483s  data: 0.0583s\n",
      "[PT] Epoch 174:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3048 (0.3045)  orig_norm: 2.6261 (2.6446)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 174:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 174\n",
      "[PT] Epoch 175:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2994 (0.2994)  orig_norm: 2.6598 (2.6598)  iter: 0.2581s  data: 0.0656s\n",
      "[PT] Epoch 175:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3005 (0.3019)  orig_norm: 2.6421 (2.6458)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 175:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 175\n",
      "[PT] Epoch 176:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3016 (0.3016)  orig_norm: 2.6384 (2.6384)  iter: 0.2450s  data: 0.0524s\n",
      "[PT] Epoch 176:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2988 (0.3010)  orig_norm: 2.6308 (2.6262)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 176:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 176\n",
      "[PT] Epoch 177:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3198 (0.3198)  orig_norm: 2.5588 (2.5588)  iter: 0.2482s  data: 0.0559s\n",
      "[PT] Epoch 177:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.3009 (0.2990)  orig_norm: 2.6058 (2.6206)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 177:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 177\n",
      "[PT] Epoch 178:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.3010 (0.3010)  orig_norm: 2.7000 (2.7000)  iter: 0.2465s  data: 0.0545s\n",
      "[PT] Epoch 178:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2948 (0.2952)  orig_norm: 2.6284 (2.6307)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 178:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 178\n",
      "[PT] Epoch 179:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2908 (0.2908)  orig_norm: 2.6265 (2.6265)  iter: 0.2424s  data: 0.0504s\n",
      "[PT] Epoch 179:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2940 (0.2947)  orig_norm: 2.5990 (2.6067)  iter: 0.1843s  data: 0.0002s\n",
      "[PT] Epoch 179:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 179\n",
      "[PT] Epoch 180:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2978 (0.2978)  orig_norm: 2.5034 (2.5034)  iter: 0.2608s  data: 0.0658s\n",
      "[PT] Epoch 180:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2934 (0.2939)  orig_norm: 2.5986 (2.6005)  iter: 0.1820s  data: 0.0002s\n",
      "[PT] Epoch 180:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 180\n",
      "[PT] Epoch 181:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2911 (0.2911)  orig_norm: 2.5749 (2.5749)  iter: 0.2505s  data: 0.0562s\n",
      "[PT] Epoch 181:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2872 (0.2907)  orig_norm: 2.6136 (2.5918)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 181:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 181\n",
      "[PT] Epoch 182:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2928 (0.2928)  orig_norm: 2.6029 (2.6029)  iter: 0.2545s  data: 0.0591s\n",
      "[PT] Epoch 182:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2895 (0.2901)  orig_norm: 2.5672 (2.5789)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 182:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 182\n",
      "[PT] Epoch 183:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2845 (0.2845)  orig_norm: 2.6029 (2.6029)  iter: 0.2626s  data: 0.0707s\n",
      "[PT] Epoch 183:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2838 (0.2857)  orig_norm: 2.5836 (2.5931)  iter: 0.1866s  data: 0.0002s\n",
      "[PT] Epoch 183:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 183\n",
      "[PT] Epoch 184:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2907 (0.2907)  orig_norm: 2.5719 (2.5719)  iter: 0.2678s  data: 0.0714s\n",
      "[PT] Epoch 184:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2826 (0.2859)  orig_norm: 2.5679 (2.5662)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 184:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 184\n",
      "[PT] Epoch 185:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2789 (0.2789)  orig_norm: 2.5968 (2.5968)  iter: 0.2492s  data: 0.0569s\n",
      "[PT] Epoch 185:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2843 (0.2841)  orig_norm: 2.5513 (2.5597)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 185:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 185\n",
      "[PT] Epoch 186:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2733 (0.2733)  orig_norm: 2.5837 (2.5837)  iter: 0.2520s  data: 0.0576s\n",
      "[PT] Epoch 186:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2827 (0.2825)  orig_norm: 2.5633 (2.5620)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 186:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 186\n",
      "[PT] Epoch 187:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2839 (0.2839)  orig_norm: 2.5379 (2.5379)  iter: 0.2591s  data: 0.0637s\n",
      "[PT] Epoch 187:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2780 (0.2802)  orig_norm: 2.5794 (2.5536)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 187:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 187\n",
      "[PT] Epoch 188:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2879 (0.2879)  orig_norm: 2.4742 (2.4742)  iter: 0.2563s  data: 0.0603s\n",
      "[PT] Epoch 188:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2810 (0.2793)  orig_norm: 2.5100 (2.5268)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 188:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 188\n",
      "[PT] Epoch 189:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2800 (0.2800)  orig_norm: 2.5565 (2.5565)  iter: 0.2585s  data: 0.0647s\n",
      "[PT] Epoch 189:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2725 (0.2779)  orig_norm: 2.5449 (2.5268)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 189:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 189\n",
      "[PT] Epoch 190:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2813 (0.2813)  orig_norm: 2.4857 (2.4857)  iter: 0.2449s  data: 0.0527s\n",
      "[PT] Epoch 190:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2742 (0.2762)  orig_norm: 2.5090 (2.5146)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 190:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 190\n",
      "[PT] Epoch 191:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2743 (0.2743)  orig_norm: 2.5350 (2.5350)  iter: 0.2591s  data: 0.0633s\n",
      "[PT] Epoch 191:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2709 (0.2736)  orig_norm: 2.4975 (2.5168)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 191:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 191\n",
      "[PT] Epoch 192:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2746 (0.2746)  orig_norm: 2.5455 (2.5455)  iter: 0.2480s  data: 0.0547s\n",
      "[PT] Epoch 192:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2680 (0.2715)  orig_norm: 2.4905 (2.5101)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 192:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 192\n",
      "[PT] Epoch 193:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2673 (0.2673)  orig_norm: 2.5361 (2.5361)  iter: 0.2667s  data: 0.0726s\n",
      "[PT] Epoch 193:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2708 (0.2707)  orig_norm: 2.4904 (2.5025)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 193:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 193\n",
      "[PT] Epoch 194:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.2624 (0.2624)  orig_norm: 2.5399 (2.5399)  iter: 0.2810s  data: 0.0789s\n",
      "[PT] Epoch 194:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2685 (0.2691)  orig_norm: 2.4876 (2.4804)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 194:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 194\n",
      "[PT] Epoch 195:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2622 (0.2622)  orig_norm: 2.5582 (2.5582)  iter: 0.2527s  data: 0.0580s\n",
      "[PT] Epoch 195:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2665 (0.2649)  orig_norm: 2.4772 (2.4932)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 195:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 195\n",
      "[PT] Epoch 196:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2571 (0.2571)  orig_norm: 2.5777 (2.5777)  iter: 0.2518s  data: 0.0569s\n",
      "[PT] Epoch 196:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2656 (0.2649)  orig_norm: 2.4596 (2.4818)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 196:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 196\n",
      "[PT] Epoch 197:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2581 (0.2581)  orig_norm: 2.4816 (2.4816)  iter: 0.2575s  data: 0.0635s\n",
      "[PT] Epoch 197:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2648 (0.2650)  orig_norm: 2.4534 (2.4654)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 197:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 197\n",
      "[PT] Epoch 198:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2646 (0.2646)  orig_norm: 2.4235 (2.4235)  iter: 0.2530s  data: 0.0604s\n",
      "[PT] Epoch 198:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2590 (0.2608)  orig_norm: 2.4667 (2.4608)  iter: 0.1855s  data: 0.0002s\n",
      "[PT] Epoch 198:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 198\n",
      "[PT] Epoch 199:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2653 (0.2653)  orig_norm: 2.4481 (2.4481)  iter: 0.2551s  data: 0.0620s\n",
      "[PT] Epoch 199:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2571 (0.2592)  orig_norm: 2.4450 (2.4526)  iter: 0.1828s  data: 0.0002s\n",
      "[PT] Epoch 199:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 199\n",
      "[PT] Epoch 200:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2497 (0.2497)  orig_norm: 2.4761 (2.4761)  iter: 0.2556s  data: 0.0643s\n",
      "[PT] Epoch 200:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2555 (0.2575)  orig_norm: 2.4540 (2.4601)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 200:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 200\n",
      "[PT] Epoch 201:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2605 (0.2605)  orig_norm: 2.4624 (2.4624)  iter: 0.2579s  data: 0.0673s\n",
      "[PT] Epoch 201:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2528 (0.2576)  orig_norm: 2.4351 (2.4347)  iter: 0.1839s  data: 0.0002s\n",
      "[PT] Epoch 201:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 201\n",
      "[PT] Epoch 202:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2531 (0.2531)  orig_norm: 2.3963 (2.3963)  iter: 0.2697s  data: 0.0720s\n",
      "[PT] Epoch 202:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2544 (0.2558)  orig_norm: 2.4208 (2.4199)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 202:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 202\n",
      "[PT] Epoch 203:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2599 (0.2599)  orig_norm: 2.4469 (2.4469)  iter: 0.2429s  data: 0.0499s\n",
      "[PT] Epoch 203:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2501 (0.2521)  orig_norm: 2.4378 (2.4397)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 203:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 203\n",
      "[PT] Epoch 204:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2592 (0.2592)  orig_norm: 2.4186 (2.4186)  iter: 0.2612s  data: 0.0665s\n",
      "[PT] Epoch 204:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2518 (0.2538)  orig_norm: 2.3843 (2.3980)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 204:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 204\n",
      "[PT] Epoch 205:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2435 (0.2435)  orig_norm: 2.4102 (2.4102)  iter: 0.2591s  data: 0.0628s\n",
      "[PT] Epoch 205:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2485 (0.2515)  orig_norm: 2.4156 (2.4055)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 205:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 205\n",
      "[PT] Epoch 206:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2398 (0.2398)  orig_norm: 2.4215 (2.4215)  iter: 0.2509s  data: 0.0560s\n",
      "[PT] Epoch 206:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2447 (0.2482)  orig_norm: 2.3917 (2.3971)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 206:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 206\n",
      "[PT] Epoch 207:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2369 (0.2369)  orig_norm: 2.4691 (2.4691)  iter: 0.2416s  data: 0.0500s\n",
      "[PT] Epoch 207:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2456 (0.2470)  orig_norm: 2.3880 (2.3899)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 207:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 207\n",
      "[PT] Epoch 208:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2491 (0.2491)  orig_norm: 2.3617 (2.3617)  iter: 0.2562s  data: 0.0610s\n",
      "[PT] Epoch 208:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2456 (0.2450)  orig_norm: 2.3417 (2.3665)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 208:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 208\n",
      "[PT] Epoch 209:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2344 (0.2344)  orig_norm: 2.4373 (2.4373)  iter: 0.2538s  data: 0.0587s\n",
      "[PT] Epoch 209:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2425 (0.2437)  orig_norm: 2.3513 (2.3593)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 209:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 209\n",
      "[PT] Epoch 210:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2315 (0.2315)  orig_norm: 2.3914 (2.3914)  iter: 0.2506s  data: 0.0578s\n",
      "[PT] Epoch 210:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2422 (0.2408)  orig_norm: 2.3511 (2.3620)  iter: 0.1840s  data: 0.0002s\n",
      "[PT] Epoch 210:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 210\n",
      "[PT] Epoch 211:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2453 (0.2453)  orig_norm: 2.2775 (2.2775)  iter: 0.2572s  data: 0.0620s\n",
      "[PT] Epoch 211:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2386 (0.2408)  orig_norm: 2.3716 (2.3519)  iter: 0.1821s  data: 0.0002s\n",
      "[PT] Epoch 211:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 211\n",
      "[PT] Epoch 212:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2384 (0.2384)  orig_norm: 2.3841 (2.3841)  iter: 0.2538s  data: 0.0577s\n",
      "[PT] Epoch 212:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2382 (0.2391)  orig_norm: 2.3202 (2.3388)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 212:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 212\n",
      "[PT] Epoch 213:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2277 (0.2277)  orig_norm: 2.3779 (2.3779)  iter: 0.2516s  data: 0.0597s\n",
      "[PT] Epoch 213:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2343 (0.2358)  orig_norm: 2.3170 (2.3361)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 213:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 213\n",
      "[PT] Epoch 214:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2365 (0.2365)  orig_norm: 2.2747 (2.2747)  iter: 0.2583s  data: 0.0646s\n",
      "[PT] Epoch 214:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2301 (0.2346)  orig_norm: 2.3356 (2.3275)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 214:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 214\n",
      "[PT] Epoch 215:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2357 (0.2357)  orig_norm: 2.3655 (2.3655)  iter: 0.2594s  data: 0.0661s\n",
      "[PT] Epoch 215:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2325 (0.2336)  orig_norm: 2.3155 (2.3261)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 215:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 215\n",
      "[PT] Epoch 216:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2493 (0.2493)  orig_norm: 2.2252 (2.2252)  iter: 0.2601s  data: 0.0665s\n",
      "[PT] Epoch 216:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2294 (0.2326)  orig_norm: 2.3066 (2.3021)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 216:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 216\n",
      "[PT] Epoch 217:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2256 (0.2256)  orig_norm: 2.3763 (2.3763)  iter: 0.2548s  data: 0.0644s\n",
      "[PT] Epoch 217:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2302 (0.2316)  orig_norm: 2.2743 (2.2893)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 217:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 217\n",
      "[PT] Epoch 218:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2338 (0.2338)  orig_norm: 2.2810 (2.2810)  iter: 0.2614s  data: 0.0656s\n",
      "[PT] Epoch 218:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2287 (0.2297)  orig_norm: 2.2672 (2.2782)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 218:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 218\n",
      "[PT] Epoch 219:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2321 (0.2321)  orig_norm: 2.2509 (2.2509)  iter: 0.2558s  data: 0.0603s\n",
      "[PT] Epoch 219:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2244 (0.2281)  orig_norm: 2.2727 (2.2643)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 219:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 219\n",
      "[PT] Epoch 220:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2252 (0.2252)  orig_norm: 2.3120 (2.3120)  iter: 0.2558s  data: 0.0650s\n",
      "[PT] Epoch 220:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2243 (0.2253)  orig_norm: 2.2649 (2.2656)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 220:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 220\n",
      "[PT] Epoch 221:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2131 (0.2131)  orig_norm: 2.2700 (2.2700)  iter: 0.2606s  data: 0.0645s\n",
      "[PT] Epoch 221:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2243 (0.2245)  orig_norm: 2.2771 (2.2589)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 221:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 221\n",
      "[PT] Epoch 222:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2226 (0.2226)  orig_norm: 2.1814 (2.1814)  iter: 0.2676s  data: 0.0734s\n",
      "[PT] Epoch 222:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2199 (0.2223)  orig_norm: 2.2432 (2.2473)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 222:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 222\n",
      "[PT] Epoch 223:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2191 (0.2191)  orig_norm: 2.2654 (2.2654)  iter: 0.2506s  data: 0.0553s\n",
      "[PT] Epoch 223:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2226 (0.2232)  orig_norm: 2.2263 (2.2255)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 223:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 223\n",
      "[PT] Epoch 224:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2291 (0.2291)  orig_norm: 2.1299 (2.1299)  iter: 0.2425s  data: 0.0493s\n",
      "[PT] Epoch 224:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2201 (0.2195)  orig_norm: 2.2225 (2.2263)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 224:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 224\n",
      "[PT] Epoch 225:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2216 (0.2216)  orig_norm: 2.1960 (2.1960)  iter: 0.2586s  data: 0.0648s\n",
      "[PT] Epoch 225:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2146 (0.2199)  orig_norm: 2.2380 (2.2221)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 225:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 225\n",
      "[PT] Epoch 226:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2073 (0.2073)  orig_norm: 2.2510 (2.2510)  iter: 0.2511s  data: 0.0581s\n",
      "[PT] Epoch 226:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2156 (0.2175)  orig_norm: 2.2121 (2.2102)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 226:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 226\n",
      "[PT] Epoch 227:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2107 (0.2107)  orig_norm: 2.2401 (2.2401)  iter: 0.2657s  data: 0.0679s\n",
      "[PT] Epoch 227:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2151 (0.2163)  orig_norm: 2.1968 (2.2043)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 227:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 227\n",
      "[PT] Epoch 228:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2217 (0.2217)  orig_norm: 2.0973 (2.0973)  iter: 0.2503s  data: 0.0573s\n",
      "[PT] Epoch 228:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2156 (0.2157)  orig_norm: 2.1522 (2.1787)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 228:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 228\n",
      "[PT] Epoch 229:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2259 (0.2259)  orig_norm: 2.1144 (2.1144)  iter: 0.2556s  data: 0.0596s\n",
      "[PT] Epoch 229:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2121 (0.2142)  orig_norm: 2.1860 (2.1811)  iter: 0.1823s  data: 0.0002s\n",
      "[PT] Epoch 229:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 229\n",
      "[PT] Epoch 230:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2136 (0.2136)  orig_norm: 2.1569 (2.1569)  iter: 0.2698s  data: 0.0756s\n",
      "[PT] Epoch 230:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2106 (0.2120)  orig_norm: 2.1295 (2.1553)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 230:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 230\n",
      "[PT] Epoch 231:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2249 (0.2249)  orig_norm: 2.1067 (2.1067)  iter: 0.2555s  data: 0.0607s\n",
      "[PT] Epoch 231:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2092 (0.2104)  orig_norm: 2.1218 (2.1492)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 231:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 231\n",
      "[PT] Epoch 232:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.2151 (0.2151)  orig_norm: 2.1312 (2.1312)  iter: 0.2679s  data: 0.0728s\n",
      "[PT] Epoch 232:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2043 (0.2079)  orig_norm: 2.1650 (2.1569)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 232:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 232\n",
      "[PT] Epoch 233:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2128 (0.2128)  orig_norm: 2.1349 (2.1349)  iter: 0.2516s  data: 0.0578s\n",
      "[PT] Epoch 233:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2061 (0.2069)  orig_norm: 2.1468 (2.1412)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 233:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 233\n",
      "[PT] Epoch 234:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1945 (0.1945)  orig_norm: 2.1313 (2.1313)  iter: 0.2541s  data: 0.0592s\n",
      "[PT] Epoch 234:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2039 (0.2045)  orig_norm: 2.1311 (2.1313)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 234:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 234\n",
      "[PT] Epoch 235:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2046 (0.2046)  orig_norm: 2.0901 (2.0901)  iter: 0.2518s  data: 0.0617s\n",
      "[PT] Epoch 235:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2023 (0.2048)  orig_norm: 2.0905 (2.1102)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 235:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 235\n",
      "[PT] Epoch 236:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1988 (0.1988)  orig_norm: 2.1054 (2.1054)  iter: 0.2587s  data: 0.0644s\n",
      "[PT] Epoch 236:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2046 (0.2036)  orig_norm: 2.0953 (2.0999)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 236:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 236\n",
      "[PT] Epoch 237:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2034 (0.2034)  orig_norm: 2.0979 (2.0979)  iter: 0.2447s  data: 0.0512s\n",
      "[PT] Epoch 237:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1999 (0.2018)  orig_norm: 2.1031 (2.0987)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 237:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 237\n",
      "[PT] Epoch 238:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2195 (0.2195)  orig_norm: 1.9716 (1.9716)  iter: 0.2578s  data: 0.0619s\n",
      "[PT] Epoch 238:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1983 (0.2014)  orig_norm: 2.0792 (2.0815)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 238:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 238\n",
      "[PT] Epoch 239:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.2035 (0.2035)  orig_norm: 1.9959 (1.9959)  iter: 0.2415s  data: 0.0478s\n",
      "[PT] Epoch 239:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1956 (0.2000)  orig_norm: 2.0677 (2.0640)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 239:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 239\n",
      "[PT] Epoch 240:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2025 (0.2025)  orig_norm: 2.0282 (2.0282)  iter: 0.2532s  data: 0.0576s\n",
      "[PT] Epoch 240:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.2003 (0.1996)  orig_norm: 2.0924 (2.0781)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 240:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 240\n",
      "[PT] Epoch 241:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1963 (0.1963)  orig_norm: 2.0573 (2.0573)  iter: 0.2526s  data: 0.0598s\n",
      "[PT] Epoch 241:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1962 (0.1988)  orig_norm: 2.0626 (2.0542)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 241:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 241\n",
      "[PT] Epoch 242:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1790 (0.1790)  orig_norm: 2.1620 (2.1620)  iter: 0.2610s  data: 0.0657s\n",
      "[PT] Epoch 242:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1915 (0.1953)  orig_norm: 2.0300 (2.0426)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 242:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 242\n",
      "[PT] Epoch 243:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1912 (0.1912)  orig_norm: 2.0844 (2.0844)  iter: 0.2546s  data: 0.0593s\n",
      "[PT] Epoch 243:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1927 (0.1937)  orig_norm: 2.0191 (2.0399)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 243:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 243\n",
      "[PT] Epoch 244:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1808 (0.1808)  orig_norm: 2.0537 (2.0537)  iter: 0.2500s  data: 0.0551s\n",
      "[PT] Epoch 244:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1922 (0.1927)  orig_norm: 2.0124 (2.0283)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 244:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 244\n",
      "[PT] Epoch 245:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1822 (0.1822)  orig_norm: 2.0682 (2.0682)  iter: 0.2578s  data: 0.0643s\n",
      "[PT] Epoch 245:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1918 (0.1924)  orig_norm: 1.9949 (2.0071)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 245:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 245\n",
      "[PT] Epoch 246:  [ 0/92]  eta: 0:00:21  max_lr: 0.00002  last_loss: 0.1996 (0.1996)  orig_norm: 1.9539 (1.9539)  iter: 0.2372s  data: 0.0455s\n",
      "[PT] Epoch 246:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1883 (0.1901)  orig_norm: 1.9813 (2.0062)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 246:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 246\n",
      "[PT] Epoch 247:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1932 (0.1932)  orig_norm: 1.9500 (1.9500)  iter: 0.2581s  data: 0.0671s\n",
      "[PT] Epoch 247:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1901 (0.1890)  orig_norm: 1.9908 (1.9926)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 247:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 247\n",
      "[PT] Epoch 248:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1851 (0.1851)  orig_norm: 1.9706 (1.9706)  iter: 0.2613s  data: 0.0605s\n",
      "[PT] Epoch 248:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1848 (0.1883)  orig_norm: 1.9873 (1.9904)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 248:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 248\n",
      "[PT] Epoch 249:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1882 (0.1882)  orig_norm: 1.9378 (1.9378)  iter: 0.2539s  data: 0.0591s\n",
      "[PT] Epoch 249:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1868 (0.1881)  orig_norm: 1.9285 (1.9581)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 249:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 249\n",
      "[PT] Epoch 250:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1952 (0.1952)  orig_norm: 1.9448 (1.9448)  iter: 0.2530s  data: 0.0625s\n",
      "[PT] Epoch 250:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1844 (0.1867)  orig_norm: 1.9558 (1.9557)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 250:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 250\n",
      "[PT] Epoch 251:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1861 (0.1861)  orig_norm: 1.9981 (1.9981)  iter: 0.2561s  data: 0.0610s\n",
      "[PT] Epoch 251:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1804 (0.1829)  orig_norm: 1.9529 (1.9461)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 251:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 251\n",
      "[PT] Epoch 252:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1756 (0.1756)  orig_norm: 1.9255 (1.9255)  iter: 0.2463s  data: 0.0550s\n",
      "[PT] Epoch 252:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1779 (0.1812)  orig_norm: 1.9560 (1.9544)  iter: 0.1848s  data: 0.0002s\n",
      "[PT] Epoch 252:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 252\n",
      "[PT] Epoch 253:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1820 (0.1820)  orig_norm: 1.9439 (1.9439)  iter: 0.2541s  data: 0.0644s\n",
      "[PT] Epoch 253:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1800 (0.1814)  orig_norm: 1.9181 (1.9413)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 253:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 253\n",
      "[PT] Epoch 254:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1873 (0.1873)  orig_norm: 1.8812 (1.8812)  iter: 0.2550s  data: 0.0591s\n",
      "[PT] Epoch 254:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1772 (0.1793)  orig_norm: 1.8988 (1.9065)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 254:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 254\n",
      "[PT] Epoch 255:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.2026 (0.2026)  orig_norm: 1.8596 (1.8596)  iter: 0.2555s  data: 0.0604s\n",
      "[PT] Epoch 255:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1794 (0.1802)  orig_norm: 1.8795 (1.9001)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 255:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 255\n",
      "[PT] Epoch 256:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1784 (0.1784)  orig_norm: 1.9165 (1.9165)  iter: 0.2601s  data: 0.0633s\n",
      "[PT] Epoch 256:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1782 (0.1777)  orig_norm: 1.8550 (1.8939)  iter: 0.1829s  data: 0.0002s\n",
      "[PT] Epoch 256:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 256\n",
      "[PT] Epoch 257:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1755 (0.1755)  orig_norm: 1.8836 (1.8836)  iter: 0.2459s  data: 0.0518s\n",
      "[PT] Epoch 257:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1760 (0.1756)  orig_norm: 1.9046 (1.8857)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 257:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 257\n",
      "[PT] Epoch 258:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1816 (0.1816)  orig_norm: 1.8394 (1.8394)  iter: 0.2493s  data: 0.0563s\n",
      "[PT] Epoch 258:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1732 (0.1760)  orig_norm: 1.8556 (1.8703)  iter: 0.1817s  data: 0.0002s\n",
      "[PT] Epoch 258:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 258\n",
      "[PT] Epoch 259:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1693 (0.1693)  orig_norm: 1.8454 (1.8454)  iter: 0.2462s  data: 0.0529s\n",
      "[PT] Epoch 259:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1698 (0.1717)  orig_norm: 1.8308 (1.8595)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 259:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 259\n",
      "[PT] Epoch 260:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1725 (0.1725)  orig_norm: 1.8299 (1.8299)  iter: 0.2641s  data: 0.0659s\n",
      "[PT] Epoch 260:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1751 (0.1758)  orig_norm: 1.7949 (1.8392)  iter: 0.1820s  data: 0.0002s\n",
      "[PT] Epoch 260:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 260\n",
      "[PT] Epoch 261:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1759 (0.1759)  orig_norm: 1.8081 (1.8081)  iter: 0.2535s  data: 0.0592s\n",
      "[PT] Epoch 261:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1683 (0.1721)  orig_norm: 1.8334 (1.8320)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 261:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 261\n",
      "[PT] Epoch 262:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1692 (0.1692)  orig_norm: 1.8438 (1.8438)  iter: 0.2580s  data: 0.0653s\n",
      "[PT] Epoch 262:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1656 (0.1700)  orig_norm: 1.8291 (1.8248)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 262:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 262\n",
      "[PT] Epoch 263:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1829 (0.1829)  orig_norm: 1.7434 (1.7434)  iter: 0.2573s  data: 0.0622s\n",
      "[PT] Epoch 263:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1670 (0.1692)  orig_norm: 1.8132 (1.8173)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 263:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 263\n",
      "[PT] Epoch 264:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1634 (0.1634)  orig_norm: 1.7484 (1.7484)  iter: 0.2613s  data: 0.0663s\n",
      "[PT] Epoch 264:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1664 (0.1690)  orig_norm: 1.7921 (1.8019)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 264:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 264\n",
      "[PT] Epoch 265:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1763 (0.1763)  orig_norm: 1.7945 (1.7945)  iter: 0.2476s  data: 0.0529s\n",
      "[PT] Epoch 265:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1657 (0.1671)  orig_norm: 1.7965 (1.7948)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 265:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 265\n",
      "[PT] Epoch 266:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1909 (0.1909)  orig_norm: 1.7085 (1.7085)  iter: 0.2517s  data: 0.0600s\n",
      "[PT] Epoch 266:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1660 (0.1668)  orig_norm: 1.7540 (1.7661)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 266:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 266\n",
      "[PT] Epoch 267:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1724 (0.1724)  orig_norm: 1.7628 (1.7628)  iter: 0.2567s  data: 0.0586s\n",
      "[PT] Epoch 267:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1613 (0.1629)  orig_norm: 1.7479 (1.7723)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 267:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 267\n",
      "[PT] Epoch 268:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1563 (0.1563)  orig_norm: 1.7988 (1.7988)  iter: 0.2556s  data: 0.0590s\n",
      "[PT] Epoch 268:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1653 (0.1649)  orig_norm: 1.7392 (1.7661)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 268:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 268\n",
      "[PT] Epoch 269:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1629 (0.1629)  orig_norm: 1.7806 (1.7806)  iter: 0.2592s  data: 0.0635s\n",
      "[PT] Epoch 269:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1587 (0.1624)  orig_norm: 1.7320 (1.7443)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 269:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 269\n",
      "[PT] Epoch 270:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1473 (0.1473)  orig_norm: 1.7756 (1.7756)  iter: 0.2500s  data: 0.0568s\n",
      "[PT] Epoch 270:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1569 (0.1604)  orig_norm: 1.7306 (1.7392)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 270:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 270\n",
      "[PT] Epoch 271:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1677 (0.1677)  orig_norm: 1.7499 (1.7499)  iter: 0.2563s  data: 0.0614s\n",
      "[PT] Epoch 271:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1587 (0.1604)  orig_norm: 1.7564 (1.7521)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 271:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 271\n",
      "[PT] Epoch 272:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1504 (0.1504)  orig_norm: 1.7676 (1.7676)  iter: 0.2569s  data: 0.0640s\n",
      "[PT] Epoch 272:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1525 (0.1576)  orig_norm: 1.7094 (1.7189)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 272:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 272\n",
      "[PT] Epoch 273:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1699 (0.1699)  orig_norm: 1.7188 (1.7188)  iter: 0.2638s  data: 0.0659s\n",
      "[PT] Epoch 273:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1535 (0.1569)  orig_norm: 1.6866 (1.7005)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 273:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 273\n",
      "[PT] Epoch 274:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1694 (0.1694)  orig_norm: 1.7577 (1.7577)  iter: 0.2498s  data: 0.0572s\n",
      "[PT] Epoch 274:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1568 (0.1596)  orig_norm: 1.6803 (1.6936)  iter: 0.1817s  data: 0.0002s\n",
      "[PT] Epoch 274:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 274\n",
      "[PT] Epoch 275:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1391 (0.1391)  orig_norm: 1.7359 (1.7359)  iter: 0.2570s  data: 0.0635s\n",
      "[PT] Epoch 275:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1507 (0.1531)  orig_norm: 1.6927 (1.6951)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 275:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 275\n",
      "[PT] Epoch 276:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1586 (0.1586)  orig_norm: 1.6673 (1.6673)  iter: 0.2572s  data: 0.0666s\n",
      "[PT] Epoch 276:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1521 (0.1555)  orig_norm: 1.6640 (1.6832)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 276:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 276\n",
      "[PT] Epoch 277:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1705 (0.1705)  orig_norm: 1.5974 (1.5974)  iter: 0.2534s  data: 0.0636s\n",
      "[PT] Epoch 277:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1479 (0.1531)  orig_norm: 1.6612 (1.6588)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 277:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 277\n",
      "[PT] Epoch 278:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1655 (0.1655)  orig_norm: 1.6315 (1.6315)  iter: 0.2534s  data: 0.0636s\n",
      "[PT] Epoch 278:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1487 (0.1514)  orig_norm: 1.6202 (1.6475)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 278:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 278\n",
      "[PT] Epoch 279:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1541 (0.1541)  orig_norm: 1.6081 (1.6081)  iter: 0.2540s  data: 0.0576s\n",
      "[PT] Epoch 279:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1544 (0.1523)  orig_norm: 1.6249 (1.6360)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 279:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 279\n",
      "[PT] Epoch 280:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1451 (0.1451)  orig_norm: 1.6844 (1.6844)  iter: 0.2543s  data: 0.0594s\n",
      "[PT] Epoch 280:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1471 (0.1491)  orig_norm: 1.5991 (1.6214)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 280:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 280\n",
      "[PT] Epoch 281:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1613 (0.1613)  orig_norm: 1.5192 (1.5192)  iter: 0.2632s  data: 0.0663s\n",
      "[PT] Epoch 281:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1500 (0.1516)  orig_norm: 1.5558 (1.5859)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 281:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 281\n",
      "[PT] Epoch 282:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1292 (0.1292)  orig_norm: 1.7184 (1.7184)  iter: 0.2590s  data: 0.0660s\n",
      "[PT] Epoch 282:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1416 (0.1493)  orig_norm: 1.5954 (1.5931)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 282:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 282\n",
      "[PT] Epoch 283:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1325 (0.1325)  orig_norm: 1.6402 (1.6402)  iter: 0.2511s  data: 0.0577s\n",
      "[PT] Epoch 283:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1459 (0.1474)  orig_norm: 1.5964 (1.5890)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 283:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 283\n",
      "[PT] Epoch 284:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1480 (0.1480)  orig_norm: 1.5670 (1.5670)  iter: 0.2551s  data: 0.0597s\n",
      "[PT] Epoch 284:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1446 (0.1459)  orig_norm: 1.5750 (1.5773)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 284:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 284\n",
      "[PT] Epoch 285:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1322 (0.1322)  orig_norm: 1.5867 (1.5867)  iter: 0.2515s  data: 0.0593s\n",
      "[PT] Epoch 285:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1431 (0.1441)  orig_norm: 1.5283 (1.5562)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 285:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 285\n",
      "[PT] Epoch 286:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1488 (0.1488)  orig_norm: 1.4727 (1.4727)  iter: 0.2443s  data: 0.0523s\n",
      "[PT] Epoch 286:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1444 (0.1444)  orig_norm: 1.5355 (1.5513)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 286:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 286\n",
      "[PT] Epoch 287:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1289 (0.1289)  orig_norm: 1.5946 (1.5946)  iter: 0.2590s  data: 0.0634s\n",
      "[PT] Epoch 287:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1431 (0.1438)  orig_norm: 1.5109 (1.5448)  iter: 0.1848s  data: 0.0001s\n",
      "[PT] Epoch 287:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 287\n",
      "[PT] Epoch 288:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1448 (0.1448)  orig_norm: 1.5958 (1.5958)  iter: 0.2539s  data: 0.0582s\n",
      "[PT] Epoch 288:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1423 (0.1433)  orig_norm: 1.5364 (1.5214)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 288:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 288\n",
      "[PT] Epoch 289:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1569 (0.1569)  orig_norm: 1.5193 (1.5193)  iter: 0.2629s  data: 0.0663s\n",
      "[PT] Epoch 289:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1387 (0.1427)  orig_norm: 1.5096 (1.5104)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 289:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 289\n",
      "[PT] Epoch 290:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1499 (0.1499)  orig_norm: 1.4842 (1.4842)  iter: 0.2528s  data: 0.0569s\n",
      "[PT] Epoch 290:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1382 (0.1411)  orig_norm: 1.4803 (1.4807)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 290:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 290\n",
      "[PT] Epoch 291:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1240 (0.1240)  orig_norm: 1.5054 (1.5054)  iter: 0.2491s  data: 0.0561s\n",
      "[PT] Epoch 291:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1349 (0.1406)  orig_norm: 1.4771 (1.4978)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 291:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 291\n",
      "[PT] Epoch 292:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1305 (0.1305)  orig_norm: 1.7725 (1.7725)  iter: 0.2489s  data: 0.0597s\n",
      "[PT] Epoch 292:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1378 (0.1389)  orig_norm: 1.4810 (1.4993)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 292:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 292\n",
      "[PT] Epoch 293:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1423 (0.1423)  orig_norm: 1.4306 (1.4306)  iter: 0.2508s  data: 0.0585s\n",
      "[PT] Epoch 293:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1357 (0.1382)  orig_norm: 1.4659 (1.4688)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 293:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 293\n",
      "[PT] Epoch 294:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1280 (0.1280)  orig_norm: 1.4728 (1.4728)  iter: 0.2605s  data: 0.0653s\n",
      "[PT] Epoch 294:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1371 (0.1366)  orig_norm: 1.4320 (1.4479)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 294:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 294\n",
      "[PT] Epoch 295:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1334 (0.1334)  orig_norm: 1.3960 (1.3960)  iter: 0.2526s  data: 0.0603s\n",
      "[PT] Epoch 295:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1339 (0.1378)  orig_norm: 1.4150 (1.4355)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 295:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 295\n",
      "[PT] Epoch 296:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1339 (0.1339)  orig_norm: 1.4147 (1.4147)  iter: 0.2642s  data: 0.0679s\n",
      "[PT] Epoch 296:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1306 (0.1370)  orig_norm: 1.4313 (1.4314)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 296:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 296\n",
      "[PT] Epoch 297:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1264 (0.1264)  orig_norm: 1.4876 (1.4876)  iter: 0.2542s  data: 0.0609s\n",
      "[PT] Epoch 297:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1343 (0.1356)  orig_norm: 1.3819 (1.4278)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 297:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 297\n",
      "[PT] Epoch 298:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1322 (0.1322)  orig_norm: 1.3763 (1.3763)  iter: 0.2567s  data: 0.0632s\n",
      "[PT] Epoch 298:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1297 (0.1330)  orig_norm: 1.4012 (1.4145)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 298:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 298\n",
      "[PT] Epoch 299:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1397 (0.1397)  orig_norm: 1.4721 (1.4721)  iter: 0.2540s  data: 0.0627s\n",
      "[PT] Epoch 299:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1327 (0.1333)  orig_norm: 1.3469 (1.3831)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 299:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 299\n",
      "[PT] Epoch 300:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1159 (0.1159)  orig_norm: 1.4733 (1.4733)  iter: 0.2590s  data: 0.0633s\n",
      "[PT] Epoch 300:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1259 (0.1323)  orig_norm: 1.3987 (1.3862)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 300:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 300\n",
      "[PT] Epoch 301:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1305 (0.1305)  orig_norm: 1.3608 (1.3608)  iter: 0.2448s  data: 0.0518s\n",
      "[PT] Epoch 301:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1297 (0.1316)  orig_norm: 1.3493 (1.3823)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 301:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 301\n",
      "[PT] Epoch 302:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1405 (0.1405)  orig_norm: 1.2865 (1.2865)  iter: 0.2605s  data: 0.0682s\n",
      "[PT] Epoch 302:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1242 (0.1281)  orig_norm: 1.3521 (1.3704)  iter: 0.1808s  data: 0.0001s\n",
      "[PT] Epoch 302:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 302\n",
      "[PT] Epoch 303:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1274 (0.1274)  orig_norm: 1.3714 (1.3714)  iter: 0.2599s  data: 0.0649s\n",
      "[PT] Epoch 303:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1321 (0.1332)  orig_norm: 1.3057 (1.3301)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 303:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 303\n",
      "[PT] Epoch 304:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1492 (0.1492)  orig_norm: 1.3779 (1.3779)  iter: 0.2533s  data: 0.0599s\n",
      "[PT] Epoch 304:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1257 (0.1280)  orig_norm: 1.3431 (1.3480)  iter: 0.1829s  data: 0.0002s\n",
      "[PT] Epoch 304:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 304\n",
      "[PT] Epoch 305:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1310 (0.1310)  orig_norm: 1.2724 (1.2724)  iter: 0.2574s  data: 0.0608s\n",
      "[PT] Epoch 305:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1263 (0.1283)  orig_norm: 1.3202 (1.3344)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 305:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 305\n",
      "[PT] Epoch 306:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.1212 (0.1212)  orig_norm: 1.3620 (1.3620)  iter: 0.2736s  data: 0.0794s\n",
      "[PT] Epoch 306:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1261 (0.1298)  orig_norm: 1.2687 (1.3195)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 306:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 306\n",
      "[PT] Epoch 307:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1214 (0.1214)  orig_norm: 1.2649 (1.2649)  iter: 0.2515s  data: 0.0571s\n",
      "[PT] Epoch 307:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1269 (0.1276)  orig_norm: 1.3013 (1.3110)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 307:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 307\n",
      "[PT] Epoch 308:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1323 (0.1323)  orig_norm: 1.2201 (1.2201)  iter: 0.2667s  data: 0.0735s\n",
      "[PT] Epoch 308:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1257 (0.1240)  orig_norm: 1.2565 (1.2962)  iter: 0.1841s  data: 0.0002s\n",
      "[PT] Epoch 308:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 308\n",
      "[PT] Epoch 309:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1212 (0.1212)  orig_norm: 1.3245 (1.3245)  iter: 0.2662s  data: 0.0676s\n",
      "[PT] Epoch 309:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1218 (0.1258)  orig_norm: 1.2620 (1.2939)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 309:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 309\n",
      "[PT] Epoch 310:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1261 (0.1261)  orig_norm: 1.2454 (1.2454)  iter: 0.2612s  data: 0.0637s\n",
      "[PT] Epoch 310:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1219 (0.1241)  orig_norm: 1.2355 (1.2519)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 310:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 310\n",
      "[PT] Epoch 311:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1157 (0.1157)  orig_norm: 1.2431 (1.2431)  iter: 0.2606s  data: 0.0637s\n",
      "[PT] Epoch 311:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1268 (0.1250)  orig_norm: 1.2010 (1.2381)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 311:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 311\n",
      "[PT] Epoch 312:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1245 (0.1245)  orig_norm: 1.2408 (1.2408)  iter: 0.2653s  data: 0.0728s\n",
      "[PT] Epoch 312:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1224 (0.1229)  orig_norm: 1.2467 (1.2410)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 312:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 312\n",
      "[PT] Epoch 313:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1274 (0.1274)  orig_norm: 1.1485 (1.1485)  iter: 0.2546s  data: 0.0607s\n",
      "[PT] Epoch 313:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1250 (0.1225)  orig_norm: 1.2044 (1.2076)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 313:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 313\n",
      "[PT] Epoch 314:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1309 (0.1309)  orig_norm: 1.2387 (1.2387)  iter: 0.2555s  data: 0.0599s\n",
      "[PT] Epoch 314:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1198 (0.1219)  orig_norm: 1.1905 (1.2069)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 314:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 314\n",
      "[PT] Epoch 315:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1122 (0.1122)  orig_norm: 1.2127 (1.2127)  iter: 0.2592s  data: 0.0646s\n",
      "[PT] Epoch 315:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1189 (0.1206)  orig_norm: 1.1597 (1.1870)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 315:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 315\n",
      "[PT] Epoch 316:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1377 (0.1377)  orig_norm: 1.1140 (1.1140)  iter: 0.2554s  data: 0.0626s\n",
      "[PT] Epoch 316:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1167 (0.1172)  orig_norm: 1.1755 (1.2026)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 316:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 316\n",
      "[PT] Epoch 317:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1097 (0.1097)  orig_norm: 1.1182 (1.1182)  iter: 0.2518s  data: 0.0580s\n",
      "[PT] Epoch 317:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1137 (0.1168)  orig_norm: 1.1762 (1.2146)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 317:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 317\n",
      "[PT] Epoch 318:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1034 (0.1034)  orig_norm: 1.1559 (1.1559)  iter: 0.2587s  data: 0.0619s\n",
      "[PT] Epoch 318:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1166 (0.1192)  orig_norm: 1.1528 (1.1627)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 318:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 318\n",
      "[PT] Epoch 319:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1049 (0.1049)  orig_norm: 1.1578 (1.1578)  iter: 0.2558s  data: 0.0642s\n",
      "[PT] Epoch 319:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1163 (0.1178)  orig_norm: 1.1840 (1.1765)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 319:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 319\n",
      "[PT] Epoch 320:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1130 (0.1130)  orig_norm: 1.1472 (1.1472)  iter: 0.2593s  data: 0.0643s\n",
      "[PT] Epoch 320:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1203 (0.1191)  orig_norm: 1.1270 (1.1799)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 320:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 320\n",
      "[PT] Epoch 321:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1061 (0.1061)  orig_norm: 1.2799 (1.2799)  iter: 0.2592s  data: 0.0645s\n",
      "[PT] Epoch 321:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1135 (0.1171)  orig_norm: 1.1384 (1.1491)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 321:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 321\n",
      "[PT] Epoch 322:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1080 (0.1080)  orig_norm: 1.1435 (1.1435)  iter: 0.2530s  data: 0.0604s\n",
      "[PT] Epoch 322:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1164 (0.1160)  orig_norm: 1.1101 (1.1337)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 322:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 322\n",
      "[PT] Epoch 323:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1152 (0.1152)  orig_norm: 1.3131 (1.3131)  iter: 0.2518s  data: 0.0552s\n",
      "[PT] Epoch 323:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1117 (0.1161)  orig_norm: 1.0989 (1.1125)  iter: 0.1854s  data: 0.0001s\n",
      "[PT] Epoch 323:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 323\n",
      "[PT] Epoch 324:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1065 (0.1065)  orig_norm: 1.1637 (1.1637)  iter: 0.2643s  data: 0.0662s\n",
      "[PT] Epoch 324:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1169 (0.1139)  orig_norm: 1.0744 (1.1137)  iter: 0.1838s  data: 0.0002s\n",
      "[PT] Epoch 324:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 324\n",
      "[PT] Epoch 325:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1094 (0.1094)  orig_norm: 1.0778 (1.0778)  iter: 0.2602s  data: 0.0660s\n",
      "[PT] Epoch 325:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1131 (0.1150)  orig_norm: 1.0867 (1.1003)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 325:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 325\n",
      "[PT] Epoch 326:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1197 (0.1197)  orig_norm: 1.2048 (1.2048)  iter: 0.2611s  data: 0.0646s\n",
      "[PT] Epoch 326:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1126 (0.1138)  orig_norm: 1.0425 (1.0862)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 326:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 326\n",
      "[PT] Epoch 327:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1166 (0.1166)  orig_norm: 0.9999 (0.9999)  iter: 0.2481s  data: 0.0532s\n",
      "[PT] Epoch 327:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1074 (0.1117)  orig_norm: 1.0614 (1.0494)  iter: 0.1838s  data: 0.0001s\n",
      "[PT] Epoch 327:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 327\n",
      "[PT] Epoch 328:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1119 (0.1119)  orig_norm: 1.0014 (1.0014)  iter: 0.2607s  data: 0.0645s\n",
      "[PT] Epoch 328:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1172 (0.1141)  orig_norm: 1.0025 (1.0643)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 328:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 328\n",
      "[PT] Epoch 329:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1052 (0.1052)  orig_norm: 1.0089 (1.0089)  iter: 0.2456s  data: 0.0515s\n",
      "[PT] Epoch 329:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1105 (0.1126)  orig_norm: 1.0167 (1.0357)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 329:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 329\n",
      "[PT] Epoch 330:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1059 (0.1059)  orig_norm: 0.9612 (0.9612)  iter: 0.2575s  data: 0.0627s\n",
      "[PT] Epoch 330:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1148 (0.1112)  orig_norm: 1.0376 (1.0471)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 330:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 330\n",
      "[PT] Epoch 331:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1238 (0.1238)  orig_norm: 1.2840 (1.2840)  iter: 0.2491s  data: 0.0519s\n",
      "[PT] Epoch 331:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1096 (0.1126)  orig_norm: 0.9869 (1.0146)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 331:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 331\n",
      "[PT] Epoch 332:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1116 (0.1116)  orig_norm: 0.9678 (0.9678)  iter: 0.2572s  data: 0.0636s\n",
      "[PT] Epoch 332:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1107 (0.1102)  orig_norm: 1.0039 (1.0262)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 332:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 332\n",
      "[PT] Epoch 333:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1108 (0.1108)  orig_norm: 1.0112 (1.0112)  iter: 0.2556s  data: 0.0594s\n",
      "[PT] Epoch 333:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1031 (0.1101)  orig_norm: 0.9720 (0.9931)  iter: 0.1810s  data: 0.0001s\n",
      "[PT] Epoch 333:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 333\n",
      "[PT] Epoch 334:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1376 (0.1376)  orig_norm: 1.0330 (1.0330)  iter: 0.2438s  data: 0.0508s\n",
      "[PT] Epoch 334:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1112 (0.1115)  orig_norm: 0.9620 (0.9917)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 334:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 334\n",
      "[PT] Epoch 335:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1023 (0.1023)  orig_norm: 1.0754 (1.0754)  iter: 0.2518s  data: 0.0595s\n",
      "[PT] Epoch 335:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1086 (0.1094)  orig_norm: 0.9647 (1.0209)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 335:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 335\n",
      "[PT] Epoch 336:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1123 (0.1123)  orig_norm: 0.9784 (0.9784)  iter: 0.2548s  data: 0.0594s\n",
      "[PT] Epoch 336:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1053 (0.1089)  orig_norm: 0.9529 (0.9891)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 336:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 336\n",
      "[PT] Epoch 337:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1020 (0.1020)  orig_norm: 0.9026 (0.9026)  iter: 0.2515s  data: 0.0600s\n",
      "[PT] Epoch 337:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1078 (0.1084)  orig_norm: 0.9730 (0.9908)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 337:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 337\n",
      "[PT] Epoch 338:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0870 (0.0870)  orig_norm: 0.9790 (0.9790)  iter: 0.2592s  data: 0.0649s\n",
      "[PT] Epoch 338:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1045 (0.1074)  orig_norm: 0.9048 (0.9425)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 338:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 338\n",
      "[PT] Epoch 339:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1123 (0.1123)  orig_norm: 0.8389 (0.8389)  iter: 0.2582s  data: 0.0657s\n",
      "[PT] Epoch 339:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1072 (0.1082)  orig_norm: 0.8866 (0.9203)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 339:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 339\n",
      "[PT] Epoch 340:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1077 (0.1077)  orig_norm: 0.8646 (0.8646)  iter: 0.2583s  data: 0.0628s\n",
      "[PT] Epoch 340:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1116 (0.1094)  orig_norm: 0.8968 (0.9163)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 340:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 340\n",
      "[PT] Epoch 341:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0977 (0.0977)  orig_norm: 0.9438 (0.9438)  iter: 0.2605s  data: 0.0675s\n",
      "[PT] Epoch 341:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1061 (0.1084)  orig_norm: 0.8843 (0.9139)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 341:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 341\n",
      "[PT] Epoch 342:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0851 (0.0851)  orig_norm: 0.9098 (0.9098)  iter: 0.2604s  data: 0.0645s\n",
      "[PT] Epoch 342:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0997 (0.1046)  orig_norm: 0.8977 (0.9096)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 342:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 342\n",
      "[PT] Epoch 343:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1114 (0.1114)  orig_norm: 0.9014 (0.9014)  iter: 0.2642s  data: 0.0707s\n",
      "[PT] Epoch 343:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0999 (0.1038)  orig_norm: 0.8639 (0.9037)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 343:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 343\n",
      "[PT] Epoch 344:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0968 (0.0968)  orig_norm: 1.1530 (1.1530)  iter: 0.2593s  data: 0.0635s\n",
      "[PT] Epoch 344:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1064 (0.1060)  orig_norm: 0.8163 (0.8699)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 344:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 344\n",
      "[PT] Epoch 345:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0913 (0.0913)  orig_norm: 0.8571 (0.8571)  iter: 0.2568s  data: 0.0603s\n",
      "[PT] Epoch 345:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1025 (0.1034)  orig_norm: 0.8669 (0.9159)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 345:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 345\n",
      "[PT] Epoch 346:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0952 (0.0952)  orig_norm: 0.8289 (0.8289)  iter: 0.2593s  data: 0.0648s\n",
      "[PT] Epoch 346:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0986 (0.1028)  orig_norm: 0.8116 (0.8566)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 346:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 346\n",
      "[PT] Epoch 347:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0935 (0.0935)  orig_norm: 0.8769 (0.8769)  iter: 0.2645s  data: 0.0716s\n",
      "[PT] Epoch 347:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0980 (0.1041)  orig_norm: 0.7916 (0.8939)  iter: 0.1838s  data: 0.0002s\n",
      "[PT] Epoch 347:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 347\n",
      "[PT] Epoch 348:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1015 (0.1015)  orig_norm: 0.8806 (0.8806)  iter: 0.2609s  data: 0.0678s\n",
      "[PT] Epoch 348:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1021 (0.1033)  orig_norm: 0.9313 (0.9153)  iter: 0.1808s  data: 0.0001s\n",
      "[PT] Epoch 348:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 348\n",
      "[PT] Epoch 349:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0940 (0.0940)  orig_norm: 0.8814 (0.8814)  iter: 0.2586s  data: 0.0627s\n",
      "[PT] Epoch 349:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1059 (0.1027)  orig_norm: 0.7838 (0.8266)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 349:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 349\n",
      "[PT] Epoch 350:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1069 (0.1069)  orig_norm: 0.8181 (0.8181)  iter: 0.2596s  data: 0.0652s\n",
      "[PT] Epoch 350:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0981 (0.1020)  orig_norm: 0.8250 (0.8357)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 350:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 350\n",
      "[PT] Epoch 351:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0991 (0.0991)  orig_norm: 0.8314 (0.8314)  iter: 0.2675s  data: 0.0749s\n",
      "[PT] Epoch 351:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1020 (0.1039)  orig_norm: 0.8618 (0.8901)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 351:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 351\n",
      "[PT] Epoch 352:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0965 (0.0965)  orig_norm: 0.7150 (0.7150)  iter: 0.2587s  data: 0.0610s\n",
      "[PT] Epoch 352:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1005 (0.1014)  orig_norm: 0.8169 (0.8280)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 352:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 352\n",
      "[PT] Epoch 353:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1018 (0.1018)  orig_norm: 0.9444 (0.9444)  iter: 0.2579s  data: 0.0641s\n",
      "[PT] Epoch 353:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0980 (0.1002)  orig_norm: 0.7064 (0.7846)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 353:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 353\n",
      "[PT] Epoch 354:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0809 (0.0809)  orig_norm: 0.7506 (0.7506)  iter: 0.2443s  data: 0.0529s\n",
      "[PT] Epoch 354:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0986 (0.0975)  orig_norm: 0.7254 (0.7674)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 354:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 354\n",
      "[PT] Epoch 355:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0926 (0.0926)  orig_norm: 0.8271 (0.8271)  iter: 0.2638s  data: 0.0654s\n",
      "[PT] Epoch 355:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1007 (0.0999)  orig_norm: 0.7859 (0.8006)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 355:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 355\n",
      "[PT] Epoch 356:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1032 (0.1032)  orig_norm: 0.9942 (0.9942)  iter: 0.2545s  data: 0.0592s\n",
      "[PT] Epoch 356:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0997 (0.1013)  orig_norm: 0.7469 (0.7540)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 356:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 356\n",
      "[PT] Epoch 357:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0922 (0.0922)  orig_norm: 0.9634 (0.9634)  iter: 0.2624s  data: 0.0671s\n",
      "[PT] Epoch 357:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0997 (0.1014)  orig_norm: 0.7548 (0.7974)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 357:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 357\n",
      "[PT] Epoch 358:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0917 (0.0917)  orig_norm: 0.6890 (0.6890)  iter: 0.2511s  data: 0.0568s\n",
      "[PT] Epoch 358:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0974 (0.1000)  orig_norm: 0.7226 (0.7222)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 358:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 358\n",
      "[PT] Epoch 359:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0993 (0.0993)  orig_norm: 0.6239 (0.6239)  iter: 0.2519s  data: 0.0603s\n",
      "[PT] Epoch 359:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0949 (0.0988)  orig_norm: 0.7715 (0.8171)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 359:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 359\n",
      "[PT] Epoch 360:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0898 (0.0898)  orig_norm: 0.7903 (0.7903)  iter: 0.2512s  data: 0.0568s\n",
      "[PT] Epoch 360:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0977 (0.1003)  orig_norm: 0.6943 (0.7923)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 360:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 360\n",
      "[PT] Epoch 361:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0909 (0.0909)  orig_norm: 0.6115 (0.6115)  iter: 0.2621s  data: 0.0671s\n",
      "[PT] Epoch 361:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0954 (0.1014)  orig_norm: 0.7394 (0.8056)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 361:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 361\n",
      "[PT] Epoch 362:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1023 (0.1023)  orig_norm: 0.8432 (0.8432)  iter: 0.2539s  data: 0.0587s\n",
      "[PT] Epoch 362:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1003 (0.0984)  orig_norm: 0.6747 (0.6968)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 362:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 362\n",
      "[PT] Epoch 363:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0948 (0.0948)  orig_norm: 0.5893 (0.5893)  iter: 0.2519s  data: 0.0567s\n",
      "[PT] Epoch 363:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0952 (0.0984)  orig_norm: 0.6817 (0.7297)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 363:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 363\n",
      "[PT] Epoch 364:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0934 (0.0934)  orig_norm: 0.6883 (0.6883)  iter: 0.2518s  data: 0.0539s\n",
      "[PT] Epoch 364:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0977 (0.1002)  orig_norm: 0.6596 (0.7579)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 364:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 364\n",
      "[PT] Epoch 365:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0924 (0.0924)  orig_norm: 0.5773 (0.5773)  iter: 0.2477s  data: 0.0517s\n",
      "[PT] Epoch 365:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0926 (0.0970)  orig_norm: 0.6928 (0.7264)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 365:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 365\n",
      "[PT] Epoch 366:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0756 (0.0756)  orig_norm: 0.8438 (0.8438)  iter: 0.2541s  data: 0.0588s\n",
      "[PT] Epoch 366:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0936 (0.0976)  orig_norm: 0.6885 (0.7255)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 366:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 366\n",
      "[PT] Epoch 367:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1082 (0.1082)  orig_norm: 0.6817 (0.6817)  iter: 0.2473s  data: 0.0526s\n",
      "[PT] Epoch 367:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0983 (0.0997)  orig_norm: 0.6778 (0.7097)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 367:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 367\n",
      "[PT] Epoch 368:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1088 (0.1088)  orig_norm: 0.9856 (0.9856)  iter: 0.2603s  data: 0.0645s\n",
      "[PT] Epoch 368:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0942 (0.0990)  orig_norm: 0.7441 (0.7731)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 368:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 368\n",
      "[PT] Epoch 369:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0907 (0.0907)  orig_norm: 0.7387 (0.7387)  iter: 0.2585s  data: 0.0643s\n",
      "[PT] Epoch 369:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0935 (0.0972)  orig_norm: 0.6249 (0.6897)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 369:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 369\n",
      "[PT] Epoch 370:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1094 (0.1094)  orig_norm: 0.6544 (0.6544)  iter: 0.2615s  data: 0.0673s\n",
      "[PT] Epoch 370:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0991 (0.0987)  orig_norm: 0.6677 (0.6825)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 370:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 370\n",
      "[PT] Epoch 371:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0979 (0.0979)  orig_norm: 1.0632 (1.0632)  iter: 0.2592s  data: 0.0652s\n",
      "[PT] Epoch 371:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0974 (0.0986)  orig_norm: 0.5781 (0.7248)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 371:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 371\n",
      "[PT] Epoch 372:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1051 (0.1051)  orig_norm: 0.7064 (0.7064)  iter: 0.2604s  data: 0.0650s\n",
      "[PT] Epoch 372:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0936 (0.0952)  orig_norm: 0.6208 (0.6867)  iter: 0.1831s  data: 0.0002s\n",
      "[PT] Epoch 372:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 372\n",
      "[PT] Epoch 373:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0992 (0.0992)  orig_norm: 0.5512 (0.5512)  iter: 0.2539s  data: 0.0560s\n",
      "[PT] Epoch 373:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0905 (0.0967)  orig_norm: 0.6106 (0.6833)  iter: 0.1837s  data: 0.0002s\n",
      "[PT] Epoch 373:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 373\n",
      "[PT] Epoch 374:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1054 (0.1054)  orig_norm: 0.5882 (0.5882)  iter: 0.2443s  data: 0.0515s\n",
      "[PT] Epoch 374:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0925 (0.0936)  orig_norm: 0.6487 (0.6694)  iter: 0.1841s  data: 0.0002s\n",
      "[PT] Epoch 374:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 374\n",
      "[PT] Epoch 375:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0926 (0.0926)  orig_norm: 1.1965 (1.1965)  iter: 0.2577s  data: 0.0632s\n",
      "[PT] Epoch 375:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0962 (0.0967)  orig_norm: 0.6614 (0.7018)  iter: 0.1841s  data: 0.0002s\n",
      "[PT] Epoch 375:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 375\n",
      "[PT] Epoch 376:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1090 (0.1090)  orig_norm: 0.4949 (0.4949)  iter: 0.2613s  data: 0.0642s\n",
      "[PT] Epoch 376:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0925 (0.0963)  orig_norm: 0.6021 (0.6583)  iter: 0.1838s  data: 0.0001s\n",
      "[PT] Epoch 376:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 376\n",
      "[PT] Epoch 377:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0902 (0.0902)  orig_norm: 0.7632 (0.7632)  iter: 0.2566s  data: 0.0610s\n",
      "[PT] Epoch 377:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1010 (0.0965)  orig_norm: 0.6709 (0.6746)  iter: 0.1850s  data: 0.0002s\n",
      "[PT] Epoch 377:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 377\n",
      "[PT] Epoch 378:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0866 (0.0866)  orig_norm: 0.5803 (0.5803)  iter: 0.2653s  data: 0.0672s\n",
      "[PT] Epoch 378:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.1005 (0.0961)  orig_norm: 0.6289 (0.6706)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 378:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 378\n",
      "[PT] Epoch 379:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0896 (0.0896)  orig_norm: 0.6693 (0.6693)  iter: 0.2510s  data: 0.0588s\n",
      "[PT] Epoch 379:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0941 (0.0954)  orig_norm: 0.6060 (0.6414)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 379:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 379\n",
      "[PT] Epoch 380:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0920 (0.0920)  orig_norm: 0.6370 (0.6370)  iter: 0.2614s  data: 0.0624s\n",
      "[PT] Epoch 380:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0925 (0.0953)  orig_norm: 0.6109 (0.6265)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 380:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 380\n",
      "[PT] Epoch 381:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0867 (0.0867)  orig_norm: 0.5960 (0.5960)  iter: 0.2606s  data: 0.0644s\n",
      "[PT] Epoch 381:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0883 (0.0934)  orig_norm: 0.6439 (0.6352)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 381:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 381\n",
      "[PT] Epoch 382:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0883 (0.0883)  orig_norm: 0.7045 (0.7045)  iter: 0.2487s  data: 0.0555s\n",
      "[PT] Epoch 382:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0964 (0.0947)  orig_norm: 0.6531 (0.7078)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 382:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 382\n",
      "[PT] Epoch 383:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0879 (0.0879)  orig_norm: 0.5502 (0.5502)  iter: 0.2465s  data: 0.0527s\n",
      "[PT] Epoch 383:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0936 (0.0943)  orig_norm: 0.5995 (0.6268)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 383:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 383\n",
      "[PT] Epoch 384:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0940 (0.0940)  orig_norm: 0.6380 (0.6380)  iter: 0.2519s  data: 0.0579s\n",
      "[PT] Epoch 384:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0928 (0.0942)  orig_norm: 0.6668 (0.6915)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 384:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 384\n",
      "[PT] Epoch 385:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0878 (0.0878)  orig_norm: 0.8911 (0.8911)  iter: 0.2510s  data: 0.0542s\n",
      "[PT] Epoch 385:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0902 (0.0939)  orig_norm: 0.6511 (0.7137)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 385:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 385\n",
      "[PT] Epoch 386:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1136 (0.1136)  orig_norm: 0.5769 (0.5769)  iter: 0.2568s  data: 0.0623s\n",
      "[PT] Epoch 386:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0946 (0.0949)  orig_norm: 0.6310 (0.6908)  iter: 0.1840s  data: 0.0001s\n",
      "[PT] Epoch 386:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 386\n",
      "[PT] Epoch 387:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.0817 (0.0817)  orig_norm: 0.4735 (0.4735)  iter: 0.2735s  data: 0.0756s\n",
      "[PT] Epoch 387:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0928 (0.0945)  orig_norm: 0.5711 (0.6485)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 387:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 387\n",
      "[PT] Epoch 388:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0770 (0.0770)  orig_norm: 0.6118 (0.6118)  iter: 0.2505s  data: 0.0568s\n",
      "[PT] Epoch 388:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0929 (0.0936)  orig_norm: 0.6005 (0.6335)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 388:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 388\n",
      "[PT] Epoch 389:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1022 (0.1022)  orig_norm: 0.5824 (0.5824)  iter: 0.2570s  data: 0.0648s\n",
      "[PT] Epoch 389:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0883 (0.0948)  orig_norm: 0.6202 (0.6164)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 389:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 389\n",
      "[PT] Epoch 390:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0845 (0.0845)  orig_norm: 0.8172 (0.8172)  iter: 0.2597s  data: 0.0626s\n",
      "[PT] Epoch 390:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0895 (0.0927)  orig_norm: 0.5824 (0.6430)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 390:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 390\n",
      "[PT] Epoch 391:  [ 0/92]  eta: 0:00:21  max_lr: 0.00002  last_loss: 0.1028 (0.1028)  orig_norm: 0.6697 (0.6697)  iter: 0.2390s  data: 0.0487s\n",
      "[PT] Epoch 391:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0892 (0.0930)  orig_norm: 0.5688 (0.6876)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 391:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 391\n",
      "[PT] Epoch 392:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1075 (0.1075)  orig_norm: 0.6837 (0.6837)  iter: 0.2437s  data: 0.0486s\n",
      "[PT] Epoch 392:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0963 (0.0959)  orig_norm: 0.6256 (0.6471)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 392:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 392\n",
      "[PT] Epoch 393:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0979 (0.0979)  orig_norm: 0.6095 (0.6095)  iter: 0.2568s  data: 0.0604s\n",
      "[PT] Epoch 393:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0915 (0.0955)  orig_norm: 0.5948 (0.6480)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 393:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 393\n",
      "[PT] Epoch 394:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1023 (0.1023)  orig_norm: 0.7816 (0.7816)  iter: 0.2453s  data: 0.0503s\n",
      "[PT] Epoch 394:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0927 (0.0942)  orig_norm: 0.6237 (0.6655)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 394:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 394\n",
      "[PT] Epoch 395:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0886 (0.0886)  orig_norm: 0.5432 (0.5432)  iter: 0.2620s  data: 0.0660s\n",
      "[PT] Epoch 395:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0876 (0.0937)  orig_norm: 0.7469 (0.6622)  iter: 0.1839s  data: 0.0001s\n",
      "[PT] Epoch 395:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 395\n",
      "[PT] Epoch 396:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1036 (0.1036)  orig_norm: 0.5568 (0.5568)  iter: 0.2691s  data: 0.0746s\n",
      "[PT] Epoch 396:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0944 (0.0951)  orig_norm: 0.6669 (0.6557)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 396:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 396\n",
      "[PT] Epoch 397:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0856 (0.0856)  orig_norm: 0.9951 (0.9951)  iter: 0.2666s  data: 0.0679s\n",
      "[PT] Epoch 397:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0911 (0.0933)  orig_norm: 0.5436 (0.6842)  iter: 0.1843s  data: 0.0002s\n",
      "[PT] Epoch 397:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 397\n",
      "[PT] Epoch 398:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0846 (0.0846)  orig_norm: 0.4969 (0.4969)  iter: 0.2530s  data: 0.0589s\n",
      "[PT] Epoch 398:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0924 (0.0934)  orig_norm: 0.6894 (0.6737)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 398:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 398\n",
      "[PT] Epoch 399:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0866 (0.0866)  orig_norm: 0.6756 (0.6756)  iter: 0.2440s  data: 0.0525s\n",
      "[PT] Epoch 399:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0940 (0.0930)  orig_norm: 0.7145 (0.6560)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 399:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 399\n",
      "[PT] Epoch 400:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1009 (0.1009)  orig_norm: 0.6147 (0.6147)  iter: 0.2685s  data: 0.0762s\n",
      "[PT] Epoch 400:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0933 (0.0940)  orig_norm: 0.6619 (0.6756)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 400:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 400\n",
      "[PT] Epoch 401:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0870 (0.0870)  orig_norm: 0.7432 (0.7432)  iter: 0.2608s  data: 0.0692s\n",
      "[PT] Epoch 401:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0932 (0.0924)  orig_norm: 0.6349 (0.7051)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 401:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 401\n",
      "[PT] Epoch 402:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0862 (0.0862)  orig_norm: 0.4963 (0.4963)  iter: 0.2461s  data: 0.0550s\n",
      "[PT] Epoch 402:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0888 (0.0914)  orig_norm: 0.5643 (0.6646)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 402:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 402\n",
      "[PT] Epoch 403:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0839 (0.0839)  orig_norm: 0.6297 (0.6297)  iter: 0.2569s  data: 0.0637s\n",
      "[PT] Epoch 403:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0895 (0.0924)  orig_norm: 0.6210 (0.6592)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 403:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 403\n",
      "[PT] Epoch 404:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0831 (0.0831)  orig_norm: 0.9458 (0.9458)  iter: 0.2599s  data: 0.0614s\n",
      "[PT] Epoch 404:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0979 (0.0940)  orig_norm: 0.6341 (0.6660)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 404:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 404\n",
      "[PT] Epoch 405:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0949 (0.0949)  orig_norm: 0.4891 (0.4891)  iter: 0.2568s  data: 0.0623s\n",
      "[PT] Epoch 405:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0873 (0.0913)  orig_norm: 0.5983 (0.6766)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 405:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 405\n",
      "[PT] Epoch 406:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1084 (0.1084)  orig_norm: 0.5873 (0.5873)  iter: 0.2521s  data: 0.0594s\n",
      "[PT] Epoch 406:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0902 (0.0945)  orig_norm: 0.6325 (0.6382)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 406:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 406\n",
      "[PT] Epoch 407:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1155 (0.1155)  orig_norm: 0.7313 (0.7313)  iter: 0.2460s  data: 0.0503s\n",
      "[PT] Epoch 407:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0890 (0.0919)  orig_norm: 0.6109 (0.7089)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 407:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 407\n",
      "[PT] Epoch 408:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0945 (0.0945)  orig_norm: 0.4974 (0.4974)  iter: 0.2555s  data: 0.0591s\n",
      "[PT] Epoch 408:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0996 (0.0943)  orig_norm: 0.7244 (0.6708)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 408:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 408\n",
      "[PT] Epoch 409:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0951 (0.0951)  orig_norm: 0.5301 (0.5301)  iter: 0.2685s  data: 0.0735s\n",
      "[PT] Epoch 409:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0958 (0.0950)  orig_norm: 0.6440 (0.6928)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 409:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 409\n",
      "[PT] Epoch 410:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0794 (0.0794)  orig_norm: 0.4876 (0.4876)  iter: 0.2543s  data: 0.0599s\n",
      "[PT] Epoch 410:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0904 (0.0921)  orig_norm: 0.6492 (0.6986)  iter: 0.1838s  data: 0.0002s\n",
      "[PT] Epoch 410:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 410\n",
      "[PT] Epoch 411:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0834 (0.0834)  orig_norm: 0.4829 (0.4829)  iter: 0.2624s  data: 0.0610s\n",
      "[PT] Epoch 411:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0881 (0.0928)  orig_norm: 0.5598 (0.6333)  iter: 0.1828s  data: 0.0002s\n",
      "[PT] Epoch 411:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 411\n",
      "[PT] Epoch 412:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0796 (0.0796)  orig_norm: 0.6271 (0.6271)  iter: 0.2551s  data: 0.0589s\n",
      "[PT] Epoch 412:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0879 (0.0916)  orig_norm: 0.5872 (0.7174)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 412:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 412\n",
      "[PT] Epoch 413:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0791 (0.0791)  orig_norm: 0.5285 (0.5285)  iter: 0.2626s  data: 0.0651s\n",
      "[PT] Epoch 413:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0939 (0.0929)  orig_norm: 0.6532 (0.6748)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 413:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 413\n",
      "[PT] Epoch 414:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1018 (0.1018)  orig_norm: 0.7576 (0.7576)  iter: 0.2686s  data: 0.0775s\n",
      "[PT] Epoch 414:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0907 (0.0916)  orig_norm: 0.6933 (0.7154)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 414:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 414\n",
      "[PT] Epoch 415:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0974 (0.0974)  orig_norm: 0.5424 (0.5424)  iter: 0.2561s  data: 0.0626s\n",
      "[PT] Epoch 415:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0928 (0.0921)  orig_norm: 0.6438 (0.6452)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 415:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 415\n",
      "[PT] Epoch 416:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0956 (0.0956)  orig_norm: 0.6022 (0.6022)  iter: 0.2592s  data: 0.0663s\n",
      "[PT] Epoch 416:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0919 (0.0921)  orig_norm: 0.5654 (0.6371)  iter: 0.1823s  data: 0.0002s\n",
      "[PT] Epoch 416:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 416\n",
      "[PT] Epoch 417:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0881 (0.0881)  orig_norm: 0.6174 (0.6174)  iter: 0.2715s  data: 0.0794s\n",
      "[PT] Epoch 417:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0950 (0.0954)  orig_norm: 0.6635 (0.7202)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 417:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 417\n",
      "[PT] Epoch 418:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0975 (0.0975)  orig_norm: 0.5059 (0.5059)  iter: 0.2590s  data: 0.0668s\n",
      "[PT] Epoch 418:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0902 (0.0914)  orig_norm: 0.6399 (0.6933)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 418:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 418\n",
      "[PT] Epoch 419:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0875 (0.0875)  orig_norm: 0.5344 (0.5344)  iter: 0.2585s  data: 0.0655s\n",
      "[PT] Epoch 419:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0892 (0.0929)  orig_norm: 0.5744 (0.6856)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 419:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 419\n",
      "[PT] Epoch 420:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1022 (0.1022)  orig_norm: 0.5424 (0.5424)  iter: 0.2692s  data: 0.0772s\n",
      "[PT] Epoch 420:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0896 (0.0925)  orig_norm: 0.6236 (0.6959)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 420:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 420\n",
      "[PT] Epoch 421:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0993 (0.0993)  orig_norm: 0.6526 (0.6526)  iter: 0.2527s  data: 0.0589s\n",
      "[PT] Epoch 421:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0902 (0.0929)  orig_norm: 0.5912 (0.6598)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 421:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 421\n",
      "[PT] Epoch 422:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0894 (0.0894)  orig_norm: 0.9232 (0.9232)  iter: 0.2593s  data: 0.0649s\n",
      "[PT] Epoch 422:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0893 (0.0908)  orig_norm: 0.7735 (0.7688)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 422:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 422\n",
      "[PT] Epoch 423:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0800 (0.0800)  orig_norm: 0.8289 (0.8289)  iter: 0.2501s  data: 0.0556s\n",
      "[PT] Epoch 423:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0907 (0.0927)  orig_norm: 0.9054 (0.8293)  iter: 0.1818s  data: 0.0002s\n",
      "[PT] Epoch 423:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 423\n",
      "[PT] Epoch 424:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0791 (0.0791)  orig_norm: 0.8465 (0.8465)  iter: 0.2559s  data: 0.0634s\n",
      "[PT] Epoch 424:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0882 (0.0932)  orig_norm: 0.6382 (0.6889)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 424:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 424\n",
      "[PT] Epoch 425:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0849 (0.0849)  orig_norm: 0.5759 (0.5759)  iter: 0.2601s  data: 0.0645s\n",
      "[PT] Epoch 425:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0917 (0.0925)  orig_norm: 0.6346 (0.7147)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 425:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 425\n",
      "[PT] Epoch 426:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0919 (0.0919)  orig_norm: 0.8063 (0.8063)  iter: 0.2568s  data: 0.0593s\n",
      "[PT] Epoch 426:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0913 (0.0932)  orig_norm: 0.5774 (0.6540)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 426:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 426\n",
      "[PT] Epoch 427:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0745 (0.0745)  orig_norm: 0.7975 (0.7975)  iter: 0.2521s  data: 0.0603s\n",
      "[PT] Epoch 427:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0900 (0.0917)  orig_norm: 0.5961 (0.6356)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 427:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 427\n",
      "[PT] Epoch 428:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0691 (0.0691)  orig_norm: 0.4042 (0.4042)  iter: 0.2542s  data: 0.0592s\n",
      "[PT] Epoch 428:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0888 (0.0933)  orig_norm: 0.5870 (0.6441)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 428:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 428\n",
      "[PT] Epoch 429:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0941 (0.0941)  orig_norm: 0.5577 (0.5577)  iter: 0.2623s  data: 0.0663s\n",
      "[PT] Epoch 429:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0937 (0.0926)  orig_norm: 0.6650 (0.6897)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 429:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 429\n",
      "[PT] Epoch 430:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0974 (0.0974)  orig_norm: 0.8884 (0.8884)  iter: 0.2556s  data: 0.0633s\n",
      "[PT] Epoch 430:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0925 (0.0914)  orig_norm: 0.5480 (0.6584)  iter: 0.1828s  data: 0.0002s\n",
      "[PT] Epoch 430:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 430\n",
      "[PT] Epoch 431:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0971 (0.0971)  orig_norm: 0.5606 (0.5606)  iter: 0.2503s  data: 0.0547s\n",
      "[PT] Epoch 431:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0898 (0.0933)  orig_norm: 0.7568 (0.7002)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 431:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 431\n",
      "[PT] Epoch 432:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0809 (0.0809)  orig_norm: 0.4370 (0.4370)  iter: 0.2608s  data: 0.0647s\n",
      "[PT] Epoch 432:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0904 (0.0916)  orig_norm: 0.6655 (0.7361)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 432:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 432\n",
      "[PT] Epoch 433:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0891 (0.0891)  orig_norm: 0.5253 (0.5253)  iter: 0.2585s  data: 0.0656s\n",
      "[PT] Epoch 433:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0929 (0.0910)  orig_norm: 0.6392 (0.6558)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 433:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 433\n",
      "[PT] Epoch 434:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0900 (0.0900)  orig_norm: 0.9428 (0.9428)  iter: 0.2604s  data: 0.0652s\n",
      "[PT] Epoch 434:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0919 (0.0914)  orig_norm: 0.6912 (0.7206)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 434:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 434\n",
      "[PT] Epoch 435:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0866 (0.0866)  orig_norm: 0.6019 (0.6019)  iter: 0.2549s  data: 0.0605s\n",
      "[PT] Epoch 435:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0885 (0.0929)  orig_norm: 0.6434 (0.7061)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 435:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 435\n",
      "[PT] Epoch 436:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0792 (0.0792)  orig_norm: 0.5897 (0.5897)  iter: 0.2612s  data: 0.0670s\n",
      "[PT] Epoch 436:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0876 (0.0925)  orig_norm: 0.6255 (0.6936)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 436:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 436\n",
      "[PT] Epoch 437:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0859 (0.0859)  orig_norm: 0.8022 (0.8022)  iter: 0.2525s  data: 0.0565s\n",
      "[PT] Epoch 437:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0892 (0.0893)  orig_norm: 0.6458 (0.6495)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 437:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 437\n",
      "[PT] Epoch 438:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1190 (0.1190)  orig_norm: 1.0249 (1.0249)  iter: 0.2517s  data: 0.0608s\n",
      "[PT] Epoch 438:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0891 (0.0922)  orig_norm: 0.6665 (0.7431)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 438:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 438\n",
      "[PT] Epoch 439:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1116 (0.1116)  orig_norm: 0.6735 (0.6735)  iter: 0.2618s  data: 0.0716s\n",
      "[PT] Epoch 439:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0882 (0.0910)  orig_norm: 0.6116 (0.6621)  iter: 0.1817s  data: 0.0002s\n",
      "[PT] Epoch 439:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 439\n",
      "[PT] Epoch 440:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0904 (0.0904)  orig_norm: 0.5077 (0.5077)  iter: 0.2597s  data: 0.0649s\n",
      "[PT] Epoch 440:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0903 (0.0914)  orig_norm: 0.6311 (0.7091)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 440:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 440\n",
      "[PT] Epoch 441:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0856 (0.0856)  orig_norm: 0.8103 (0.8103)  iter: 0.2545s  data: 0.0593s\n",
      "[PT] Epoch 441:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0851 (0.0897)  orig_norm: 0.6298 (0.7428)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 441:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 441\n",
      "[PT] Epoch 442:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0848 (0.0848)  orig_norm: 0.7790 (0.7790)  iter: 0.2549s  data: 0.0636s\n",
      "[PT] Epoch 442:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0884 (0.0927)  orig_norm: 0.6680 (0.6791)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 442:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 442\n",
      "[PT] Epoch 443:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0866 (0.0866)  orig_norm: 0.5258 (0.5258)  iter: 0.2611s  data: 0.0664s\n",
      "[PT] Epoch 443:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0862 (0.0898)  orig_norm: 0.6208 (0.6606)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 443:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 443\n",
      "[PT] Epoch 444:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0906 (0.0906)  orig_norm: 0.5680 (0.5680)  iter: 0.2439s  data: 0.0493s\n",
      "[PT] Epoch 444:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0887 (0.0904)  orig_norm: 0.6055 (0.6091)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 444:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 444\n",
      "[PT] Epoch 445:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0917 (0.0917)  orig_norm: 0.8700 (0.8700)  iter: 0.2489s  data: 0.0535s\n",
      "[PT] Epoch 445:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0904 (0.0913)  orig_norm: 0.6798 (0.7151)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 445:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 445\n",
      "[PT] Epoch 446:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0874 (0.0874)  orig_norm: 0.6585 (0.6585)  iter: 0.2555s  data: 0.0601s\n",
      "[PT] Epoch 446:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0956 (0.0921)  orig_norm: 0.6628 (0.6725)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 446:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 446\n",
      "[PT] Epoch 447:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0947 (0.0947)  orig_norm: 0.6847 (0.6847)  iter: 0.2597s  data: 0.0669s\n",
      "[PT] Epoch 447:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0940 (0.0929)  orig_norm: 0.6738 (0.6619)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 447:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 447\n",
      "[PT] Epoch 448:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0794 (0.0794)  orig_norm: 0.4183 (0.4183)  iter: 0.2531s  data: 0.0591s\n",
      "[PT] Epoch 448:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0821 (0.0897)  orig_norm: 0.6142 (0.6231)  iter: 0.1819s  data: 0.0002s\n",
      "[PT] Epoch 448:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 448\n",
      "[PT] Epoch 449:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0827 (0.0827)  orig_norm: 0.5001 (0.5001)  iter: 0.2550s  data: 0.0617s\n",
      "[PT] Epoch 449:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0916 (0.0892)  orig_norm: 0.6252 (0.6191)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 449:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 449\n",
      "[PT] Epoch 450:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0857 (0.0857)  orig_norm: 0.6836 (0.6836)  iter: 0.2411s  data: 0.0491s\n",
      "[PT] Epoch 450:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0878 (0.0907)  orig_norm: 0.6063 (0.6299)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 450:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 450\n",
      "[PT] Epoch 451:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.8155 (0.8155)  iter: 0.2558s  data: 0.0594s\n",
      "[PT] Epoch 451:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0867 (0.0904)  orig_norm: 0.6985 (0.7034)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 451:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 451\n",
      "[PT] Epoch 452:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0828 (0.0828)  orig_norm: 0.5469 (0.5469)  iter: 0.2538s  data: 0.0572s\n",
      "[PT] Epoch 452:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0863 (0.0905)  orig_norm: 0.7101 (0.7196)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 452:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 452\n",
      "[PT] Epoch 453:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0885 (0.0885)  orig_norm: 0.7441 (0.7441)  iter: 0.2532s  data: 0.0587s\n",
      "[PT] Epoch 453:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0898 (0.0901)  orig_norm: 0.5877 (0.6404)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 453:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 453\n",
      "[PT] Epoch 454:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0873 (0.0873)  orig_norm: 1.0417 (1.0417)  iter: 0.2566s  data: 0.0610s\n",
      "[PT] Epoch 454:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0912 (0.0907)  orig_norm: 0.6552 (0.7220)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 454:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 454\n",
      "[PT] Epoch 455:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1007 (0.1007)  orig_norm: 0.5570 (0.5570)  iter: 0.2568s  data: 0.0622s\n",
      "[PT] Epoch 455:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0853 (0.0892)  orig_norm: 0.6675 (0.6997)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 455:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 455\n",
      "[PT] Epoch 456:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0965 (0.0965)  orig_norm: 0.6133 (0.6133)  iter: 0.2473s  data: 0.0533s\n",
      "[PT] Epoch 456:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0883 (0.0905)  orig_norm: 0.7204 (0.7372)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 456:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 456\n",
      "[PT] Epoch 457:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1046 (0.1046)  orig_norm: 0.7969 (0.7969)  iter: 0.2616s  data: 0.0654s\n",
      "[PT] Epoch 457:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0888 (0.0909)  orig_norm: 0.6795 (0.6828)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 457:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 457\n",
      "[PT] Epoch 458:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0869 (0.0869)  orig_norm: 0.5207 (0.5207)  iter: 0.2484s  data: 0.0522s\n",
      "[PT] Epoch 458:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0823 (0.0877)  orig_norm: 0.6075 (0.6839)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 458:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 458\n",
      "[PT] Epoch 459:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1104 (0.1104)  orig_norm: 0.6175 (0.6175)  iter: 0.2527s  data: 0.0617s\n",
      "[PT] Epoch 459:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0921 (0.0916)  orig_norm: 0.6785 (0.6846)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 459:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 459\n",
      "[PT] Epoch 460:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0920 (0.0920)  orig_norm: 0.6028 (0.6028)  iter: 0.2555s  data: 0.0602s\n",
      "[PT] Epoch 460:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0894 (0.0886)  orig_norm: 0.6984 (0.6895)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 460:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 460\n",
      "[PT] Epoch 461:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0870 (0.0870)  orig_norm: 0.6036 (0.6036)  iter: 0.2515s  data: 0.0564s\n",
      "[PT] Epoch 461:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0835 (0.0892)  orig_norm: 0.6128 (0.6799)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 461:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 461\n",
      "[PT] Epoch 462:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0721 (0.0721)  orig_norm: 0.4817 (0.4817)  iter: 0.2555s  data: 0.0613s\n",
      "[PT] Epoch 462:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0941 (0.0910)  orig_norm: 0.5978 (0.6356)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 462:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 462\n",
      "[PT] Epoch 463:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1127 (0.1127)  orig_norm: 1.2111 (1.2111)  iter: 0.2507s  data: 0.0595s\n",
      "[PT] Epoch 463:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0878 (0.0897)  orig_norm: 0.6024 (0.6218)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 463:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 463\n",
      "[PT] Epoch 464:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0832 (0.0832)  orig_norm: 0.7316 (0.7316)  iter: 0.2596s  data: 0.0646s\n",
      "[PT] Epoch 464:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0921 (0.0895)  orig_norm: 0.6838 (0.7403)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 464:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 464\n",
      "[PT] Epoch 465:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0967 (0.0967)  orig_norm: 0.7724 (0.7724)  iter: 0.2534s  data: 0.0578s\n",
      "[PT] Epoch 465:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0873 (0.0894)  orig_norm: 0.6289 (0.6648)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 465:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 465\n",
      "[PT] Epoch 466:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0977 (0.0977)  orig_norm: 1.0128 (1.0128)  iter: 0.2589s  data: 0.0632s\n",
      "[PT] Epoch 466:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0896 (0.0906)  orig_norm: 0.6626 (0.7274)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 466:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 466\n",
      "[PT] Epoch 467:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1054 (0.1054)  orig_norm: 1.0037 (1.0037)  iter: 0.2497s  data: 0.0501s\n",
      "[PT] Epoch 467:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0945 (0.0910)  orig_norm: 0.6650 (0.6980)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 467:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 467\n",
      "[PT] Epoch 468:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.7033 (0.7033)  iter: 0.2551s  data: 0.0630s\n",
      "[PT] Epoch 468:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0854 (0.0909)  orig_norm: 0.6842 (0.6934)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 468:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 468\n",
      "[PT] Epoch 469:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0923 (0.0923)  orig_norm: 0.6537 (0.6537)  iter: 0.2636s  data: 0.0680s\n",
      "[PT] Epoch 469:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0869 (0.0900)  orig_norm: 0.6102 (0.6664)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 469:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 469\n",
      "[PT] Epoch 470:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1201 (0.1201)  orig_norm: 0.9190 (0.9190)  iter: 0.2559s  data: 0.0618s\n",
      "[PT] Epoch 470:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0905 (0.0928)  orig_norm: 0.7198 (0.7829)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 470:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 470\n",
      "[PT] Epoch 471:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.4858 (0.4858)  iter: 0.2533s  data: 0.0579s\n",
      "[PT] Epoch 471:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0910 (0.0909)  orig_norm: 0.6714 (0.7401)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 471:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 471\n",
      "[PT] Epoch 472:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0905 (0.0905)  orig_norm: 0.5395 (0.5395)  iter: 0.2573s  data: 0.0643s\n",
      "[PT] Epoch 472:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0869 (0.0908)  orig_norm: 0.7157 (0.7983)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 472:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 472\n",
      "[PT] Epoch 473:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1066 (0.1066)  orig_norm: 0.7130 (0.7130)  iter: 0.2539s  data: 0.0589s\n",
      "[PT] Epoch 473:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0915 (0.0895)  orig_norm: 0.6035 (0.6473)  iter: 0.1843s  data: 0.0002s\n",
      "[PT] Epoch 473:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 473\n",
      "[PT] Epoch 474:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0928 (0.0928)  orig_norm: 0.7479 (0.7479)  iter: 0.2680s  data: 0.0732s\n",
      "[PT] Epoch 474:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0823 (0.0884)  orig_norm: 0.6179 (0.6576)  iter: 0.1854s  data: 0.0002s\n",
      "[PT] Epoch 474:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 474\n",
      "[PT] Epoch 475:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0843 (0.0843)  orig_norm: 0.9341 (0.9341)  iter: 0.2687s  data: 0.0751s\n",
      "[PT] Epoch 475:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0908 (0.0899)  orig_norm: 0.5352 (0.6543)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 475:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 475\n",
      "[PT] Epoch 476:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0966 (0.0966)  orig_norm: 0.8752 (0.8752)  iter: 0.2615s  data: 0.0667s\n",
      "[PT] Epoch 476:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0922 (0.0915)  orig_norm: 0.6523 (0.6528)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 476:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 476\n",
      "[PT] Epoch 477:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0782 (0.0782)  orig_norm: 0.8648 (0.8648)  iter: 0.2563s  data: 0.0635s\n",
      "[PT] Epoch 477:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0906 (0.0904)  orig_norm: 0.7509 (0.7365)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 477:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 477\n",
      "[PT] Epoch 478:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0753 (0.0753)  orig_norm: 0.8761 (0.8761)  iter: 0.2577s  data: 0.0631s\n",
      "[PT] Epoch 478:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0880 (0.0886)  orig_norm: 0.6399 (0.6751)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 478:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 478\n",
      "[PT] Epoch 479:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0823 (0.0823)  orig_norm: 0.8173 (0.8173)  iter: 0.2568s  data: 0.0615s\n",
      "[PT] Epoch 479:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0871 (0.0890)  orig_norm: 0.6665 (0.6497)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 479:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 479\n",
      "[PT] Epoch 480:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0834 (0.0834)  orig_norm: 0.5128 (0.5128)  iter: 0.2647s  data: 0.0720s\n",
      "[PT] Epoch 480:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0864 (0.0898)  orig_norm: 0.6317 (0.6657)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 480:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 480\n",
      "[PT] Epoch 481:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0925 (0.0925)  orig_norm: 0.7611 (0.7611)  iter: 0.2535s  data: 0.0621s\n",
      "[PT] Epoch 481:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0850 (0.0883)  orig_norm: 0.6143 (0.6910)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 481:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 481\n",
      "[PT] Epoch 482:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0903 (0.0903)  orig_norm: 0.6567 (0.6567)  iter: 0.2552s  data: 0.0622s\n",
      "[PT] Epoch 482:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0867 (0.0883)  orig_norm: 0.6029 (0.6537)  iter: 0.1820s  data: 0.0002s\n",
      "[PT] Epoch 482:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 482\n",
      "[PT] Epoch 483:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0988 (0.0988)  orig_norm: 0.7898 (0.7898)  iter: 0.2517s  data: 0.0573s\n",
      "[PT] Epoch 483:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0847 (0.0906)  orig_norm: 0.6425 (0.6671)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 483:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 483\n",
      "[PT] Epoch 484:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0822 (0.0822)  orig_norm: 0.7516 (0.7516)  iter: 0.2616s  data: 0.0647s\n",
      "[PT] Epoch 484:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0892 (0.0893)  orig_norm: 0.6325 (0.6747)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 484:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 484\n",
      "[PT] Epoch 485:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0844 (0.0844)  orig_norm: 0.7526 (0.7526)  iter: 0.2493s  data: 0.0536s\n",
      "[PT] Epoch 485:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0901 (0.0891)  orig_norm: 0.6768 (0.6887)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 485:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 485\n",
      "[PT] Epoch 486:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0893 (0.0893)  orig_norm: 0.4981 (0.4981)  iter: 0.2574s  data: 0.0616s\n",
      "[PT] Epoch 486:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0881 (0.0891)  orig_norm: 0.6662 (0.6742)  iter: 0.1851s  data: 0.0002s\n",
      "[PT] Epoch 486:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 486\n",
      "[PT] Epoch 487:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0911 (0.0911)  orig_norm: 0.6977 (0.6977)  iter: 0.2619s  data: 0.0694s\n",
      "[PT] Epoch 487:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0836 (0.0861)  orig_norm: 0.7148 (0.7052)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 487:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 487\n",
      "[PT] Epoch 488:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0984 (0.0984)  orig_norm: 1.4443 (1.4443)  iter: 0.2527s  data: 0.0556s\n",
      "[PT] Epoch 488:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0836 (0.0892)  orig_norm: 0.6584 (0.7190)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 488:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 488\n",
      "[PT] Epoch 489:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0911 (0.0911)  orig_norm: 0.8635 (0.8635)  iter: 0.2481s  data: 0.0522s\n",
      "[PT] Epoch 489:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0874 (0.0891)  orig_norm: 0.7007 (0.7293)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 489:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 489\n",
      "[PT] Epoch 490:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0967 (0.0967)  orig_norm: 0.9429 (0.9429)  iter: 0.2565s  data: 0.0631s\n",
      "[PT] Epoch 490:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0920 (0.0907)  orig_norm: 0.7648 (0.7198)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 490:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 490\n",
      "[PT] Epoch 491:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.0985 (0.0985)  orig_norm: 0.8624 (0.8624)  iter: 0.2810s  data: 0.0841s\n",
      "[PT] Epoch 491:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0931 (0.0900)  orig_norm: 0.6447 (0.7572)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 491:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 491\n",
      "[PT] Epoch 492:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0849 (0.0849)  orig_norm: 0.5245 (0.5245)  iter: 0.2543s  data: 0.0635s\n",
      "[PT] Epoch 492:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0875 (0.0904)  orig_norm: 0.6380 (0.7348)  iter: 0.1829s  data: 0.0002s\n",
      "[PT] Epoch 492:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 492\n",
      "[PT] Epoch 493:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0920 (0.0920)  orig_norm: 0.5180 (0.5180)  iter: 0.2581s  data: 0.0630s\n",
      "[PT] Epoch 493:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0848 (0.0892)  orig_norm: 0.7122 (0.7285)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 493:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 493\n",
      "[PT] Epoch 494:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0917 (0.0917)  orig_norm: 0.6452 (0.6452)  iter: 0.2531s  data: 0.0594s\n",
      "[PT] Epoch 494:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0873 (0.0869)  orig_norm: 0.5755 (0.6626)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 494:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 494\n",
      "[PT] Epoch 495:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0913 (0.0913)  orig_norm: 0.6414 (0.6414)  iter: 0.2577s  data: 0.0629s\n",
      "[PT] Epoch 495:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0901 (0.0890)  orig_norm: 0.6790 (0.7047)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 495:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 495\n",
      "[PT] Epoch 496:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0888 (0.0888)  orig_norm: 0.8043 (0.8043)  iter: 0.2534s  data: 0.0578s\n",
      "[PT] Epoch 496:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0826 (0.0871)  orig_norm: 0.5879 (0.6718)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 496:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 496\n",
      "[PT] Epoch 497:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0834 (0.0834)  orig_norm: 0.9987 (0.9987)  iter: 0.2503s  data: 0.0588s\n",
      "[PT] Epoch 497:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0855 (0.0869)  orig_norm: 0.6592 (0.6662)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 497:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 497\n",
      "[PT] Epoch 498:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0773 (0.0773)  orig_norm: 0.6011 (0.6011)  iter: 0.2524s  data: 0.0578s\n",
      "[PT] Epoch 498:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0877 (0.0899)  orig_norm: 0.6563 (0.6546)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 498:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 498\n",
      "[PT] Epoch 499:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0790 (0.0790)  orig_norm: 0.5650 (0.5650)  iter: 0.2567s  data: 0.0665s\n",
      "[PT] Epoch 499:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0847 (0.0870)  orig_norm: 0.6101 (0.6534)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 499:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 499\n",
      "[PT] Epoch 500:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1072 (0.1072)  orig_norm: 0.6096 (0.6096)  iter: 0.2554s  data: 0.0600s\n",
      "[PT] Epoch 500:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0863 (0.0911)  orig_norm: 0.5850 (0.7289)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 500:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 500\n",
      "[PT] Epoch 501:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0985 (0.0985)  orig_norm: 0.6149 (0.6149)  iter: 0.2539s  data: 0.0581s\n",
      "[PT] Epoch 501:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0936 (0.0911)  orig_norm: 0.6663 (0.6844)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 501:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 501\n",
      "[PT] Epoch 502:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0798 (0.0798)  orig_norm: 0.6998 (0.6998)  iter: 0.2510s  data: 0.0538s\n",
      "[PT] Epoch 502:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0882 (0.0917)  orig_norm: 0.6425 (0.7255)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 502:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 502\n",
      "[PT] Epoch 503:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0940 (0.0940)  orig_norm: 0.5343 (0.5343)  iter: 0.2585s  data: 0.0622s\n",
      "[PT] Epoch 503:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0884 (0.0886)  orig_norm: 0.5935 (0.6724)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 503:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 503\n",
      "[PT] Epoch 504:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0846 (0.0846)  orig_norm: 0.4528 (0.4528)  iter: 0.2630s  data: 0.0666s\n",
      "[PT] Epoch 504:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0836 (0.0854)  orig_norm: 0.6386 (0.6573)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 504:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 504\n",
      "[PT] Epoch 505:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0890 (0.0890)  orig_norm: 0.7023 (0.7023)  iter: 0.2600s  data: 0.0665s\n",
      "[PT] Epoch 505:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0867 (0.0876)  orig_norm: 0.7280 (0.7077)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 505:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 505\n",
      "[PT] Epoch 506:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0792 (0.0792)  orig_norm: 0.4171 (0.4171)  iter: 0.2543s  data: 0.0589s\n",
      "[PT] Epoch 506:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0842 (0.0882)  orig_norm: 0.6925 (0.7021)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 506:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 506\n",
      "[PT] Epoch 507:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0827 (0.0827)  orig_norm: 0.6242 (0.6242)  iter: 0.2566s  data: 0.0603s\n",
      "[PT] Epoch 507:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0834 (0.0872)  orig_norm: 0.7094 (0.7172)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 507:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 507\n",
      "[PT] Epoch 508:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0896 (0.0896)  orig_norm: 0.6614 (0.6614)  iter: 0.2603s  data: 0.0647s\n",
      "[PT] Epoch 508:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0848 (0.0883)  orig_norm: 0.7056 (0.7116)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 508:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 508\n",
      "[PT] Epoch 509:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0683 (0.0683)  orig_norm: 0.6382 (0.6382)  iter: 0.2552s  data: 0.0588s\n",
      "[PT] Epoch 509:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0925 (0.0879)  orig_norm: 0.6148 (0.6381)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 509:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 509\n",
      "[PT] Epoch 510:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0915 (0.0915)  orig_norm: 0.5352 (0.5352)  iter: 0.2474s  data: 0.0534s\n",
      "[PT] Epoch 510:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0837 (0.0865)  orig_norm: 0.6189 (0.6645)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 510:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 510\n",
      "[PT] Epoch 511:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0883 (0.0883)  orig_norm: 0.5931 (0.5931)  iter: 0.2424s  data: 0.0520s\n",
      "[PT] Epoch 511:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0915 (0.0887)  orig_norm: 0.6441 (0.6806)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 511:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 511\n",
      "[PT] Epoch 512:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0860 (0.0860)  orig_norm: 0.6760 (0.6760)  iter: 0.2559s  data: 0.0610s\n",
      "[PT] Epoch 512:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0827 (0.0870)  orig_norm: 0.6904 (0.7385)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 512:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 512\n",
      "[PT] Epoch 513:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1043 (0.1043)  orig_norm: 1.2878 (1.2878)  iter: 0.2596s  data: 0.0658s\n",
      "[PT] Epoch 513:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0853 (0.0889)  orig_norm: 0.5988 (0.7448)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 513:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 513\n",
      "[PT] Epoch 514:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0829 (0.0829)  orig_norm: 0.6637 (0.6637)  iter: 0.2594s  data: 0.0659s\n",
      "[PT] Epoch 514:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0890 (0.0891)  orig_norm: 0.6822 (0.7664)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 514:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 514\n",
      "[PT] Epoch 515:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0816 (0.0816)  orig_norm: 0.5689 (0.5689)  iter: 0.2542s  data: 0.0618s\n",
      "[PT] Epoch 515:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0818 (0.0864)  orig_norm: 0.5900 (0.6645)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 515:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 515\n",
      "[PT] Epoch 516:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0814 (0.0814)  orig_norm: 0.6129 (0.6129)  iter: 0.2581s  data: 0.0638s\n",
      "[PT] Epoch 516:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0854 (0.0886)  orig_norm: 0.7139 (0.6542)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 516:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 516\n",
      "[PT] Epoch 517:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0822 (0.0822)  orig_norm: 0.5688 (0.5688)  iter: 0.2543s  data: 0.0586s\n",
      "[PT] Epoch 517:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0865 (0.0876)  orig_norm: 0.5737 (0.6462)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 517:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 517\n",
      "[PT] Epoch 518:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0769 (0.0769)  orig_norm: 0.7406 (0.7406)  iter: 0.2575s  data: 0.0639s\n",
      "[PT] Epoch 518:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0882 (0.0866)  orig_norm: 0.8236 (0.7747)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 518:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 518\n",
      "[PT] Epoch 519:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0949 (0.0949)  orig_norm: 0.7219 (0.7219)  iter: 0.2486s  data: 0.0556s\n",
      "[PT] Epoch 519:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0853 (0.0851)  orig_norm: 0.6538 (0.7036)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 519:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 519\n",
      "[PT] Epoch 520:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1032 (0.1032)  orig_norm: 0.8315 (0.8315)  iter: 0.2486s  data: 0.0543s\n",
      "[PT] Epoch 520:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0876 (0.0883)  orig_norm: 0.6683 (0.7100)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 520:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 520\n",
      "[PT] Epoch 521:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0787 (0.0787)  orig_norm: 0.5012 (0.5012)  iter: 0.2579s  data: 0.0621s\n",
      "[PT] Epoch 521:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0875 (0.0884)  orig_norm: 0.6844 (0.6853)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 521:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 521\n",
      "[PT] Epoch 522:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0810 (0.0810)  orig_norm: 0.5619 (0.5619)  iter: 0.2561s  data: 0.0608s\n",
      "[PT] Epoch 522:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0900 (0.0886)  orig_norm: 0.7682 (0.7385)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 522:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 522\n",
      "[PT] Epoch 523:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0831 (0.0831)  orig_norm: 0.9565 (0.9565)  iter: 0.2591s  data: 0.0651s\n",
      "[PT] Epoch 523:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0858 (0.0878)  orig_norm: 0.7019 (0.7221)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 523:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 523\n",
      "[PT] Epoch 524:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0799 (0.0799)  orig_norm: 0.6076 (0.6076)  iter: 0.2537s  data: 0.0577s\n",
      "[PT] Epoch 524:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0866 (0.0872)  orig_norm: 0.6164 (0.6883)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 524:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 524\n",
      "[PT] Epoch 525:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0913 (0.0913)  orig_norm: 0.5105 (0.5105)  iter: 0.2535s  data: 0.0596s\n",
      "[PT] Epoch 525:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0841 (0.0865)  orig_norm: 0.6368 (0.7071)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 525:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 525\n",
      "[PT] Epoch 526:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0942 (0.0942)  orig_norm: 0.5396 (0.5396)  iter: 0.2563s  data: 0.0610s\n",
      "[PT] Epoch 526:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0846 (0.0878)  orig_norm: 0.6451 (0.6815)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 526:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 526\n",
      "[PT] Epoch 527:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0771 (0.0771)  orig_norm: 0.5935 (0.5935)  iter: 0.2525s  data: 0.0599s\n",
      "[PT] Epoch 527:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0836 (0.0858)  orig_norm: 0.6484 (0.7273)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 527:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 527\n",
      "[PT] Epoch 528:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0801 (0.0801)  orig_norm: 0.5412 (0.5412)  iter: 0.2564s  data: 0.0609s\n",
      "[PT] Epoch 528:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0913 (0.0892)  orig_norm: 0.6685 (0.7282)  iter: 0.1846s  data: 0.0002s\n",
      "[PT] Epoch 528:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 528\n",
      "[PT] Epoch 529:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0812 (0.0812)  orig_norm: 0.4834 (0.4834)  iter: 0.2505s  data: 0.0591s\n",
      "[PT] Epoch 529:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0880 (0.0871)  orig_norm: 0.6000 (0.6492)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 529:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 529\n",
      "[PT] Epoch 530:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0860 (0.0860)  orig_norm: 0.7125 (0.7125)  iter: 0.2557s  data: 0.0598s\n",
      "[PT] Epoch 530:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0816 (0.0879)  orig_norm: 0.6230 (0.6922)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 530:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 530\n",
      "[PT] Epoch 531:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1221 (0.1221)  orig_norm: 0.7636 (0.7636)  iter: 0.2601s  data: 0.0647s\n",
      "[PT] Epoch 531:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0881 (0.0877)  orig_norm: 0.6875 (0.6804)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 531:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 531\n",
      "[PT] Epoch 532:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0853 (0.0853)  orig_norm: 0.7256 (0.7256)  iter: 0.2576s  data: 0.0597s\n",
      "[PT] Epoch 532:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0880 (0.0891)  orig_norm: 0.6319 (0.7160)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 532:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 532\n",
      "[PT] Epoch 533:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0742 (0.0742)  orig_norm: 0.6786 (0.6786)  iter: 0.2542s  data: 0.0634s\n",
      "[PT] Epoch 533:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0855 (0.0874)  orig_norm: 0.7041 (0.7036)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 533:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 533\n",
      "[PT] Epoch 534:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0840 (0.0840)  orig_norm: 0.9363 (0.9363)  iter: 0.2628s  data: 0.0664s\n",
      "[PT] Epoch 534:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0904 (0.0880)  orig_norm: 0.6679 (0.6965)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 534:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 534\n",
      "[PT] Epoch 535:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0842 (0.0842)  orig_norm: 0.6421 (0.6421)  iter: 0.2554s  data: 0.0613s\n",
      "[PT] Epoch 535:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0895 (0.0870)  orig_norm: 0.6225 (0.7040)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 535:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 535\n",
      "[PT] Epoch 536:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0972 (0.0972)  orig_norm: 0.7091 (0.7091)  iter: 0.2615s  data: 0.0707s\n",
      "[PT] Epoch 536:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0849 (0.0881)  orig_norm: 0.6055 (0.7109)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 536:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 536\n",
      "[PT] Epoch 537:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0807 (0.0807)  orig_norm: 0.6797 (0.6797)  iter: 0.2565s  data: 0.0619s\n",
      "[PT] Epoch 537:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0875 (0.0863)  orig_norm: 0.6684 (0.6731)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 537:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 537\n",
      "[PT] Epoch 538:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0857 (0.0857)  orig_norm: 0.6305 (0.6305)  iter: 0.2526s  data: 0.0580s\n",
      "[PT] Epoch 538:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0819 (0.0850)  orig_norm: 0.6375 (0.7043)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 538:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 538\n",
      "[PT] Epoch 539:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0938 (0.0938)  orig_norm: 0.7188 (0.7188)  iter: 0.2568s  data: 0.0596s\n",
      "[PT] Epoch 539:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0873 (0.0875)  orig_norm: 0.7008 (0.7032)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 539:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 539\n",
      "[PT] Epoch 540:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0863 (0.0863)  orig_norm: 0.6481 (0.6481)  iter: 0.2616s  data: 0.0681s\n",
      "[PT] Epoch 540:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0871 (0.0888)  orig_norm: 0.6712 (0.7282)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 540:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 540\n",
      "[PT] Epoch 541:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1001 (0.1001)  orig_norm: 1.2712 (1.2712)  iter: 0.2549s  data: 0.0613s\n",
      "[PT] Epoch 541:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0853 (0.0897)  orig_norm: 1.0637 (0.8728)  iter: 0.1831s  data: 0.0002s\n",
      "[PT] Epoch 541:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 541\n",
      "[PT] Epoch 542:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0704 (0.0704)  orig_norm: 0.7266 (0.7266)  iter: 0.2563s  data: 0.0599s\n",
      "[PT] Epoch 542:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0845 (0.0865)  orig_norm: 0.7028 (0.7593)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 542:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 542\n",
      "[PT] Epoch 543:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0838 (0.0838)  orig_norm: 0.8136 (0.8136)  iter: 0.2610s  data: 0.0629s\n",
      "[PT] Epoch 543:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0889 (0.0882)  orig_norm: 0.6458 (0.6942)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 543:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 543\n",
      "[PT] Epoch 544:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0871 (0.0871)  orig_norm: 0.6214 (0.6214)  iter: 0.2549s  data: 0.0592s\n",
      "[PT] Epoch 544:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0837 (0.0863)  orig_norm: 0.6861 (0.7060)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 544:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 544\n",
      "[PT] Epoch 545:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0802 (0.0802)  orig_norm: 0.8774 (0.8774)  iter: 0.2554s  data: 0.0586s\n",
      "[PT] Epoch 545:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0876 (0.0859)  orig_norm: 0.6224 (0.7350)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 545:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 545\n",
      "[PT] Epoch 546:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1145 (0.1145)  orig_norm: 1.2783 (1.2783)  iter: 0.2589s  data: 0.0641s\n",
      "[PT] Epoch 546:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0858 (0.0877)  orig_norm: 0.6733 (0.7688)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 546:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 546\n",
      "[PT] Epoch 547:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1043 (0.1043)  orig_norm: 0.9747 (0.9747)  iter: 0.2568s  data: 0.0643s\n",
      "[PT] Epoch 547:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0880 (0.0873)  orig_norm: 0.6909 (0.7128)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 547:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 547\n",
      "[PT] Epoch 548:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0860 (0.0860)  orig_norm: 0.6158 (0.6158)  iter: 0.2601s  data: 0.0657s\n",
      "[PT] Epoch 548:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0854 (0.0864)  orig_norm: 0.6185 (0.6583)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 548:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 548\n",
      "[PT] Epoch 549:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0760 (0.0760)  orig_norm: 0.4902 (0.4902)  iter: 0.2485s  data: 0.0564s\n",
      "[PT] Epoch 549:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0861 (0.0875)  orig_norm: 0.7229 (0.7481)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 549:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 549\n",
      "[PT] Epoch 550:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.5990 (0.5990)  iter: 0.2552s  data: 0.0644s\n",
      "[PT] Epoch 550:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0852 (0.0859)  orig_norm: 0.6927 (0.7348)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 550:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 550\n",
      "[PT] Epoch 551:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1073 (0.1073)  orig_norm: 0.9369 (0.9369)  iter: 0.2528s  data: 0.0574s\n",
      "[PT] Epoch 551:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0872 (0.0874)  orig_norm: 0.6686 (0.6721)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 551:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 551\n",
      "[PT] Epoch 552:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0859 (0.0859)  orig_norm: 0.5422 (0.5422)  iter: 0.2575s  data: 0.0612s\n",
      "[PT] Epoch 552:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0815 (0.0855)  orig_norm: 0.5747 (0.6996)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 552:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 552\n",
      "[PT] Epoch 553:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0867 (0.0867)  orig_norm: 0.5161 (0.5161)  iter: 0.2502s  data: 0.0573s\n",
      "[PT] Epoch 553:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0831 (0.0863)  orig_norm: 0.7578 (0.7572)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 553:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 553\n",
      "[PT] Epoch 554:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0835 (0.0835)  orig_norm: 0.9281 (0.9281)  iter: 0.2495s  data: 0.0563s\n",
      "[PT] Epoch 554:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0880 (0.0854)  orig_norm: 0.6612 (0.6814)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 554:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 554\n",
      "[PT] Epoch 555:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0876 (0.0876)  orig_norm: 1.4931 (1.4931)  iter: 0.2556s  data: 0.0617s\n",
      "[PT] Epoch 555:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0839 (0.0869)  orig_norm: 0.6717 (0.7333)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 555:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 555\n",
      "[PT] Epoch 556:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0866 (0.0866)  orig_norm: 0.9790 (0.9790)  iter: 0.2544s  data: 0.0590s\n",
      "[PT] Epoch 556:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0821 (0.0834)  orig_norm: 0.6456 (0.7001)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 556:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 556\n",
      "[PT] Epoch 557:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0715 (0.0715)  orig_norm: 0.6345 (0.6345)  iter: 0.2589s  data: 0.0646s\n",
      "[PT] Epoch 557:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0828 (0.0852)  orig_norm: 0.6812 (0.6861)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 557:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 557\n",
      "[PT] Epoch 558:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0724 (0.0724)  orig_norm: 0.6197 (0.6197)  iter: 0.2549s  data: 0.0642s\n",
      "[PT] Epoch 558:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0829 (0.0857)  orig_norm: 0.6767 (0.7320)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 558:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 558\n",
      "[PT] Epoch 559:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0921 (0.0921)  orig_norm: 0.5905 (0.5905)  iter: 0.2464s  data: 0.0504s\n",
      "[PT] Epoch 559:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0860 (0.0872)  orig_norm: 0.6084 (0.6639)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 559:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 559\n",
      "[PT] Epoch 560:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0859 (0.0859)  orig_norm: 0.5858 (0.5858)  iter: 0.2607s  data: 0.0687s\n",
      "[PT] Epoch 560:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0867 (0.0891)  orig_norm: 0.6400 (0.6692)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 560:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 560\n",
      "[PT] Epoch 561:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0795 (0.0795)  orig_norm: 0.6024 (0.6024)  iter: 0.2560s  data: 0.0620s\n",
      "[PT] Epoch 561:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0851 (0.0873)  orig_norm: 0.5948 (0.6487)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 561:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 561\n",
      "[PT] Epoch 562:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0712 (0.0712)  orig_norm: 0.5848 (0.5848)  iter: 0.2596s  data: 0.0638s\n",
      "[PT] Epoch 562:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0813 (0.0843)  orig_norm: 0.6353 (0.6514)  iter: 0.1839s  data: 0.0001s\n",
      "[PT] Epoch 562:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 562\n",
      "[PT] Epoch 563:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0839 (0.0839)  orig_norm: 0.6741 (0.6741)  iter: 0.2642s  data: 0.0683s\n",
      "[PT] Epoch 563:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0877 (0.0880)  orig_norm: 0.6816 (0.7204)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 563:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 563\n",
      "[PT] Epoch 564:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0807 (0.0807)  orig_norm: 0.9431 (0.9431)  iter: 0.2714s  data: 0.0759s\n",
      "[PT] Epoch 564:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0868 (0.0859)  orig_norm: 0.7857 (0.7510)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 564:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 564\n",
      "[PT] Epoch 565:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1043 (0.1043)  orig_norm: 0.5436 (0.5436)  iter: 0.2604s  data: 0.0669s\n",
      "[PT] Epoch 565:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0858 (0.0859)  orig_norm: 0.6864 (0.6839)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 565:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 565\n",
      "[PT] Epoch 566:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0952 (0.0952)  orig_norm: 1.3058 (1.3058)  iter: 0.2608s  data: 0.0659s\n",
      "[PT] Epoch 566:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0794 (0.0860)  orig_norm: 0.5923 (0.7080)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 566:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 566\n",
      "[PT] Epoch 567:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1036 (0.1036)  orig_norm: 0.8763 (0.8763)  iter: 0.2594s  data: 0.0657s\n",
      "[PT] Epoch 567:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0855 (0.0852)  orig_norm: 0.6036 (0.6645)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 567:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 567\n",
      "[PT] Epoch 568:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0914 (0.0914)  orig_norm: 0.5528 (0.5528)  iter: 0.2586s  data: 0.0634s\n",
      "[PT] Epoch 568:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0805 (0.0863)  orig_norm: 0.6265 (0.6368)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 568:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 568\n",
      "[PT] Epoch 569:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0923 (0.0923)  orig_norm: 0.6166 (0.6166)  iter: 0.2526s  data: 0.0563s\n",
      "[PT] Epoch 569:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0886 (0.0858)  orig_norm: 0.6541 (0.6767)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 569:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 569\n",
      "[PT] Epoch 570:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0903 (0.0903)  orig_norm: 0.6484 (0.6484)  iter: 0.2527s  data: 0.0568s\n",
      "[PT] Epoch 570:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0795 (0.0844)  orig_norm: 0.6143 (0.6766)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 570:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 570\n",
      "[PT] Epoch 571:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0741 (0.0741)  orig_norm: 0.6716 (0.6716)  iter: 0.2608s  data: 0.0669s\n",
      "[PT] Epoch 571:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0864 (0.0862)  orig_norm: 0.6154 (0.6848)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 571:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 571\n",
      "[PT] Epoch 572:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0943 (0.0943)  orig_norm: 0.7609 (0.7609)  iter: 0.2539s  data: 0.0592s\n",
      "[PT] Epoch 572:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0872 (0.0874)  orig_norm: 0.6976 (0.7124)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 572:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 572\n",
      "[PT] Epoch 573:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1004 (0.1004)  orig_norm: 0.6109 (0.6109)  iter: 0.2531s  data: 0.0587s\n",
      "[PT] Epoch 573:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0806 (0.0855)  orig_norm: 0.6625 (0.7041)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 573:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 573\n",
      "[PT] Epoch 574:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1021 (0.1021)  orig_norm: 0.8187 (0.8187)  iter: 0.2537s  data: 0.0581s\n",
      "[PT] Epoch 574:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0877 (0.0873)  orig_norm: 0.6845 (0.7232)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 574:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 574\n",
      "[PT] Epoch 575:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0671 (0.0671)  orig_norm: 0.7064 (0.7064)  iter: 0.2524s  data: 0.0581s\n",
      "[PT] Epoch 575:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0850 (0.0860)  orig_norm: 0.6739 (0.6939)  iter: 0.1845s  data: 0.0002s\n",
      "[PT] Epoch 575:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 575\n",
      "[PT] Epoch 576:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1149 (0.1149)  orig_norm: 1.1260 (1.1260)  iter: 0.2632s  data: 0.0689s\n",
      "[PT] Epoch 576:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0785 (0.0842)  orig_norm: 0.6182 (0.7036)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 576:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 576\n",
      "[PT] Epoch 577:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0820 (0.0820)  orig_norm: 0.5756 (0.5756)  iter: 0.2589s  data: 0.0668s\n",
      "[PT] Epoch 577:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0783 (0.0838)  orig_norm: 0.6064 (0.6645)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 577:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 577\n",
      "[PT] Epoch 578:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0893 (0.0893)  orig_norm: 0.9193 (0.9193)  iter: 0.2582s  data: 0.0628s\n",
      "[PT] Epoch 578:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0837 (0.0868)  orig_norm: 0.6752 (0.7719)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 578:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 578\n",
      "[PT] Epoch 579:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0862 (0.0862)  orig_norm: 0.7485 (0.7485)  iter: 0.2622s  data: 0.0607s\n",
      "[PT] Epoch 579:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0803 (0.0844)  orig_norm: 0.6860 (0.7097)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 579:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 579\n",
      "[PT] Epoch 580:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0867 (0.0867)  orig_norm: 0.6030 (0.6030)  iter: 0.2561s  data: 0.0586s\n",
      "[PT] Epoch 580:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0885 (0.0870)  orig_norm: 0.7407 (0.7420)  iter: 0.1829s  data: 0.0002s\n",
      "[PT] Epoch 580:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 580\n",
      "[PT] Epoch 581:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0900 (0.0900)  orig_norm: 0.4542 (0.4542)  iter: 0.2549s  data: 0.0614s\n",
      "[PT] Epoch 581:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0846 (0.0862)  orig_norm: 0.6546 (0.6966)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 581:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 581\n",
      "[PT] Epoch 582:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0983 (0.0983)  orig_norm: 0.6454 (0.6454)  iter: 0.2553s  data: 0.0609s\n",
      "[PT] Epoch 582:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0832 (0.0856)  orig_norm: 0.6200 (0.6962)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 582:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 582\n",
      "[PT] Epoch 583:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.1071 (0.1071)  orig_norm: 0.9227 (0.9227)  iter: 0.2430s  data: 0.0529s\n",
      "[PT] Epoch 583:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0877 (0.0864)  orig_norm: 0.6552 (0.6577)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 583:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 583\n",
      "[PT] Epoch 584:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.1010 (0.1010)  orig_norm: 0.7785 (0.7785)  iter: 0.2612s  data: 0.0644s\n",
      "[PT] Epoch 584:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0803 (0.0855)  orig_norm: 0.6793 (0.7343)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 584:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 584\n",
      "[PT] Epoch 585:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0806 (0.0806)  orig_norm: 0.5256 (0.5256)  iter: 0.2591s  data: 0.0652s\n",
      "[PT] Epoch 585:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0809 (0.0874)  orig_norm: 0.6312 (0.6938)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 585:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 585\n",
      "[PT] Epoch 586:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0940 (0.0940)  orig_norm: 0.9008 (0.9008)  iter: 0.2577s  data: 0.0639s\n",
      "[PT] Epoch 586:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0851 (0.0859)  orig_norm: 0.6295 (0.6950)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 586:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 586\n",
      "[PT] Epoch 587:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0773 (0.0773)  orig_norm: 0.5194 (0.5194)  iter: 0.2624s  data: 0.0670s\n",
      "[PT] Epoch 587:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0831 (0.0863)  orig_norm: 0.5965 (0.6734)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 587:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 587\n",
      "[PT] Epoch 588:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0996 (0.0996)  orig_norm: 0.7075 (0.7075)  iter: 0.2668s  data: 0.0738s\n",
      "[PT] Epoch 588:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0850 (0.0851)  orig_norm: 0.6427 (0.6746)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 588:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 588\n",
      "[PT] Epoch 589:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0671 (0.0671)  orig_norm: 0.5627 (0.5627)  iter: 0.2545s  data: 0.0600s\n",
      "[PT] Epoch 589:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0860 (0.0849)  orig_norm: 0.6971 (0.7121)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 589:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 589\n",
      "[PT] Epoch 590:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0992 (0.0992)  orig_norm: 1.1262 (1.1262)  iter: 0.2573s  data: 0.0622s\n",
      "[PT] Epoch 590:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0788 (0.0842)  orig_norm: 0.7429 (0.7643)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 590:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 590\n",
      "[PT] Epoch 591:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0885 (0.0885)  orig_norm: 0.9633 (0.9633)  iter: 0.2586s  data: 0.0643s\n",
      "[PT] Epoch 591:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0868 (0.0872)  orig_norm: 0.6036 (0.6959)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 591:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 591\n",
      "[PT] Epoch 592:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0766 (0.0766)  orig_norm: 0.7625 (0.7625)  iter: 0.2686s  data: 0.0669s\n",
      "[PT] Epoch 592:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0859 (0.0881)  orig_norm: 0.6698 (0.7447)  iter: 0.1845s  data: 0.0001s\n",
      "[PT] Epoch 592:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 592\n",
      "[PT] Epoch 593:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0762 (0.0762)  orig_norm: 0.6575 (0.6575)  iter: 0.2649s  data: 0.0678s\n",
      "[PT] Epoch 593:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0774 (0.0835)  orig_norm: 0.6553 (0.6820)  iter: 0.1837s  data: 0.0002s\n",
      "[PT] Epoch 593:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 593\n",
      "[PT] Epoch 594:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0993 (0.0993)  orig_norm: 0.7456 (0.7456)  iter: 0.2568s  data: 0.0608s\n",
      "[PT] Epoch 594:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0811 (0.0837)  orig_norm: 0.6558 (0.7050)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 594:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 594\n",
      "[PT] Epoch 595:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0794 (0.0794)  orig_norm: 0.6705 (0.6705)  iter: 0.2577s  data: 0.0614s\n",
      "[PT] Epoch 595:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0834 (0.0862)  orig_norm: 0.6769 (0.6827)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 595:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 595\n",
      "[PT] Epoch 596:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0885 (0.0885)  orig_norm: 0.7430 (0.7430)  iter: 0.2463s  data: 0.0534s\n",
      "[PT] Epoch 596:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0864 (0.0836)  orig_norm: 0.6549 (0.6691)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 596:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 596\n",
      "[PT] Epoch 597:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0964 (0.0964)  orig_norm: 0.6385 (0.6385)  iter: 0.2562s  data: 0.0656s\n",
      "[PT] Epoch 597:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0814 (0.0860)  orig_norm: 0.6392 (0.7220)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 597:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 597\n",
      "[PT] Epoch 598:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0820 (0.0820)  orig_norm: 0.7179 (0.7179)  iter: 0.2528s  data: 0.0565s\n",
      "[PT] Epoch 598:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0839 (0.0855)  orig_norm: 0.5711 (0.6852)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 598:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 598\n",
      "[PT] Epoch 599:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0855 (0.0855)  orig_norm: 0.6171 (0.6171)  iter: 0.2584s  data: 0.0642s\n",
      "[PT] Epoch 599:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0827 (0.0829)  orig_norm: 0.6518 (0.6543)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 599:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 599\n",
      "[PT] Epoch 600:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0858 (0.0858)  orig_norm: 0.4586 (0.4586)  iter: 0.2534s  data: 0.0590s\n",
      "[PT] Epoch 600:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0806 (0.0850)  orig_norm: 0.6604 (0.7115)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 600:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 600\n",
      "[PT] Epoch 601:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0728 (0.0728)  orig_norm: 0.7320 (0.7320)  iter: 0.2614s  data: 0.0651s\n",
      "[PT] Epoch 601:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0857 (0.0852)  orig_norm: 0.6274 (0.6311)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 601:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 601\n",
      "[PT] Epoch 602:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0782 (0.0782)  orig_norm: 0.9845 (0.9845)  iter: 0.2554s  data: 0.0637s\n",
      "[PT] Epoch 602:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0813 (0.0838)  orig_norm: 0.6046 (0.6793)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 602:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 602\n",
      "[PT] Epoch 603:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0869 (0.0869)  orig_norm: 0.6291 (0.6291)  iter: 0.2527s  data: 0.0607s\n",
      "[PT] Epoch 603:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0809 (0.0841)  orig_norm: 0.5853 (0.6620)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 603:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 603\n",
      "[PT] Epoch 604:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0781 (0.0781)  orig_norm: 0.6774 (0.6774)  iter: 0.2577s  data: 0.0614s\n",
      "[PT] Epoch 604:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0838 (0.0858)  orig_norm: 0.6518 (0.6899)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 604:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 604\n",
      "[PT] Epoch 605:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0985 (0.0985)  orig_norm: 0.8836 (0.8836)  iter: 0.2530s  data: 0.0636s\n",
      "[PT] Epoch 605:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0799 (0.0846)  orig_norm: 0.5750 (0.6852)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 605:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 605\n",
      "[PT] Epoch 606:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0762 (0.0762)  orig_norm: 0.5451 (0.5451)  iter: 0.2548s  data: 0.0583s\n",
      "[PT] Epoch 606:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0822 (0.0844)  orig_norm: 0.6602 (0.6801)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 606:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 606\n",
      "[PT] Epoch 607:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0987 (0.0987)  orig_norm: 0.9021 (0.9021)  iter: 0.2579s  data: 0.0643s\n",
      "[PT] Epoch 607:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0829 (0.0842)  orig_norm: 0.6883 (0.6759)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 607:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 607\n",
      "[PT] Epoch 608:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0901 (0.0901)  orig_norm: 0.6703 (0.6703)  iter: 0.2634s  data: 0.0669s\n",
      "[PT] Epoch 608:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0805 (0.0842)  orig_norm: 0.6888 (0.7024)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 608:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 608\n",
      "[PT] Epoch 609:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1181 (0.1181)  orig_norm: 0.8920 (0.8920)  iter: 0.2550s  data: 0.0604s\n",
      "[PT] Epoch 609:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0762 (0.0835)  orig_norm: 0.6898 (0.6904)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 609:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 609\n",
      "[PT] Epoch 610:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0801 (0.0801)  orig_norm: 0.4850 (0.4850)  iter: 0.2556s  data: 0.0605s\n",
      "[PT] Epoch 610:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0835 (0.0849)  orig_norm: 0.7079 (0.6979)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 610:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 610\n",
      "[PT] Epoch 611:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0780 (0.0780)  orig_norm: 0.8778 (0.8778)  iter: 0.2604s  data: 0.0661s\n",
      "[PT] Epoch 611:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0861 (0.0855)  orig_norm: 0.7058 (0.6673)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 611:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 611\n",
      "[PT] Epoch 612:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0833 (0.0833)  orig_norm: 0.7098 (0.7098)  iter: 0.2556s  data: 0.0656s\n",
      "[PT] Epoch 612:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0843 (0.0855)  orig_norm: 0.6320 (0.6600)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 612:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 612\n",
      "[PT] Epoch 613:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0829 (0.0829)  orig_norm: 0.5070 (0.5070)  iter: 0.2575s  data: 0.0627s\n",
      "[PT] Epoch 613:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0819 (0.0850)  orig_norm: 0.6255 (0.6587)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 613:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 613\n",
      "[PT] Epoch 614:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 1.1213 (1.1213)  iter: 0.2629s  data: 0.0693s\n",
      "[PT] Epoch 614:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0821 (0.0829)  orig_norm: 0.6841 (0.6892)  iter: 0.1844s  data: 0.0002s\n",
      "[PT] Epoch 614:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 614\n",
      "[PT] Epoch 615:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0913 (0.0913)  orig_norm: 0.8263 (0.8263)  iter: 0.2637s  data: 0.0668s\n",
      "[PT] Epoch 615:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0833 (0.0844)  orig_norm: 0.6657 (0.7437)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 615:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 615\n",
      "[PT] Epoch 616:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0716 (0.0716)  orig_norm: 0.6595 (0.6595)  iter: 0.2592s  data: 0.0614s\n",
      "[PT] Epoch 616:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0854 (0.0857)  orig_norm: 0.6226 (0.7111)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 616:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 616\n",
      "[PT] Epoch 617:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0833 (0.0833)  orig_norm: 0.5863 (0.5863)  iter: 0.2467s  data: 0.0530s\n",
      "[PT] Epoch 617:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0862 (0.0849)  orig_norm: 0.6609 (0.6873)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 617:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 617\n",
      "[PT] Epoch 618:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0763 (0.0763)  orig_norm: 0.4754 (0.4754)  iter: 0.2596s  data: 0.0621s\n",
      "[PT] Epoch 618:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0866 (0.0856)  orig_norm: 0.7078 (0.7038)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 618:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 618\n",
      "[PT] Epoch 619:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0692 (0.0692)  orig_norm: 0.4573 (0.4573)  iter: 0.2470s  data: 0.0573s\n",
      "[PT] Epoch 619:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0829 (0.0844)  orig_norm: 0.7062 (0.7453)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 619:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 619\n",
      "[PT] Epoch 620:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0652 (0.0652)  orig_norm: 0.6670 (0.6670)  iter: 0.2564s  data: 0.0633s\n",
      "[PT] Epoch 620:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0815 (0.0834)  orig_norm: 0.6201 (0.6933)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 620:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 620\n",
      "[PT] Epoch 621:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0859 (0.0859)  orig_norm: 0.7237 (0.7237)  iter: 0.2521s  data: 0.0585s\n",
      "[PT] Epoch 621:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0853 (0.0856)  orig_norm: 0.7058 (0.7383)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 621:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 621\n",
      "[PT] Epoch 622:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0742 (0.0742)  orig_norm: 0.9104 (0.9104)  iter: 0.2406s  data: 0.0485s\n",
      "[PT] Epoch 622:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0813 (0.0848)  orig_norm: 0.6222 (0.6686)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 622:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 622\n",
      "[PT] Epoch 623:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0743 (0.0743)  orig_norm: 0.7965 (0.7965)  iter: 0.2560s  data: 0.0603s\n",
      "[PT] Epoch 623:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0830 (0.0854)  orig_norm: 0.6940 (0.7148)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 623:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 623\n",
      "[PT] Epoch 624:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0834 (0.0834)  orig_norm: 0.6660 (0.6660)  iter: 0.2489s  data: 0.0541s\n",
      "[PT] Epoch 624:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0813 (0.0853)  orig_norm: 0.6233 (0.7087)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 624:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 624\n",
      "[PT] Epoch 625:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0848 (0.0848)  orig_norm: 0.5897 (0.5897)  iter: 0.2594s  data: 0.0642s\n",
      "[PT] Epoch 625:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0800 (0.0854)  orig_norm: 0.6858 (0.7167)  iter: 0.1828s  data: 0.0002s\n",
      "[PT] Epoch 625:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 625\n",
      "[PT] Epoch 626:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0808 (0.0808)  orig_norm: 1.0825 (1.0825)  iter: 0.2608s  data: 0.0657s\n",
      "[PT] Epoch 626:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0834 (0.0848)  orig_norm: 0.6857 (0.7103)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 626:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 626\n",
      "[PT] Epoch 627:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0759 (0.0759)  orig_norm: 0.5420 (0.5420)  iter: 0.2568s  data: 0.0605s\n",
      "[PT] Epoch 627:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0820 (0.0843)  orig_norm: 0.6641 (0.7041)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 627:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 627\n",
      "[PT] Epoch 628:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0840 (0.0840)  orig_norm: 0.5151 (0.5151)  iter: 0.2540s  data: 0.0606s\n",
      "[PT] Epoch 628:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0875 (0.0850)  orig_norm: 0.6691 (0.6726)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 628:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 628\n",
      "[PT] Epoch 629:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0978 (0.0978)  orig_norm: 1.2109 (1.2109)  iter: 0.2560s  data: 0.0616s\n",
      "[PT] Epoch 629:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0854 (0.0847)  orig_norm: 0.6745 (0.7101)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 629:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 629\n",
      "[PT] Epoch 630:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0988 (0.0988)  orig_norm: 0.7722 (0.7722)  iter: 0.2501s  data: 0.0567s\n",
      "[PT] Epoch 630:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0838 (0.0865)  orig_norm: 0.6359 (0.6839)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 630:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 630\n",
      "[PT] Epoch 631:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0979 (0.0979)  orig_norm: 0.5336 (0.5336)  iter: 0.2477s  data: 0.0564s\n",
      "[PT] Epoch 631:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0817 (0.0828)  orig_norm: 0.7375 (0.7037)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 631:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 631\n",
      "[PT] Epoch 632:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0789 (0.0789)  orig_norm: 0.6665 (0.6665)  iter: 0.2684s  data: 0.0730s\n",
      "[PT] Epoch 632:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0861 (0.0839)  orig_norm: 0.6819 (0.6691)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 632:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 632\n",
      "[PT] Epoch 633:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0948 (0.0948)  orig_norm: 0.6356 (0.6356)  iter: 0.2634s  data: 0.0687s\n",
      "[PT] Epoch 633:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0847 (0.0837)  orig_norm: 0.7015 (0.7151)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 633:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 633\n",
      "[PT] Epoch 634:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0718 (0.0718)  orig_norm: 0.6047 (0.6047)  iter: 0.2538s  data: 0.0602s\n",
      "[PT] Epoch 634:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0818 (0.0822)  orig_norm: 0.5454 (0.6635)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 634:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 634\n",
      "[PT] Epoch 635:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0872 (0.0872)  orig_norm: 0.4760 (0.4760)  iter: 0.2578s  data: 0.0652s\n",
      "[PT] Epoch 635:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0843 (0.0877)  orig_norm: 0.7084 (0.6875)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 635:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 635\n",
      "[PT] Epoch 636:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0822 (0.0822)  orig_norm: 0.6208 (0.6208)  iter: 0.2555s  data: 0.0579s\n",
      "[PT] Epoch 636:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0778 (0.0835)  orig_norm: 0.6975 (0.7077)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 636:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 636\n",
      "[PT] Epoch 637:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0760 (0.0760)  orig_norm: 0.6945 (0.6945)  iter: 0.2617s  data: 0.0637s\n",
      "[PT] Epoch 637:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0840 (0.0855)  orig_norm: 0.6431 (0.6994)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 637:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 637\n",
      "[PT] Epoch 638:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0718 (0.0718)  orig_norm: 0.5793 (0.5793)  iter: 0.2586s  data: 0.0663s\n",
      "[PT] Epoch 638:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0862 (0.0834)  orig_norm: 0.7480 (0.6728)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 638:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 638\n",
      "[PT] Epoch 639:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0804 (0.0804)  orig_norm: 0.8529 (0.8529)  iter: 0.2546s  data: 0.0583s\n",
      "[PT] Epoch 639:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0815 (0.0837)  orig_norm: 0.6815 (0.7247)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 639:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 639\n",
      "[PT] Epoch 640:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0753 (0.0753)  orig_norm: 0.6413 (0.6413)  iter: 0.2592s  data: 0.0662s\n",
      "[PT] Epoch 640:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0824 (0.0844)  orig_norm: 0.6645 (0.7204)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 640:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 640\n",
      "[PT] Epoch 641:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0839 (0.0839)  orig_norm: 0.6232 (0.6232)  iter: 0.2536s  data: 0.0623s\n",
      "[PT] Epoch 641:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0849 (0.0842)  orig_norm: 0.7208 (0.7047)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 641:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 641\n",
      "[PT] Epoch 642:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0805 (0.0805)  orig_norm: 0.7358 (0.7358)  iter: 0.2512s  data: 0.0575s\n",
      "[PT] Epoch 642:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0831 (0.0841)  orig_norm: 0.7058 (0.7117)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 642:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 642\n",
      "[PT] Epoch 643:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0861 (0.0861)  orig_norm: 0.9198 (0.9198)  iter: 0.2485s  data: 0.0532s\n",
      "[PT] Epoch 643:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0735 (0.0819)  orig_norm: 0.6841 (0.6850)  iter: 0.1825s  data: 0.0002s\n",
      "[PT] Epoch 643:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 643\n",
      "[PT] Epoch 644:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0985 (0.0985)  orig_norm: 0.5978 (0.5978)  iter: 0.2577s  data: 0.0676s\n",
      "[PT] Epoch 644:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0836 (0.0836)  orig_norm: 0.6124 (0.6786)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 644:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 644\n",
      "[PT] Epoch 645:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.8711 (0.8711)  iter: 0.2646s  data: 0.0706s\n",
      "[PT] Epoch 645:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0855 (0.0854)  orig_norm: 0.6057 (0.6440)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 645:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 645\n",
      "[PT] Epoch 646:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1011 (0.1011)  orig_norm: 0.7536 (0.7536)  iter: 0.2572s  data: 0.0636s\n",
      "[PT] Epoch 646:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0843 (0.0862)  orig_norm: 0.6657 (0.7156)  iter: 0.1840s  data: 0.0002s\n",
      "[PT] Epoch 646:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 646\n",
      "[PT] Epoch 647:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.0783 (0.0783)  orig_norm: 0.9231 (0.9231)  iter: 0.2729s  data: 0.0807s\n",
      "[PT] Epoch 647:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0880 (0.0847)  orig_norm: 0.6091 (0.6828)  iter: 0.1831s  data: 0.0002s\n",
      "[PT] Epoch 647:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 647\n",
      "[PT] Epoch 648:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1018 (0.1018)  orig_norm: 0.6066 (0.6066)  iter: 0.2505s  data: 0.0563s\n",
      "[PT] Epoch 648:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0837 (0.0853)  orig_norm: 0.6527 (0.7108)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 648:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 648\n",
      "[PT] Epoch 649:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0907 (0.0907)  orig_norm: 0.5634 (0.5634)  iter: 0.2475s  data: 0.0536s\n",
      "[PT] Epoch 649:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0776 (0.0837)  orig_norm: 0.6276 (0.6859)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 649:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 649\n",
      "[PT] Epoch 650:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0770 (0.0770)  orig_norm: 0.7162 (0.7162)  iter: 0.2648s  data: 0.0664s\n",
      "[PT] Epoch 650:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0785 (0.0816)  orig_norm: 0.6709 (0.6834)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 650:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 650\n",
      "[PT] Epoch 651:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0904 (0.0904)  orig_norm: 0.6221 (0.6221)  iter: 0.2690s  data: 0.0752s\n",
      "[PT] Epoch 651:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0825 (0.0844)  orig_norm: 0.6544 (0.7019)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 651:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 651\n",
      "[PT] Epoch 652:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0987 (0.0987)  orig_norm: 0.8612 (0.8612)  iter: 0.2554s  data: 0.0573s\n",
      "[PT] Epoch 652:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0863 (0.0834)  orig_norm: 0.6819 (0.7144)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 652:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 652\n",
      "[PT] Epoch 653:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0778 (0.0778)  orig_norm: 0.5540 (0.5540)  iter: 0.2535s  data: 0.0605s\n",
      "[PT] Epoch 653:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0811 (0.0828)  orig_norm: 0.6580 (0.6609)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 653:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 653\n",
      "[PT] Epoch 654:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0650 (0.0650)  orig_norm: 0.6424 (0.6424)  iter: 0.2581s  data: 0.0658s\n",
      "[PT] Epoch 654:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0873 (0.0830)  orig_norm: 0.6719 (0.7104)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 654:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 654\n",
      "[PT] Epoch 655:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0887 (0.0887)  orig_norm: 0.5591 (0.5591)  iter: 0.2547s  data: 0.0613s\n",
      "[PT] Epoch 655:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0830 (0.0831)  orig_norm: 0.6556 (0.6771)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 655:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 655\n",
      "[PT] Epoch 656:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0759 (0.0759)  orig_norm: 0.4818 (0.4818)  iter: 0.2536s  data: 0.0602s\n",
      "[PT] Epoch 656:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0809 (0.0824)  orig_norm: 0.6748 (0.6950)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 656:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 656\n",
      "[PT] Epoch 657:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0857 (0.0857)  orig_norm: 0.5288 (0.5288)  iter: 0.2673s  data: 0.0724s\n",
      "[PT] Epoch 657:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0802 (0.0826)  orig_norm: 0.6104 (0.7589)  iter: 0.1821s  data: 0.0002s\n",
      "[PT] Epoch 657:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 657\n",
      "[PT] Epoch 658:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0928 (0.0928)  orig_norm: 0.7425 (0.7425)  iter: 0.2474s  data: 0.0531s\n",
      "[PT] Epoch 658:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0828 (0.0846)  orig_norm: 0.6640 (0.7157)  iter: 0.1845s  data: 0.0002s\n",
      "[PT] Epoch 658:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 658\n",
      "[PT] Epoch 659:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0983 (0.0983)  orig_norm: 0.9391 (0.9391)  iter: 0.2641s  data: 0.0690s\n",
      "[PT] Epoch 659:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0841 (0.0828)  orig_norm: 0.6534 (0.7491)  iter: 0.1851s  data: 0.0002s\n",
      "[PT] Epoch 659:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 659\n",
      "[PT] Epoch 660:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0892 (0.0892)  orig_norm: 0.7948 (0.7948)  iter: 0.2661s  data: 0.0712s\n",
      "[PT] Epoch 660:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0781 (0.0826)  orig_norm: 0.6472 (0.7084)  iter: 0.1842s  data: 0.0001s\n",
      "[PT] Epoch 660:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 660\n",
      "[PT] Epoch 661:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0776 (0.0776)  orig_norm: 0.5228 (0.5228)  iter: 0.2592s  data: 0.0603s\n",
      "[PT] Epoch 661:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0848 (0.0818)  orig_norm: 0.7268 (0.6986)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 661:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 661\n",
      "[PT] Epoch 662:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0838 (0.0838)  orig_norm: 0.8953 (0.8953)  iter: 0.2636s  data: 0.0667s\n",
      "[PT] Epoch 662:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0801 (0.0831)  orig_norm: 0.6946 (0.7453)  iter: 0.1827s  data: 0.0002s\n",
      "[PT] Epoch 662:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 662\n",
      "[PT] Epoch 663:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0811 (0.0811)  orig_norm: 0.5045 (0.5045)  iter: 0.2546s  data: 0.0596s\n",
      "[PT] Epoch 663:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0816 (0.0835)  orig_norm: 0.7243 (0.6957)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 663:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 663\n",
      "[PT] Epoch 664:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1189 (0.1189)  orig_norm: 1.0454 (1.0454)  iter: 0.2514s  data: 0.0591s\n",
      "[PT] Epoch 664:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0810 (0.0832)  orig_norm: 0.6862 (0.6901)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 664:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 664\n",
      "[PT] Epoch 665:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0781 (0.0781)  orig_norm: 0.4776 (0.4776)  iter: 0.2613s  data: 0.0657s\n",
      "[PT] Epoch 665:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0819 (0.0825)  orig_norm: 0.6364 (0.6987)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 665:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 665\n",
      "[PT] Epoch 666:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0824 (0.0824)  orig_norm: 0.6500 (0.6500)  iter: 0.2596s  data: 0.0664s\n",
      "[PT] Epoch 666:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0856 (0.0820)  orig_norm: 0.6054 (0.6643)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 666:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 666\n",
      "[PT] Epoch 667:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0995 (0.0995)  orig_norm: 0.7698 (0.7698)  iter: 0.2492s  data: 0.0541s\n",
      "[PT] Epoch 667:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0843 (0.0842)  orig_norm: 0.6338 (0.7263)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 667:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 667\n",
      "[PT] Epoch 668:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0673 (0.0673)  orig_norm: 0.4789 (0.4789)  iter: 0.2611s  data: 0.0675s\n",
      "[PT] Epoch 668:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0855 (0.0828)  orig_norm: 0.7014 (0.7018)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 668:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 668\n",
      "[PT] Epoch 669:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0756 (0.0756)  orig_norm: 0.4805 (0.4805)  iter: 0.2450s  data: 0.0523s\n",
      "[PT] Epoch 669:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0835 (0.0823)  orig_norm: 0.6264 (0.6451)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 669:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 669\n",
      "[PT] Epoch 670:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0878 (0.0878)  orig_norm: 0.6962 (0.6962)  iter: 0.2583s  data: 0.0649s\n",
      "[PT] Epoch 670:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0859 (0.0835)  orig_norm: 0.6944 (0.7096)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 670:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 670\n",
      "[PT] Epoch 671:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1161 (0.1161)  orig_norm: 1.2880 (1.2880)  iter: 0.2528s  data: 0.0589s\n",
      "[PT] Epoch 671:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0827 (0.0844)  orig_norm: 0.7271 (0.7706)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 671:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 671\n",
      "[PT] Epoch 672:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0715 (0.0715)  orig_norm: 0.5303 (0.5303)  iter: 0.2668s  data: 0.0728s\n",
      "[PT] Epoch 672:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0786 (0.0830)  orig_norm: 0.6597 (0.7152)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 672:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 672\n",
      "[PT] Epoch 673:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0864 (0.0864)  orig_norm: 0.6336 (0.6336)  iter: 0.2541s  data: 0.0591s\n",
      "[PT] Epoch 673:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0785 (0.0819)  orig_norm: 0.6403 (0.6706)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 673:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 673\n",
      "[PT] Epoch 674:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0763 (0.0763)  orig_norm: 0.8224 (0.8224)  iter: 0.2601s  data: 0.0649s\n",
      "[PT] Epoch 674:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0795 (0.0814)  orig_norm: 0.6428 (0.6961)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 674:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 674\n",
      "[PT] Epoch 675:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0732 (0.0732)  orig_norm: 0.9184 (0.9184)  iter: 0.2622s  data: 0.0669s\n",
      "[PT] Epoch 675:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0793 (0.0819)  orig_norm: 0.6569 (0.6959)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 675:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 675\n",
      "[PT] Epoch 676:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0817 (0.0817)  orig_norm: 0.5356 (0.5356)  iter: 0.2618s  data: 0.0643s\n",
      "[PT] Epoch 676:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0806 (0.0810)  orig_norm: 0.6541 (0.6738)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 676:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 676\n",
      "[PT] Epoch 677:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0789 (0.0789)  orig_norm: 0.8068 (0.8068)  iter: 0.2588s  data: 0.0656s\n",
      "[PT] Epoch 677:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0802 (0.0824)  orig_norm: 0.6879 (0.7070)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 677:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 677\n",
      "[PT] Epoch 678:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0819 (0.0819)  orig_norm: 1.2915 (1.2915)  iter: 0.2499s  data: 0.0597s\n",
      "[PT] Epoch 678:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0847 (0.0818)  orig_norm: 0.6282 (0.6908)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 678:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 678\n",
      "[PT] Epoch 679:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0871 (0.0871)  orig_norm: 0.4261 (0.4261)  iter: 0.2488s  data: 0.0538s\n",
      "[PT] Epoch 679:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0811 (0.0830)  orig_norm: 0.7373 (0.7448)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 679:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 679\n",
      "[PT] Epoch 680:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0740 (0.0740)  orig_norm: 1.4072 (1.4072)  iter: 0.2578s  data: 0.0655s\n",
      "[PT] Epoch 680:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0836 (0.0839)  orig_norm: 0.6661 (0.7424)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 680:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 680\n",
      "[PT] Epoch 681:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0668 (0.0668)  orig_norm: 0.6068 (0.6068)  iter: 0.2601s  data: 0.0637s\n",
      "[PT] Epoch 681:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0883 (0.0832)  orig_norm: 0.6795 (0.7453)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 681:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 681\n",
      "[PT] Epoch 682:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0741 (0.0741)  orig_norm: 0.7142 (0.7142)  iter: 0.2461s  data: 0.0522s\n",
      "[PT] Epoch 682:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0808 (0.0818)  orig_norm: 0.6678 (0.7158)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 682:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 682\n",
      "[PT] Epoch 683:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0882 (0.0882)  orig_norm: 0.6073 (0.6073)  iter: 0.2560s  data: 0.0612s\n",
      "[PT] Epoch 683:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0828 (0.0842)  orig_norm: 0.6260 (0.6713)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 683:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 683\n",
      "[PT] Epoch 684:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.7161 (0.7161)  iter: 0.2503s  data: 0.0592s\n",
      "[PT] Epoch 684:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0810 (0.0832)  orig_norm: 0.7881 (0.7618)  iter: 0.1831s  data: 0.0002s\n",
      "[PT] Epoch 684:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 684\n",
      "[PT] Epoch 685:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0884 (0.0884)  orig_norm: 0.7144 (0.7144)  iter: 0.2660s  data: 0.0724s\n",
      "[PT] Epoch 685:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0824 (0.0838)  orig_norm: 0.6817 (0.7182)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 685:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 685\n",
      "[PT] Epoch 686:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0808 (0.0808)  orig_norm: 0.8456 (0.8456)  iter: 0.2588s  data: 0.0630s\n",
      "[PT] Epoch 686:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0773 (0.0812)  orig_norm: 0.7076 (0.7192)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 686:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 686\n",
      "[PT] Epoch 687:  [ 0/92]  eta: 0:00:25  max_lr: 0.00002  last_loss: 0.0852 (0.0852)  orig_norm: 0.6108 (0.6108)  iter: 0.2720s  data: 0.0783s\n",
      "[PT] Epoch 687:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0777 (0.0812)  orig_norm: 0.5826 (0.6678)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 687:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 687\n",
      "[PT] Epoch 688:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1162 (0.1162)  orig_norm: 0.7354 (0.7354)  iter: 0.2574s  data: 0.0655s\n",
      "[PT] Epoch 688:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0821 (0.0831)  orig_norm: 0.6339 (0.6596)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 688:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 688\n",
      "[PT] Epoch 689:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0815 (0.0815)  orig_norm: 0.9608 (0.9608)  iter: 0.2596s  data: 0.0648s\n",
      "[PT] Epoch 689:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0787 (0.0824)  orig_norm: 0.7609 (0.6966)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 689:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 689\n",
      "[PT] Epoch 690:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0753 (0.0753)  orig_norm: 0.8395 (0.8395)  iter: 0.2591s  data: 0.0646s\n",
      "[PT] Epoch 690:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0837 (0.0833)  orig_norm: 0.6923 (0.7158)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 690:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 690\n",
      "[PT] Epoch 691:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0755 (0.0755)  orig_norm: 0.6057 (0.6057)  iter: 0.2599s  data: 0.0644s\n",
      "[PT] Epoch 691:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0832 (0.0845)  orig_norm: 0.7018 (0.7551)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 691:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 691\n",
      "[PT] Epoch 692:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0719 (0.0719)  orig_norm: 0.5893 (0.5893)  iter: 0.2575s  data: 0.0602s\n",
      "[PT] Epoch 692:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0787 (0.0818)  orig_norm: 0.6900 (0.7072)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 692:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 692\n",
      "[PT] Epoch 693:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0876 (0.0876)  orig_norm: 0.9671 (0.9671)  iter: 0.2570s  data: 0.0603s\n",
      "[PT] Epoch 693:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0763 (0.0822)  orig_norm: 0.6113 (0.6735)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 693:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 693\n",
      "[PT] Epoch 694:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0814 (0.0814)  orig_norm: 0.6639 (0.6639)  iter: 0.2532s  data: 0.0573s\n",
      "[PT] Epoch 694:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0787 (0.0831)  orig_norm: 0.6163 (0.7079)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 694:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 694\n",
      "[PT] Epoch 695:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0861 (0.0861)  orig_norm: 0.5796 (0.5796)  iter: 0.2564s  data: 0.0610s\n",
      "[PT] Epoch 695:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0816 (0.0833)  orig_norm: 0.6959 (0.6943)  iter: 0.1811s  data: 0.0001s\n",
      "[PT] Epoch 695:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 695\n",
      "[PT] Epoch 696:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0684 (0.0684)  orig_norm: 0.6398 (0.6398)  iter: 0.2530s  data: 0.0593s\n",
      "[PT] Epoch 696:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0795 (0.0824)  orig_norm: 0.7178 (0.7096)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 696:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 696\n",
      "[PT] Epoch 697:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0737 (0.0737)  orig_norm: 0.6116 (0.6116)  iter: 0.2480s  data: 0.0535s\n",
      "[PT] Epoch 697:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0766 (0.0811)  orig_norm: 0.6015 (0.6353)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 697:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 697\n",
      "[PT] Epoch 698:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0773 (0.0773)  orig_norm: 0.6056 (0.6056)  iter: 0.2587s  data: 0.0656s\n",
      "[PT] Epoch 698:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0819 (0.0829)  orig_norm: 0.7816 (0.8052)  iter: 0.1865s  data: 0.0002s\n",
      "[PT] Epoch 698:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 698\n",
      "[PT] Epoch 699:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0921 (0.0921)  orig_norm: 0.5411 (0.5411)  iter: 0.2590s  data: 0.0645s\n",
      "[PT] Epoch 699:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0816 (0.0827)  orig_norm: 0.6879 (0.7799)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 699:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 699\n",
      "[PT] Epoch 700:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0763 (0.0763)  orig_norm: 0.5913 (0.5913)  iter: 0.2500s  data: 0.0537s\n",
      "[PT] Epoch 700:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0797 (0.0819)  orig_norm: 0.6293 (0.6568)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 700:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 700\n",
      "[PT] Epoch 701:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1021 (0.1021)  orig_norm: 0.7877 (0.7877)  iter: 0.2577s  data: 0.0629s\n",
      "[PT] Epoch 701:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0767 (0.0814)  orig_norm: 0.6909 (0.7094)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 701:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 701\n",
      "[PT] Epoch 702:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0830 (0.0830)  orig_norm: 0.6912 (0.6912)  iter: 0.2499s  data: 0.0580s\n",
      "[PT] Epoch 702:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0809 (0.0825)  orig_norm: 0.7009 (0.7357)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 702:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 702\n",
      "[PT] Epoch 703:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0889 (0.0889)  orig_norm: 0.5446 (0.5446)  iter: 0.2568s  data: 0.0614s\n",
      "[PT] Epoch 703:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0829 (0.0825)  orig_norm: 0.6794 (0.6684)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 703:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 703\n",
      "[PT] Epoch 704:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0754 (0.0754)  orig_norm: 0.9038 (0.9038)  iter: 0.2535s  data: 0.0607s\n",
      "[PT] Epoch 704:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0796 (0.0806)  orig_norm: 0.6854 (0.6503)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 704:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 704\n",
      "[PT] Epoch 705:  [ 0/92]  eta: 0:00:21  max_lr: 0.00002  last_loss: 0.0792 (0.0792)  orig_norm: 0.6724 (0.6724)  iter: 0.2380s  data: 0.0483s\n",
      "[PT] Epoch 705:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0756 (0.0824)  orig_norm: 0.7586 (0.7538)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 705:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 705\n",
      "[PT] Epoch 706:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0874 (0.0874)  orig_norm: 0.7612 (0.7612)  iter: 0.2603s  data: 0.0663s\n",
      "[PT] Epoch 706:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0824 (0.0828)  orig_norm: 0.6281 (0.6828)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 706:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 706\n",
      "[PT] Epoch 707:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.1027 (0.1027)  orig_norm: 0.6703 (0.6703)  iter: 0.2566s  data: 0.0639s\n",
      "[PT] Epoch 707:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0835 (0.0845)  orig_norm: 0.7349 (0.7362)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 707:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 707\n",
      "[PT] Epoch 708:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0744 (0.0744)  orig_norm: 0.5458 (0.5458)  iter: 0.2576s  data: 0.0655s\n",
      "[PT] Epoch 708:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0806 (0.0819)  orig_norm: 0.6755 (0.7428)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 708:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 708\n",
      "[PT] Epoch 709:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0987 (0.0987)  orig_norm: 0.7489 (0.7489)  iter: 0.2506s  data: 0.0571s\n",
      "[PT] Epoch 709:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0813 (0.0824)  orig_norm: 0.6489 (0.7228)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 709:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 709\n",
      "[PT] Epoch 710:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0920 (0.0920)  orig_norm: 0.7062 (0.7062)  iter: 0.2500s  data: 0.0555s\n",
      "[PT] Epoch 710:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0792 (0.0822)  orig_norm: 0.6473 (0.6709)  iter: 0.1839s  data: 0.0002s\n",
      "[PT] Epoch 710:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 710\n",
      "[PT] Epoch 711:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0668 (0.0668)  orig_norm: 0.5372 (0.5372)  iter: 0.2583s  data: 0.0618s\n",
      "[PT] Epoch 711:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0807 (0.0825)  orig_norm: 0.6829 (0.6522)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 711:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 711\n",
      "[PT] Epoch 712:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0832 (0.0832)  orig_norm: 0.6564 (0.6564)  iter: 0.2534s  data: 0.0579s\n",
      "[PT] Epoch 712:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0822 (0.0819)  orig_norm: 0.6732 (0.6771)  iter: 0.1866s  data: 0.0002s\n",
      "[PT] Epoch 712:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 712\n",
      "[PT] Epoch 713:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0775 (0.0775)  orig_norm: 0.4728 (0.4728)  iter: 0.2558s  data: 0.0610s\n",
      "[PT] Epoch 713:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0745 (0.0790)  orig_norm: 0.6097 (0.6557)  iter: 0.1840s  data: 0.0002s\n",
      "[PT] Epoch 713:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 713\n",
      "[PT] Epoch 714:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0916 (0.0916)  orig_norm: 1.1133 (1.1133)  iter: 0.2648s  data: 0.0650s\n",
      "[PT] Epoch 714:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0846 (0.0827)  orig_norm: 0.6466 (0.6761)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 714:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 714\n",
      "[PT] Epoch 715:  [ 0/92]  eta: 0:00:22  max_lr: 0.00002  last_loss: 0.0977 (0.0977)  orig_norm: 0.7621 (0.7621)  iter: 0.2476s  data: 0.0563s\n",
      "[PT] Epoch 715:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0847 (0.0808)  orig_norm: 0.6740 (0.6536)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 715:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 715\n",
      "[PT] Epoch 716:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0739 (0.0739)  orig_norm: 0.6073 (0.6073)  iter: 0.2502s  data: 0.0557s\n",
      "[PT] Epoch 716:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0799 (0.0828)  orig_norm: 0.7007 (0.7144)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 716:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 716\n",
      "[PT] Epoch 717:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0859 (0.0859)  orig_norm: 0.6513 (0.6513)  iter: 0.2590s  data: 0.0665s\n",
      "[PT] Epoch 717:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0810 (0.0814)  orig_norm: 0.6700 (0.6907)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 717:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 717\n",
      "[PT] Epoch 718:  [ 0/92]  eta: 0:00:23  max_lr: 0.00002  last_loss: 0.0912 (0.0912)  orig_norm: 0.9330 (0.9330)  iter: 0.2546s  data: 0.0608s\n",
      "[PT] Epoch 718:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0802 (0.0805)  orig_norm: 0.6813 (0.7405)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 718:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 718\n",
      "[PT] Epoch 719:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0677 (0.0677)  orig_norm: 0.6666 (0.6666)  iter: 0.2703s  data: 0.0757s\n",
      "[PT] Epoch 719:  [45/92]  eta: 0:00:08  max_lr: 0.00002  last_loss: 0.0807 (0.0822)  orig_norm: 0.6496 (0.7178)  iter: 0.1821s  data: 0.0002s\n",
      "[PT] Epoch 719:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 719\n",
      "[PT] Epoch 720:  [ 0/92]  eta: 0:00:24  max_lr: 0.00002  last_loss: 0.0773 (0.0773)  orig_norm: 1.2021 (1.2021)  iter: 0.2641s  data: 0.0699s\n",
      "[PT] Epoch 720:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0839 (0.0831)  orig_norm: 0.6858 (0.6973)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 720:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 720\n",
      "[PT] Epoch 721:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0889 (0.0889)  orig_norm: 0.5430 (0.5430)  iter: 0.2542s  data: 0.0585s\n",
      "[PT] Epoch 721:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0830 (0.0826)  orig_norm: 0.6882 (0.7092)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 721:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 721\n",
      "[PT] Epoch 722:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0841 (0.0841)  orig_norm: 0.6022 (0.6022)  iter: 0.2580s  data: 0.0639s\n",
      "[PT] Epoch 722:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0818 (0.0802)  orig_norm: 0.6285 (0.6632)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 722:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 722\n",
      "[PT] Epoch 723:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0694 (0.0694)  orig_norm: 0.6161 (0.6161)  iter: 0.2495s  data: 0.0562s\n",
      "[PT] Epoch 723:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0803 (0.0823)  orig_norm: 0.6556 (0.7256)  iter: 0.1840s  data: 0.0002s\n",
      "[PT] Epoch 723:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 723\n",
      "[PT] Epoch 724:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0719 (0.0719)  orig_norm: 0.9779 (0.9779)  iter: 0.2535s  data: 0.0586s\n",
      "[PT] Epoch 724:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0830 (0.0819)  orig_norm: 0.6475 (0.6694)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 724:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 724\n",
      "[PT] Epoch 725:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0679 (0.0679)  orig_norm: 0.5602 (0.5602)  iter: 0.2595s  data: 0.0668s\n",
      "[PT] Epoch 725:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0792 (0.0810)  orig_norm: 0.7531 (0.7001)  iter: 0.1858s  data: 0.0002s\n",
      "[PT] Epoch 725:   Total time:      0:00:08   (0.096 s / it)\n",
      "Finished training epoch 725\n",
      "[PT] Epoch 726:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0826 (0.0826)  orig_norm: 0.6677 (0.6677)  iter: 0.2556s  data: 0.0578s\n",
      "[PT] Epoch 726:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0795 (0.0805)  orig_norm: 0.6173 (0.6583)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 726:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 726\n",
      "[PT] Epoch 727:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0746 (0.0746)  orig_norm: 0.5695 (0.5695)  iter: 0.2570s  data: 0.0578s\n",
      "[PT] Epoch 727:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0773 (0.0817)  orig_norm: 0.6137 (0.7053)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 727:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 727\n",
      "[PT] Epoch 728:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0766 (0.0766)  orig_norm: 0.7218 (0.7218)  iter: 0.2500s  data: 0.0568s\n",
      "[PT] Epoch 728:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0771 (0.0801)  orig_norm: 0.6884 (0.6864)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 728:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 728\n",
      "[PT] Epoch 729:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0702 (0.0702)  orig_norm: 0.4548 (0.4548)  iter: 0.2561s  data: 0.0590s\n",
      "[PT] Epoch 729:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0824 (0.0825)  orig_norm: 0.6957 (0.6861)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 729:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 729\n",
      "[PT] Epoch 730:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0857 (0.0857)  orig_norm: 0.6672 (0.6672)  iter: 0.2559s  data: 0.0599s\n",
      "[PT] Epoch 730:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0795 (0.0815)  orig_norm: 0.7271 (0.7400)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 730:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 730\n",
      "[PT] Epoch 731:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0698 (0.0698)  orig_norm: 0.5515 (0.5515)  iter: 0.2495s  data: 0.0586s\n",
      "[PT] Epoch 731:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0836 (0.0814)  orig_norm: 0.5825 (0.6518)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 731:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 731\n",
      "[PT] Epoch 732:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0750 (0.0750)  orig_norm: 0.4850 (0.4850)  iter: 0.2553s  data: 0.0625s\n",
      "[PT] Epoch 732:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0843 (0.0828)  orig_norm: 0.6248 (0.6950)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 732:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 732\n",
      "[PT] Epoch 733:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.1011 (0.1011)  orig_norm: 1.4740 (1.4740)  iter: 0.2610s  data: 0.0655s\n",
      "[PT] Epoch 733:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0806 (0.0823)  orig_norm: 0.6260 (0.7267)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 733:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 733\n",
      "[PT] Epoch 734:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0755 (0.0755)  orig_norm: 0.6062 (0.6062)  iter: 0.2610s  data: 0.0680s\n",
      "[PT] Epoch 734:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0815 (0.0815)  orig_norm: 0.5883 (0.6967)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 734:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 734\n",
      "[PT] Epoch 735:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0876 (0.0876)  orig_norm: 0.7251 (0.7251)  iter: 0.2638s  data: 0.0678s\n",
      "[PT] Epoch 735:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0806 (0.0812)  orig_norm: 0.6725 (0.6827)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 735:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 735\n",
      "[PT] Epoch 736:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0851 (0.0851)  orig_norm: 0.7741 (0.7741)  iter: 0.2518s  data: 0.0612s\n",
      "[PT] Epoch 736:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0775 (0.0807)  orig_norm: 0.7189 (0.7172)  iter: 0.1821s  data: 0.0002s\n",
      "[PT] Epoch 736:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 736\n",
      "[PT] Epoch 737:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0924 (0.0924)  orig_norm: 0.7705 (0.7705)  iter: 0.2616s  data: 0.0628s\n",
      "[PT] Epoch 737:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0807 (0.0817)  orig_norm: 0.6049 (0.6698)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 737:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 737\n",
      "[PT] Epoch 738:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0782 (0.0782)  orig_norm: 0.9203 (0.9203)  iter: 0.2533s  data: 0.0572s\n",
      "[PT] Epoch 738:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0787 (0.0827)  orig_norm: 0.8865 (0.8022)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 738:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 738\n",
      "[PT] Epoch 739:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0871 (0.0871)  orig_norm: 0.5760 (0.5760)  iter: 0.2554s  data: 0.0602s\n",
      "[PT] Epoch 739:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0801 (0.0813)  orig_norm: 0.6880 (0.7269)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 739:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 739\n",
      "[PT] Epoch 740:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0834 (0.0834)  orig_norm: 0.7334 (0.7334)  iter: 0.2464s  data: 0.0535s\n",
      "[PT] Epoch 740:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0838 (0.0820)  orig_norm: 0.6632 (0.6881)  iter: 0.1823s  data: 0.0002s\n",
      "[PT] Epoch 740:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 740\n",
      "[PT] Epoch 741:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0776 (0.0776)  orig_norm: 0.6566 (0.6566)  iter: 0.2574s  data: 0.0612s\n",
      "[PT] Epoch 741:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0814 (0.0810)  orig_norm: 0.6821 (0.7010)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 741:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 741\n",
      "[PT] Epoch 742:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0823 (0.0823)  orig_norm: 0.6475 (0.6475)  iter: 0.2595s  data: 0.0651s\n",
      "[PT] Epoch 742:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0798 (0.0816)  orig_norm: 0.6601 (0.7031)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 742:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 742\n",
      "[PT] Epoch 743:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0965 (0.0965)  orig_norm: 0.5552 (0.5552)  iter: 0.2474s  data: 0.0517s\n",
      "[PT] Epoch 743:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0795 (0.0827)  orig_norm: 0.6420 (0.6982)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 743:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 743\n",
      "[PT] Epoch 744:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0979 (0.0979)  orig_norm: 0.6649 (0.6649)  iter: 0.2517s  data: 0.0588s\n",
      "[PT] Epoch 744:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0807 (0.0812)  orig_norm: 0.6252 (0.6624)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 744:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 744\n",
      "[PT] Epoch 745:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0848 (0.0848)  orig_norm: 0.5409 (0.5409)  iter: 0.2531s  data: 0.0573s\n",
      "[PT] Epoch 745:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0793 (0.0799)  orig_norm: 0.6448 (0.7024)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 745:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 745\n",
      "[PT] Epoch 746:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0729 (0.0729)  orig_norm: 0.6081 (0.6081)  iter: 0.2448s  data: 0.0535s\n",
      "[PT] Epoch 746:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0792 (0.0813)  orig_norm: 0.6295 (0.7453)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 746:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 746\n",
      "[PT] Epoch 747:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0982 (0.0982)  orig_norm: 0.6253 (0.6253)  iter: 0.2580s  data: 0.0633s\n",
      "[PT] Epoch 747:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0819 (0.0831)  orig_norm: 0.5930 (0.6624)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 747:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 747\n",
      "[PT] Epoch 748:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0787 (0.0787)  orig_norm: 0.5002 (0.5002)  iter: 0.2514s  data: 0.0592s\n",
      "[PT] Epoch 748:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0801 (0.0794)  orig_norm: 0.6258 (0.6471)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 748:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 748\n",
      "[PT] Epoch 749:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0797 (0.0797)  orig_norm: 0.5549 (0.5549)  iter: 0.2705s  data: 0.0748s\n",
      "[PT] Epoch 749:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0804 (0.0811)  orig_norm: 0.7680 (0.7554)  iter: 0.1841s  data: 0.0001s\n",
      "[PT] Epoch 749:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 749\n",
      "[PT] Epoch 750:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0600 (0.0600)  orig_norm: 0.5233 (0.5233)  iter: 0.2633s  data: 0.0646s\n",
      "[PT] Epoch 750:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0808)  orig_norm: 0.6070 (0.7300)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 750:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 750\n",
      "[PT] Epoch 751:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.1046 (0.1046)  orig_norm: 1.1498 (1.1498)  iter: 0.2600s  data: 0.0639s\n",
      "[PT] Epoch 751:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0784 (0.0797)  orig_norm: 0.6663 (0.7331)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 751:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 751\n",
      "[PT] Epoch 752:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0763 (0.0763)  orig_norm: 0.8646 (0.8646)  iter: 0.2627s  data: 0.0669s\n",
      "[PT] Epoch 752:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0822 (0.0808)  orig_norm: 0.6405 (0.6539)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 752:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 752\n",
      "[PT] Epoch 753:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0829 (0.0829)  orig_norm: 0.5828 (0.5828)  iter: 0.2662s  data: 0.0655s\n",
      "[PT] Epoch 753:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0787 (0.0807)  orig_norm: 0.6282 (0.6846)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 753:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 753\n",
      "[PT] Epoch 754:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0828 (0.0828)  orig_norm: 0.4896 (0.4896)  iter: 0.2544s  data: 0.0628s\n",
      "[PT] Epoch 754:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0829 (0.0809)  orig_norm: 0.6987 (0.6961)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 754:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 754\n",
      "[PT] Epoch 755:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0921 (0.0921)  orig_norm: 0.6187 (0.6187)  iter: 0.2534s  data: 0.0592s\n",
      "[PT] Epoch 755:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0829 (0.0822)  orig_norm: 0.6323 (0.7556)  iter: 0.1808s  data: 0.0001s\n",
      "[PT] Epoch 755:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 755\n",
      "[PT] Epoch 756:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0681 (0.0681)  orig_norm: 0.7569 (0.7569)  iter: 0.2535s  data: 0.0603s\n",
      "[PT] Epoch 756:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0815 (0.0797)  orig_norm: 0.6032 (0.6613)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 756:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 756\n",
      "[PT] Epoch 757:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0662 (0.0662)  orig_norm: 0.4994 (0.4994)  iter: 0.2536s  data: 0.0592s\n",
      "[PT] Epoch 757:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0775 (0.0812)  orig_norm: 0.5793 (0.6612)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 757:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 757\n",
      "[PT] Epoch 758:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.1063 (0.1063)  orig_norm: 0.8950 (0.8950)  iter: 0.2546s  data: 0.0605s\n",
      "[PT] Epoch 758:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0797)  orig_norm: 0.6476 (0.7046)  iter: 0.1843s  data: 0.0002s\n",
      "[PT] Epoch 758:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 758\n",
      "[PT] Epoch 759:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0857 (0.0857)  orig_norm: 0.7997 (0.7997)  iter: 0.2560s  data: 0.0631s\n",
      "[PT] Epoch 759:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0782 (0.0807)  orig_norm: 0.6459 (0.7002)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 759:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 759\n",
      "[PT] Epoch 760:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0914 (0.0914)  orig_norm: 0.5800 (0.5800)  iter: 0.2568s  data: 0.0596s\n",
      "[PT] Epoch 760:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0791 (0.0804)  orig_norm: 0.6587 (0.6821)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 760:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 760\n",
      "[PT] Epoch 761:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0920 (0.0920)  orig_norm: 0.6673 (0.6673)  iter: 0.2558s  data: 0.0607s\n",
      "[PT] Epoch 761:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0797 (0.0806)  orig_norm: 0.6525 (0.6606)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 761:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 761\n",
      "[PT] Epoch 762:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0714 (0.0714)  orig_norm: 0.6149 (0.6149)  iter: 0.2644s  data: 0.0680s\n",
      "[PT] Epoch 762:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0814 (0.0825)  orig_norm: 0.6299 (0.7243)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 762:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 762\n",
      "[PT] Epoch 763:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0948 (0.0948)  orig_norm: 0.7796 (0.7796)  iter: 0.2572s  data: 0.0634s\n",
      "[PT] Epoch 763:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0799 (0.0809)  orig_norm: 0.6060 (0.6815)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 763:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 763\n",
      "[PT] Epoch 764:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0800 (0.0800)  orig_norm: 0.8130 (0.8130)  iter: 0.2607s  data: 0.0633s\n",
      "[PT] Epoch 764:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0825 (0.0816)  orig_norm: 0.6840 (0.7099)  iter: 0.1841s  data: 0.0001s\n",
      "[PT] Epoch 764:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 764\n",
      "[PT] Epoch 765:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0673 (0.0673)  orig_norm: 0.5692 (0.5692)  iter: 0.2604s  data: 0.0659s\n",
      "[PT] Epoch 765:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0768 (0.0800)  orig_norm: 0.6252 (0.7222)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 765:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 765\n",
      "[PT] Epoch 766:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0888 (0.0888)  orig_norm: 0.6786 (0.6786)  iter: 0.2621s  data: 0.0644s\n",
      "[PT] Epoch 766:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0819 (0.0795)  orig_norm: 0.6174 (0.6912)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 766:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 766\n",
      "[PT] Epoch 767:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0655 (0.0655)  orig_norm: 0.5496 (0.5496)  iter: 0.2594s  data: 0.0636s\n",
      "[PT] Epoch 767:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0768 (0.0786)  orig_norm: 0.6553 (0.6992)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 767:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 767\n",
      "[PT] Epoch 768:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0711 (0.0711)  orig_norm: 0.4814 (0.4814)  iter: 0.2569s  data: 0.0595s\n",
      "[PT] Epoch 768:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0808 (0.0796)  orig_norm: 0.6680 (0.6519)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 768:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 768\n",
      "[PT] Epoch 769:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0915 (0.0915)  orig_norm: 0.5338 (0.5338)  iter: 0.2482s  data: 0.0546s\n",
      "[PT] Epoch 769:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0781 (0.0814)  orig_norm: 0.5618 (0.6625)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 769:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 769\n",
      "[PT] Epoch 770:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0907 (0.0907)  orig_norm: 1.0440 (1.0440)  iter: 0.2573s  data: 0.0625s\n",
      "[PT] Epoch 770:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0801 (0.0826)  orig_norm: 0.6660 (0.6568)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 770:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 770\n",
      "[PT] Epoch 771:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0949 (0.0949)  orig_norm: 0.8041 (0.8041)  iter: 0.2602s  data: 0.0676s\n",
      "[PT] Epoch 771:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0775 (0.0808)  orig_norm: 0.6270 (0.6737)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 771:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 771\n",
      "[PT] Epoch 772:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0750 (0.0750)  orig_norm: 0.6387 (0.6387)  iter: 0.2524s  data: 0.0582s\n",
      "[PT] Epoch 772:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0784 (0.0805)  orig_norm: 0.6434 (0.6555)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 772:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 772\n",
      "[PT] Epoch 773:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.1031 (0.1031)  orig_norm: 0.6954 (0.6954)  iter: 0.2619s  data: 0.0655s\n",
      "[PT] Epoch 773:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0772 (0.0807)  orig_norm: 0.7346 (0.7381)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 773:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 773\n",
      "[PT] Epoch 774:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0915 (0.0915)  orig_norm: 0.7239 (0.7239)  iter: 0.2577s  data: 0.0613s\n",
      "[PT] Epoch 774:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0820 (0.0809)  orig_norm: 0.6678 (0.6663)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 774:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 774\n",
      "[PT] Epoch 775:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0958 (0.0958)  orig_norm: 0.8467 (0.8467)  iter: 0.2565s  data: 0.0634s\n",
      "[PT] Epoch 775:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0810 (0.0823)  orig_norm: 0.6626 (0.6985)  iter: 0.1840s  data: 0.0002s\n",
      "[PT] Epoch 775:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 775\n",
      "[PT] Epoch 776:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0806 (0.0806)  orig_norm: 0.6369 (0.6369)  iter: 0.2561s  data: 0.0602s\n",
      "[PT] Epoch 776:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0805 (0.0807)  orig_norm: 0.6585 (0.7205)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 776:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 776\n",
      "[PT] Epoch 777:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0742 (0.0742)  orig_norm: 0.7288 (0.7288)  iter: 0.2691s  data: 0.0752s\n",
      "[PT] Epoch 777:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0793 (0.0812)  orig_norm: 0.6768 (0.7424)  iter: 0.1844s  data: 0.0002s\n",
      "[PT] Epoch 777:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 777\n",
      "[PT] Epoch 778:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0864 (0.0864)  orig_norm: 0.6642 (0.6642)  iter: 0.2620s  data: 0.0677s\n",
      "[PT] Epoch 778:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0796 (0.0802)  orig_norm: 0.7827 (0.7205)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 778:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 778\n",
      "[PT] Epoch 779:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0895 (0.0895)  orig_norm: 1.0522 (1.0522)  iter: 0.2560s  data: 0.0636s\n",
      "[PT] Epoch 779:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0795 (0.0817)  orig_norm: 0.6559 (0.7432)  iter: 0.1811s  data: 0.0001s\n",
      "[PT] Epoch 779:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 779\n",
      "[PT] Epoch 780:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0819 (0.0819)  orig_norm: 0.8810 (0.8810)  iter: 0.2464s  data: 0.0547s\n",
      "[PT] Epoch 780:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0782 (0.0801)  orig_norm: 0.6487 (0.6970)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 780:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 780\n",
      "[PT] Epoch 781:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0985 (0.0985)  orig_norm: 0.7497 (0.7497)  iter: 0.2632s  data: 0.0696s\n",
      "[PT] Epoch 781:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0803 (0.0804)  orig_norm: 0.5432 (0.6569)  iter: 0.1838s  data: 0.0001s\n",
      "[PT] Epoch 781:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 781\n",
      "[PT] Epoch 782:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0767 (0.0767)  orig_norm: 0.5572 (0.5572)  iter: 0.2580s  data: 0.0642s\n",
      "[PT] Epoch 782:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0803)  orig_norm: 0.6175 (0.6659)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 782:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 782\n",
      "[PT] Epoch 783:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0756 (0.0756)  orig_norm: 0.3790 (0.3790)  iter: 0.2452s  data: 0.0529s\n",
      "[PT] Epoch 783:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0807)  orig_norm: 0.6232 (0.6833)  iter: 0.1817s  data: 0.0002s\n",
      "[PT] Epoch 783:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 783\n",
      "[PT] Epoch 784:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0800 (0.0800)  orig_norm: 0.5309 (0.5309)  iter: 0.2576s  data: 0.0634s\n",
      "[PT] Epoch 784:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0835 (0.0827)  orig_norm: 0.6350 (0.6746)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 784:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 784\n",
      "[PT] Epoch 785:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0948 (0.0948)  orig_norm: 0.7531 (0.7531)  iter: 0.2559s  data: 0.0639s\n",
      "[PT] Epoch 785:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0816 (0.0821)  orig_norm: 0.6335 (0.6839)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 785:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 785\n",
      "[PT] Epoch 786:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0782 (0.0782)  orig_norm: 1.3269 (1.3269)  iter: 0.2584s  data: 0.0607s\n",
      "[PT] Epoch 786:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0823 (0.0824)  orig_norm: 0.6129 (0.7331)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 786:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 786\n",
      "[PT] Epoch 787:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0869 (0.0869)  orig_norm: 0.6224 (0.6224)  iter: 0.2442s  data: 0.0509s\n",
      "[PT] Epoch 787:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0809 (0.0806)  orig_norm: 0.6875 (0.7127)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 787:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 787\n",
      "[PT] Epoch 788:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0725 (0.0725)  orig_norm: 0.4437 (0.4437)  iter: 0.2500s  data: 0.0540s\n",
      "[PT] Epoch 788:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0792 (0.0800)  orig_norm: 0.6288 (0.6505)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 788:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 788\n",
      "[PT] Epoch 789:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0797 (0.0797)  orig_norm: 0.6640 (0.6640)  iter: 0.2605s  data: 0.0659s\n",
      "[PT] Epoch 789:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0789 (0.0793)  orig_norm: 0.6636 (0.7334)  iter: 0.1812s  data: 0.0001s\n",
      "[PT] Epoch 789:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 789\n",
      "[PT] Epoch 790:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0859 (0.0859)  orig_norm: 0.5418 (0.5418)  iter: 0.2658s  data: 0.0716s\n",
      "[PT] Epoch 790:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0753 (0.0789)  orig_norm: 0.6478 (0.6887)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 790:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 790\n",
      "[PT] Epoch 791:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0673 (0.0673)  orig_norm: 0.5000 (0.5000)  iter: 0.2561s  data: 0.0598s\n",
      "[PT] Epoch 791:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0776 (0.0793)  orig_norm: 0.6880 (0.6960)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 791:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 791\n",
      "[PT] Epoch 792:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0690 (0.0690)  orig_norm: 0.6660 (0.6660)  iter: 0.2589s  data: 0.0681s\n",
      "[PT] Epoch 792:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0792 (0.0801)  orig_norm: 0.6955 (0.7070)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 792:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 792\n",
      "[PT] Epoch 793:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0886 (0.0886)  orig_norm: 0.6370 (0.6370)  iter: 0.2564s  data: 0.0662s\n",
      "[PT] Epoch 793:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0781 (0.0808)  orig_norm: 0.6531 (0.7134)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 793:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 793\n",
      "[PT] Epoch 794:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0828 (0.0828)  orig_norm: 0.9273 (0.9273)  iter: 0.2658s  data: 0.0716s\n",
      "[PT] Epoch 794:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0771 (0.0796)  orig_norm: 0.6839 (0.7195)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 794:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 794\n",
      "[PT] Epoch 795:  [ 0/92]  eta: 0:00:25  max_lr: 0.00001  last_loss: 0.0790 (0.0790)  orig_norm: 0.8009 (0.8009)  iter: 0.2723s  data: 0.0781s\n",
      "[PT] Epoch 795:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0756 (0.0799)  orig_norm: 0.6187 (0.7037)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 795:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 795\n",
      "[PT] Epoch 796:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0849 (0.0849)  orig_norm: 0.6364 (0.6364)  iter: 0.2478s  data: 0.0535s\n",
      "[PT] Epoch 796:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0804 (0.0805)  orig_norm: 0.7628 (0.7402)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 796:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 796\n",
      "[PT] Epoch 797:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0849 (0.0849)  orig_norm: 0.9789 (0.9789)  iter: 0.2520s  data: 0.0566s\n",
      "[PT] Epoch 797:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0772 (0.0791)  orig_norm: 0.5912 (0.6687)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 797:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 797\n",
      "[PT] Epoch 798:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0902 (0.0902)  orig_norm: 0.7138 (0.7138)  iter: 0.2584s  data: 0.0620s\n",
      "[PT] Epoch 798:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0813 (0.0792)  orig_norm: 0.6912 (0.6818)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 798:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 798\n",
      "[PT] Epoch 799:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0871 (0.0871)  orig_norm: 0.5890 (0.5890)  iter: 0.2600s  data: 0.0654s\n",
      "[PT] Epoch 799:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0825 (0.0804)  orig_norm: 0.6676 (0.7029)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 799:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 799\n",
      "[PT] Epoch 800:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0863 (0.0863)  orig_norm: 0.7609 (0.7609)  iter: 0.2578s  data: 0.0612s\n",
      "[PT] Epoch 800:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0796 (0.0812)  orig_norm: 0.7583 (0.7362)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 800:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 800\n",
      "[PT] Epoch 801:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0907 (0.0907)  orig_norm: 0.7353 (0.7353)  iter: 0.2540s  data: 0.0595s\n",
      "[PT] Epoch 801:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0749 (0.0797)  orig_norm: 0.6432 (0.7235)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 801:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 801\n",
      "[PT] Epoch 802:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0771 (0.0771)  orig_norm: 0.4477 (0.4477)  iter: 0.2569s  data: 0.0625s\n",
      "[PT] Epoch 802:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0811)  orig_norm: 0.6426 (0.7071)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 802:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 802\n",
      "[PT] Epoch 803:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0891 (0.0891)  orig_norm: 0.6378 (0.6378)  iter: 0.2612s  data: 0.0641s\n",
      "[PT] Epoch 803:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0810 (0.0787)  orig_norm: 0.6741 (0.6670)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 803:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 803\n",
      "[PT] Epoch 804:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0897 (0.0897)  orig_norm: 0.7818 (0.7818)  iter: 0.2546s  data: 0.0596s\n",
      "[PT] Epoch 804:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0769 (0.0811)  orig_norm: 0.6509 (0.7167)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 804:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 804\n",
      "[PT] Epoch 805:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0759 (0.0759)  orig_norm: 0.5503 (0.5503)  iter: 0.2620s  data: 0.0685s\n",
      "[PT] Epoch 805:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0836 (0.0810)  orig_norm: 0.7268 (0.6918)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 805:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 805\n",
      "[PT] Epoch 806:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0860 (0.0860)  orig_norm: 0.6112 (0.6112)  iter: 0.2547s  data: 0.0600s\n",
      "[PT] Epoch 806:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0809 (0.0793)  orig_norm: 0.6408 (0.7102)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 806:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 806\n",
      "[PT] Epoch 807:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0959 (0.0959)  orig_norm: 0.5883 (0.5883)  iter: 0.2556s  data: 0.0609s\n",
      "[PT] Epoch 807:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0802)  orig_norm: 0.6486 (0.6741)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 807:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 807\n",
      "[PT] Epoch 808:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0722 (0.0722)  orig_norm: 0.7984 (0.7984)  iter: 0.2601s  data: 0.0672s\n",
      "[PT] Epoch 808:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0799)  orig_norm: 0.6457 (0.6848)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 808:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 808\n",
      "[PT] Epoch 809:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0831 (0.0831)  orig_norm: 0.7101 (0.7101)  iter: 0.2546s  data: 0.0575s\n",
      "[PT] Epoch 809:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0794 (0.0807)  orig_norm: 0.6497 (0.7029)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 809:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 809\n",
      "[PT] Epoch 810:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0803 (0.0803)  orig_norm: 0.6839 (0.6839)  iter: 0.2601s  data: 0.0651s\n",
      "[PT] Epoch 810:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0805 (0.0797)  orig_norm: 0.7554 (0.7603)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 810:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 810\n",
      "[PT] Epoch 811:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0827 (0.0827)  orig_norm: 0.7034 (0.7034)  iter: 0.2601s  data: 0.0656s\n",
      "[PT] Epoch 811:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0847 (0.0812)  orig_norm: 0.6442 (0.6917)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 811:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 811\n",
      "[PT] Epoch 812:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0771 (0.0771)  orig_norm: 0.4859 (0.4859)  iter: 0.2602s  data: 0.0656s\n",
      "[PT] Epoch 812:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0754 (0.0801)  orig_norm: 0.7554 (0.7347)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 812:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 812\n",
      "[PT] Epoch 813:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0823 (0.0823)  orig_norm: 0.8211 (0.8211)  iter: 0.2450s  data: 0.0498s\n",
      "[PT] Epoch 813:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0798)  orig_norm: 0.6268 (0.6553)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 813:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 813\n",
      "[PT] Epoch 814:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0748 (0.0748)  orig_norm: 0.7614 (0.7614)  iter: 0.2472s  data: 0.0537s\n",
      "[PT] Epoch 814:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0788 (0.0804)  orig_norm: 0.6628 (0.7313)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 814:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 814\n",
      "[PT] Epoch 815:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0755 (0.0755)  orig_norm: 0.5188 (0.5188)  iter: 0.2518s  data: 0.0587s\n",
      "[PT] Epoch 815:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0773 (0.0800)  orig_norm: 0.7199 (0.7536)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 815:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 815\n",
      "[PT] Epoch 816:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0607 (0.0607)  orig_norm: 0.9754 (0.9754)  iter: 0.2605s  data: 0.0605s\n",
      "[PT] Epoch 816:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0791 (0.0801)  orig_norm: 0.6137 (0.6985)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 816:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 816\n",
      "[PT] Epoch 817:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0751 (0.0751)  orig_norm: 0.5289 (0.5289)  iter: 0.2696s  data: 0.0768s\n",
      "[PT] Epoch 817:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0800 (0.0785)  orig_norm: 0.5686 (0.6306)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 817:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 817\n",
      "[PT] Epoch 818:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0817 (0.0817)  orig_norm: 0.6375 (0.6375)  iter: 0.2499s  data: 0.0548s\n",
      "[PT] Epoch 818:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0804)  orig_norm: 0.6853 (0.7165)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 818:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 818\n",
      "[PT] Epoch 819:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0710 (0.0710)  orig_norm: 0.8663 (0.8663)  iter: 0.2594s  data: 0.0573s\n",
      "[PT] Epoch 819:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0787 (0.0816)  orig_norm: 0.6687 (0.7123)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 819:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 819\n",
      "[PT] Epoch 820:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0742 (0.0742)  orig_norm: 0.6055 (0.6055)  iter: 0.2568s  data: 0.0629s\n",
      "[PT] Epoch 820:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0773 (0.0815)  orig_norm: 0.7028 (0.6997)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 820:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 820\n",
      "[PT] Epoch 821:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0780 (0.0780)  orig_norm: 0.6250 (0.6250)  iter: 0.2535s  data: 0.0586s\n",
      "[PT] Epoch 821:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0765 (0.0787)  orig_norm: 0.6358 (0.6948)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 821:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 821\n",
      "[PT] Epoch 822:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0906 (0.0906)  orig_norm: 0.6737 (0.6737)  iter: 0.2574s  data: 0.0647s\n",
      "[PT] Epoch 822:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0723 (0.0807)  orig_norm: 0.7186 (0.7243)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 822:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 822\n",
      "[PT] Epoch 823:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0691 (0.0691)  orig_norm: 0.5300 (0.5300)  iter: 0.2572s  data: 0.0649s\n",
      "[PT] Epoch 823:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0809 (0.0795)  orig_norm: 0.6288 (0.6877)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 823:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 823\n",
      "[PT] Epoch 824:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0842 (0.0842)  orig_norm: 0.7569 (0.7569)  iter: 0.2633s  data: 0.0706s\n",
      "[PT] Epoch 824:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0782 (0.0793)  orig_norm: 0.6196 (0.6599)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 824:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 824\n",
      "[PT] Epoch 825:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0701 (0.0701)  orig_norm: 0.9112 (0.9112)  iter: 0.2465s  data: 0.0535s\n",
      "[PT] Epoch 825:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0798 (0.0793)  orig_norm: 0.6654 (0.6704)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 825:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 825\n",
      "[PT] Epoch 826:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0684 (0.0684)  orig_norm: 0.4828 (0.4828)  iter: 0.2549s  data: 0.0585s\n",
      "[PT] Epoch 826:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0801 (0.0807)  orig_norm: 0.5998 (0.6960)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 826:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 826\n",
      "[PT] Epoch 827:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0781 (0.0781)  orig_norm: 0.7371 (0.7371)  iter: 0.2586s  data: 0.0611s\n",
      "[PT] Epoch 827:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0794 (0.0806)  orig_norm: 0.6095 (0.6646)  iter: 0.1831s  data: 0.0002s\n",
      "[PT] Epoch 827:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 827\n",
      "[PT] Epoch 828:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0754 (0.0754)  orig_norm: 0.9230 (0.9230)  iter: 0.2575s  data: 0.0606s\n",
      "[PT] Epoch 828:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0762 (0.0778)  orig_norm: 0.6518 (0.6888)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 828:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 828\n",
      "[PT] Epoch 829:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0896 (0.0896)  orig_norm: 0.7520 (0.7520)  iter: 0.2601s  data: 0.0639s\n",
      "[PT] Epoch 829:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0779 (0.0825)  orig_norm: 0.5981 (0.6969)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 829:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 829\n",
      "[PT] Epoch 830:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0869 (0.0869)  orig_norm: 0.5171 (0.5171)  iter: 0.2551s  data: 0.0606s\n",
      "[PT] Epoch 830:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0779 (0.0817)  orig_norm: 0.6424 (0.7005)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 830:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 830\n",
      "[PT] Epoch 831:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0740 (0.0740)  orig_norm: 0.6475 (0.6475)  iter: 0.2541s  data: 0.0584s\n",
      "[PT] Epoch 831:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0755 (0.0790)  orig_norm: 0.6151 (0.6727)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 831:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 831\n",
      "[PT] Epoch 832:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0781 (0.0781)  orig_norm: 0.5575 (0.5575)  iter: 0.2521s  data: 0.0577s\n",
      "[PT] Epoch 832:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0765 (0.0803)  orig_norm: 0.6721 (0.6879)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 832:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 832\n",
      "[PT] Epoch 833:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0718 (0.0718)  orig_norm: 0.7091 (0.7091)  iter: 0.2584s  data: 0.0667s\n",
      "[PT] Epoch 833:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0815 (0.0819)  orig_norm: 0.6930 (0.7491)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 833:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 833\n",
      "[PT] Epoch 834:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0788 (0.0788)  orig_norm: 0.5414 (0.5414)  iter: 0.2631s  data: 0.0648s\n",
      "[PT] Epoch 834:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0811)  orig_norm: 0.7083 (0.7382)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 834:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 834\n",
      "[PT] Epoch 835:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0797 (0.0797)  orig_norm: 0.5951 (0.5951)  iter: 0.2630s  data: 0.0666s\n",
      "[PT] Epoch 835:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0748 (0.0790)  orig_norm: 0.6322 (0.6786)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 835:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 835\n",
      "[PT] Epoch 836:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0666 (0.0666)  orig_norm: 0.7054 (0.7054)  iter: 0.2475s  data: 0.0529s\n",
      "[PT] Epoch 836:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0811)  orig_norm: 0.6856 (0.7187)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 836:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 836\n",
      "[PT] Epoch 837:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0716 (0.0716)  orig_norm: 0.5554 (0.5554)  iter: 0.2616s  data: 0.0646s\n",
      "[PT] Epoch 837:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0787 (0.0789)  orig_norm: 0.6148 (0.7216)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 837:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 837\n",
      "[PT] Epoch 838:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0716 (0.0716)  orig_norm: 0.6635 (0.6635)  iter: 0.2476s  data: 0.0503s\n",
      "[PT] Epoch 838:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0811 (0.0805)  orig_norm: 0.7081 (0.6959)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 838:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 838\n",
      "[PT] Epoch 839:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0972 (0.0972)  orig_norm: 0.6080 (0.6080)  iter: 0.2529s  data: 0.0560s\n",
      "[PT] Epoch 839:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0764 (0.0798)  orig_norm: 0.6595 (0.6993)  iter: 0.1840s  data: 0.0001s\n",
      "[PT] Epoch 839:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 839\n",
      "[PT] Epoch 840:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0741 (0.0741)  orig_norm: 0.4288 (0.4288)  iter: 0.2540s  data: 0.0592s\n",
      "[PT] Epoch 840:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0775 (0.0780)  orig_norm: 0.6952 (0.6887)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 840:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 840\n",
      "[PT] Epoch 841:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0807 (0.0807)  orig_norm: 1.0688 (1.0688)  iter: 0.2562s  data: 0.0626s\n",
      "[PT] Epoch 841:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0781 (0.0805)  orig_norm: 0.6628 (0.7180)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 841:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 841\n",
      "[PT] Epoch 842:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0813 (0.0813)  orig_norm: 0.6487 (0.6487)  iter: 0.2563s  data: 0.0638s\n",
      "[PT] Epoch 842:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0788)  orig_norm: 0.5937 (0.6870)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 842:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 842\n",
      "[PT] Epoch 843:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0725 (0.0725)  orig_norm: 0.6731 (0.6731)  iter: 0.2589s  data: 0.0634s\n",
      "[PT] Epoch 843:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0735 (0.0774)  orig_norm: 0.5458 (0.6734)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 843:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 843\n",
      "[PT] Epoch 844:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0769 (0.0769)  orig_norm: 0.7278 (0.7278)  iter: 0.2440s  data: 0.0524s\n",
      "[PT] Epoch 844:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0759 (0.0792)  orig_norm: 0.6063 (0.6676)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 844:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 844\n",
      "[PT] Epoch 845:  [ 0/92]  eta: 0:00:25  max_lr: 0.00001  last_loss: 0.0855 (0.0855)  orig_norm: 0.5926 (0.5926)  iter: 0.2720s  data: 0.0742s\n",
      "[PT] Epoch 845:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0797 (0.0799)  orig_norm: 0.6327 (0.7041)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 845:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 845\n",
      "[PT] Epoch 846:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0948 (0.0948)  orig_norm: 0.7178 (0.7178)  iter: 0.2597s  data: 0.0652s\n",
      "[PT] Epoch 846:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0782 (0.0793)  orig_norm: 0.6812 (0.7082)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 846:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 846\n",
      "[PT] Epoch 847:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0942 (0.0942)  orig_norm: 0.7999 (0.7999)  iter: 0.2510s  data: 0.0569s\n",
      "[PT] Epoch 847:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0766 (0.0788)  orig_norm: 0.7040 (0.7182)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 847:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 847\n",
      "[PT] Epoch 848:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0821 (0.0821)  orig_norm: 0.7234 (0.7234)  iter: 0.2558s  data: 0.0607s\n",
      "[PT] Epoch 848:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0829 (0.0811)  orig_norm: 0.6467 (0.7300)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 848:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 848\n",
      "[PT] Epoch 849:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0673 (0.0673)  orig_norm: 0.9927 (0.9927)  iter: 0.2592s  data: 0.0651s\n",
      "[PT] Epoch 849:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0809 (0.0793)  orig_norm: 0.6859 (0.7229)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 849:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 849\n",
      "[PT] Epoch 850:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0771 (0.0771)  orig_norm: 0.6288 (0.6288)  iter: 0.2555s  data: 0.0655s\n",
      "[PT] Epoch 850:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0782 (0.0788)  orig_norm: 0.6274 (0.6379)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 850:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 850\n",
      "[PT] Epoch 851:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0756 (0.0756)  orig_norm: 0.4123 (0.4123)  iter: 0.2620s  data: 0.0722s\n",
      "[PT] Epoch 851:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0813 (0.0803)  orig_norm: 0.7033 (0.6971)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 851:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 851\n",
      "[PT] Epoch 852:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0723 (0.0723)  orig_norm: 0.7909 (0.7909)  iter: 0.2648s  data: 0.0686s\n",
      "[PT] Epoch 852:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0745 (0.0775)  orig_norm: 0.5638 (0.6589)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 852:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 852\n",
      "[PT] Epoch 853:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0816 (0.0816)  orig_norm: 0.5478 (0.5478)  iter: 0.2454s  data: 0.0552s\n",
      "[PT] Epoch 853:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0797 (0.0785)  orig_norm: 0.5848 (0.6667)  iter: 0.1845s  data: 0.0002s\n",
      "[PT] Epoch 853:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 853\n",
      "[PT] Epoch 854:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0628 (0.0628)  orig_norm: 0.8663 (0.8663)  iter: 0.2524s  data: 0.0599s\n",
      "[PT] Epoch 854:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0789 (0.0797)  orig_norm: 0.5978 (0.6749)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 854:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 854\n",
      "[PT] Epoch 855:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0916 (0.0916)  orig_norm: 0.8477 (0.8477)  iter: 0.2561s  data: 0.0612s\n",
      "[PT] Epoch 855:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0801 (0.0800)  orig_norm: 0.7387 (0.7122)  iter: 0.1821s  data: 0.0002s\n",
      "[PT] Epoch 855:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 855\n",
      "[PT] Epoch 856:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0802 (0.0802)  orig_norm: 0.4484 (0.4484)  iter: 0.2416s  data: 0.0494s\n",
      "[PT] Epoch 856:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0758 (0.0789)  orig_norm: 0.6663 (0.6785)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 856:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 856\n",
      "[PT] Epoch 857:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0907 (0.0907)  orig_norm: 0.5250 (0.5250)  iter: 0.2450s  data: 0.0527s\n",
      "[PT] Epoch 857:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0810)  orig_norm: 0.7065 (0.6951)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 857:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 857\n",
      "[PT] Epoch 858:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0789 (0.0789)  orig_norm: 0.5499 (0.5499)  iter: 0.2636s  data: 0.0658s\n",
      "[PT] Epoch 858:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0771 (0.0792)  orig_norm: 0.6193 (0.6890)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 858:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 858\n",
      "[PT] Epoch 859:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0804 (0.0804)  orig_norm: 0.7047 (0.7047)  iter: 0.2431s  data: 0.0505s\n",
      "[PT] Epoch 859:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0812 (0.0794)  orig_norm: 0.7186 (0.7464)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 859:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 859\n",
      "[PT] Epoch 860:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0710 (0.0710)  orig_norm: 0.5159 (0.5159)  iter: 0.2585s  data: 0.0634s\n",
      "[PT] Epoch 860:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0781 (0.0792)  orig_norm: 0.7008 (0.7510)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 860:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 860\n",
      "[PT] Epoch 861:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0777 (0.0777)  orig_norm: 0.4291 (0.4291)  iter: 0.2606s  data: 0.0629s\n",
      "[PT] Epoch 861:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0775 (0.0784)  orig_norm: 0.5612 (0.6442)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 861:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 861\n",
      "[PT] Epoch 862:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0720 (0.0720)  orig_norm: 0.4562 (0.4562)  iter: 0.2585s  data: 0.0653s\n",
      "[PT] Epoch 862:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0809)  orig_norm: 0.6071 (0.7408)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 862:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 862\n",
      "[PT] Epoch 863:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0742 (0.0742)  orig_norm: 0.8273 (0.8273)  iter: 0.2629s  data: 0.0675s\n",
      "[PT] Epoch 863:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0779 (0.0805)  orig_norm: 0.6196 (0.6614)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 863:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 863\n",
      "[PT] Epoch 864:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0773 (0.0773)  orig_norm: 0.7942 (0.7942)  iter: 0.2569s  data: 0.0604s\n",
      "[PT] Epoch 864:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0788 (0.0795)  orig_norm: 0.6593 (0.6705)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 864:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 864\n",
      "[PT] Epoch 865:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0801 (0.0801)  orig_norm: 0.6719 (0.6719)  iter: 0.2540s  data: 0.0589s\n",
      "[PT] Epoch 865:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0792)  orig_norm: 0.6996 (0.7051)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 865:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 865\n",
      "[PT] Epoch 866:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0710 (0.0710)  orig_norm: 0.6535 (0.6535)  iter: 0.2542s  data: 0.0597s\n",
      "[PT] Epoch 866:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0794 (0.0797)  orig_norm: 0.7073 (0.7062)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 866:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 866\n",
      "[PT] Epoch 867:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0741 (0.0741)  orig_norm: 1.1478 (1.1478)  iter: 0.2591s  data: 0.0643s\n",
      "[PT] Epoch 867:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0792)  orig_norm: 0.6420 (0.6570)  iter: 0.1808s  data: 0.0001s\n",
      "[PT] Epoch 867:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 867\n",
      "[PT] Epoch 868:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0861 (0.0861)  orig_norm: 0.8489 (0.8489)  iter: 0.2520s  data: 0.0593s\n",
      "[PT] Epoch 868:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0774 (0.0791)  orig_norm: 0.6878 (0.6902)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 868:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 868\n",
      "[PT] Epoch 869:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0695 (0.0695)  orig_norm: 0.6809 (0.6809)  iter: 0.2589s  data: 0.0668s\n",
      "[PT] Epoch 869:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0743 (0.0775)  orig_norm: 0.6802 (0.6862)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 869:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 869\n",
      "[PT] Epoch 870:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0746 (0.0746)  orig_norm: 0.6853 (0.6853)  iter: 0.2588s  data: 0.0656s\n",
      "[PT] Epoch 870:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0769 (0.0775)  orig_norm: 0.5998 (0.7445)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 870:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 870\n",
      "[PT] Epoch 871:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0647 (0.0647)  orig_norm: 0.9141 (0.9141)  iter: 0.2646s  data: 0.0711s\n",
      "[PT] Epoch 871:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0759 (0.0782)  orig_norm: 0.6149 (0.6884)  iter: 0.1837s  data: 0.0002s\n",
      "[PT] Epoch 871:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 871\n",
      "[PT] Epoch 872:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0745 (0.0745)  orig_norm: 0.4775 (0.4775)  iter: 0.2572s  data: 0.0625s\n",
      "[PT] Epoch 872:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0777 (0.0802)  orig_norm: 0.6709 (0.6786)  iter: 0.1827s  data: 0.0002s\n",
      "[PT] Epoch 872:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 872\n",
      "[PT] Epoch 873:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0662 (0.0662)  orig_norm: 0.4626 (0.4626)  iter: 0.2697s  data: 0.0740s\n",
      "[PT] Epoch 873:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0777 (0.0803)  orig_norm: 0.6629 (0.6937)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 873:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 873\n",
      "[PT] Epoch 874:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0908 (0.0908)  orig_norm: 0.7055 (0.7055)  iter: 0.2528s  data: 0.0580s\n",
      "[PT] Epoch 874:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0754 (0.0798)  orig_norm: 0.7233 (0.7229)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 874:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 874\n",
      "[PT] Epoch 875:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0862 (0.0862)  orig_norm: 0.5752 (0.5752)  iter: 0.2545s  data: 0.0595s\n",
      "[PT] Epoch 875:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0759 (0.0795)  orig_norm: 0.5621 (0.6639)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 875:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 875\n",
      "[PT] Epoch 876:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0761 (0.0761)  orig_norm: 0.5193 (0.5193)  iter: 0.2434s  data: 0.0491s\n",
      "[PT] Epoch 876:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0801 (0.0776)  orig_norm: 0.6956 (0.7360)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 876:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 876\n",
      "[PT] Epoch 877:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0743 (0.0743)  orig_norm: 0.8131 (0.8131)  iter: 0.2578s  data: 0.0629s\n",
      "[PT] Epoch 877:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0818 (0.0795)  orig_norm: 0.6765 (0.6659)  iter: 0.1846s  data: 0.0002s\n",
      "[PT] Epoch 877:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 877\n",
      "[PT] Epoch 878:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0643 (0.0643)  orig_norm: 0.5386 (0.5386)  iter: 0.2566s  data: 0.0650s\n",
      "[PT] Epoch 878:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0762 (0.0782)  orig_norm: 0.6716 (0.6714)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 878:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 878\n",
      "[PT] Epoch 879:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0707 (0.0707)  orig_norm: 0.6806 (0.6806)  iter: 0.2438s  data: 0.0523s\n",
      "[PT] Epoch 879:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0737 (0.0771)  orig_norm: 0.6172 (0.6524)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 879:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 879\n",
      "[PT] Epoch 880:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0814 (0.0814)  orig_norm: 0.6412 (0.6412)  iter: 0.2560s  data: 0.0605s\n",
      "[PT] Epoch 880:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0769 (0.0802)  orig_norm: 0.6810 (0.7130)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 880:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 880\n",
      "[PT] Epoch 881:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0810 (0.0810)  orig_norm: 0.8910 (0.8910)  iter: 0.2540s  data: 0.0589s\n",
      "[PT] Epoch 881:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0799 (0.0809)  orig_norm: 0.6358 (0.7088)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 881:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 881\n",
      "[PT] Epoch 882:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0769 (0.0769)  orig_norm: 0.8066 (0.8066)  iter: 0.2550s  data: 0.0593s\n",
      "[PT] Epoch 882:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0776 (0.0809)  orig_norm: 0.6374 (0.6603)  iter: 0.1836s  data: 0.0001s\n",
      "[PT] Epoch 882:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 882\n",
      "[PT] Epoch 883:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0791 (0.0791)  orig_norm: 0.5867 (0.5867)  iter: 0.2570s  data: 0.0614s\n",
      "[PT] Epoch 883:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0763 (0.0782)  orig_norm: 0.6748 (0.6583)  iter: 0.1837s  data: 0.0001s\n",
      "[PT] Epoch 883:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 883\n",
      "[PT] Epoch 884:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0886 (0.0886)  orig_norm: 0.9004 (0.9004)  iter: 0.2634s  data: 0.0661s\n",
      "[PT] Epoch 884:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0789 (0.0790)  orig_norm: 0.6814 (0.7180)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 884:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 884\n",
      "[PT] Epoch 885:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0753 (0.0753)  orig_norm: 0.5106 (0.5106)  iter: 0.2459s  data: 0.0526s\n",
      "[PT] Epoch 885:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0817 (0.0794)  orig_norm: 0.6424 (0.6827)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 885:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 885\n",
      "[PT] Epoch 886:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0678 (0.0678)  orig_norm: 0.4999 (0.4999)  iter: 0.2578s  data: 0.0629s\n",
      "[PT] Epoch 886:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0779 (0.0809)  orig_norm: 0.7131 (0.7116)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 886:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 886\n",
      "[PT] Epoch 887:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0896 (0.0896)  orig_norm: 0.8200 (0.8200)  iter: 0.2566s  data: 0.0650s\n",
      "[PT] Epoch 887:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0769 (0.0808)  orig_norm: 0.6687 (0.7349)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 887:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 887\n",
      "[PT] Epoch 888:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0692 (0.0692)  orig_norm: 0.4786 (0.4786)  iter: 0.2498s  data: 0.0552s\n",
      "[PT] Epoch 888:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0804 (0.0790)  orig_norm: 0.6664 (0.6632)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 888:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 888\n",
      "[PT] Epoch 889:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0945 (0.0945)  orig_norm: 0.7350 (0.7350)  iter: 0.2523s  data: 0.0564s\n",
      "[PT] Epoch 889:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0775 (0.0798)  orig_norm: 0.6228 (0.6611)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 889:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 889\n",
      "[PT] Epoch 890:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0744 (0.0744)  orig_norm: 0.5424 (0.5424)  iter: 0.2416s  data: 0.0499s\n",
      "[PT] Epoch 890:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0780 (0.0791)  orig_norm: 0.6323 (0.6632)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 890:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 890\n",
      "[PT] Epoch 891:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0882 (0.0882)  orig_norm: 0.5085 (0.5085)  iter: 0.2539s  data: 0.0590s\n",
      "[PT] Epoch 891:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0782 (0.0811)  orig_norm: 0.6305 (0.6750)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 891:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 891\n",
      "[PT] Epoch 892:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.1015 (0.1015)  orig_norm: 0.6337 (0.6337)  iter: 0.2565s  data: 0.0649s\n",
      "[PT] Epoch 892:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0759 (0.0811)  orig_norm: 0.6796 (0.7003)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 892:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 892\n",
      "[PT] Epoch 893:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0658 (0.0658)  orig_norm: 0.5773 (0.5773)  iter: 0.2549s  data: 0.0585s\n",
      "[PT] Epoch 893:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0798 (0.0794)  orig_norm: 0.7224 (0.7061)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 893:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 893\n",
      "[PT] Epoch 894:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0660 (0.0660)  orig_norm: 0.5330 (0.5330)  iter: 0.2539s  data: 0.0612s\n",
      "[PT] Epoch 894:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0747 (0.0774)  orig_norm: 0.6401 (0.7033)  iter: 0.1846s  data: 0.0001s\n",
      "[PT] Epoch 894:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 894\n",
      "[PT] Epoch 895:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0945 (0.0945)  orig_norm: 0.5914 (0.5914)  iter: 0.2670s  data: 0.0709s\n",
      "[PT] Epoch 895:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0780 (0.0802)  orig_norm: 0.7908 (0.7676)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 895:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 895\n",
      "[PT] Epoch 896:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0792 (0.0792)  orig_norm: 0.7167 (0.7167)  iter: 0.2561s  data: 0.0653s\n",
      "[PT] Epoch 896:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0769 (0.0782)  orig_norm: 0.6832 (0.6626)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 896:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 896\n",
      "[PT] Epoch 897:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0638 (0.0638)  orig_norm: 0.4653 (0.4653)  iter: 0.2574s  data: 0.0631s\n",
      "[PT] Epoch 897:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0832 (0.0794)  orig_norm: 0.6528 (0.7338)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 897:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 897\n",
      "[PT] Epoch 898:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0853 (0.0853)  orig_norm: 0.7614 (0.7614)  iter: 0.2499s  data: 0.0566s\n",
      "[PT] Epoch 898:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0751 (0.0782)  orig_norm: 0.6599 (0.7064)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 898:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 898\n",
      "[PT] Epoch 899:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0856 (0.0856)  orig_norm: 0.6519 (0.6519)  iter: 0.2606s  data: 0.0667s\n",
      "[PT] Epoch 899:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0798 (0.0774)  orig_norm: 0.6408 (0.6601)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 899:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 899\n",
      "[PT] Epoch 900:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0749 (0.0749)  orig_norm: 0.6776 (0.6776)  iter: 0.2443s  data: 0.0529s\n",
      "[PT] Epoch 900:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0743 (0.0778)  orig_norm: 0.6762 (0.7010)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 900:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 900\n",
      "[PT] Epoch 901:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0790 (0.0790)  orig_norm: 0.5838 (0.5838)  iter: 0.2470s  data: 0.0538s\n",
      "[PT] Epoch 901:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0727 (0.0772)  orig_norm: 0.6940 (0.6941)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 901:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 901\n",
      "[PT] Epoch 902:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0797 (0.0797)  orig_norm: 0.5732 (0.5732)  iter: 0.2511s  data: 0.0578s\n",
      "[PT] Epoch 902:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0835 (0.0801)  orig_norm: 0.6934 (0.6750)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 902:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 902\n",
      "[PT] Epoch 903:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0804 (0.0804)  orig_norm: 0.6739 (0.6739)  iter: 0.2620s  data: 0.0660s\n",
      "[PT] Epoch 903:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0819 (0.0807)  orig_norm: 0.6998 (0.6928)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 903:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 903\n",
      "[PT] Epoch 904:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0780 (0.0780)  orig_norm: 0.5599 (0.5599)  iter: 0.2545s  data: 0.0595s\n",
      "[PT] Epoch 904:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0802)  orig_norm: 0.6146 (0.7050)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 904:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 904\n",
      "[PT] Epoch 905:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0689 (0.0689)  orig_norm: 0.5188 (0.5188)  iter: 0.2579s  data: 0.0629s\n",
      "[PT] Epoch 905:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0749 (0.0780)  orig_norm: 0.6549 (0.6668)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 905:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 905\n",
      "[PT] Epoch 906:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0651 (0.0651)  orig_norm: 0.6140 (0.6140)  iter: 0.2617s  data: 0.0667s\n",
      "[PT] Epoch 906:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0804 (0.0788)  orig_norm: 0.5980 (0.6802)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 906:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 906\n",
      "[PT] Epoch 907:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0789 (0.0789)  orig_norm: 0.6733 (0.6733)  iter: 0.2517s  data: 0.0581s\n",
      "[PT] Epoch 907:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0755 (0.0785)  orig_norm: 0.7472 (0.7225)  iter: 0.1823s  data: 0.0002s\n",
      "[PT] Epoch 907:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 907\n",
      "[PT] Epoch 908:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0815 (0.0815)  orig_norm: 0.4905 (0.4905)  iter: 0.2453s  data: 0.0528s\n",
      "[PT] Epoch 908:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0815 (0.0812)  orig_norm: 0.6582 (0.6951)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 908:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 908\n",
      "[PT] Epoch 909:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0852 (0.0852)  orig_norm: 0.6419 (0.6419)  iter: 0.2528s  data: 0.0595s\n",
      "[PT] Epoch 909:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0739 (0.0781)  orig_norm: 0.6795 (0.6933)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 909:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 909\n",
      "[PT] Epoch 910:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0713 (0.0713)  orig_norm: 0.5813 (0.5813)  iter: 0.2628s  data: 0.0677s\n",
      "[PT] Epoch 910:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0731 (0.0770)  orig_norm: 0.7160 (0.7141)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 910:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 910\n",
      "[PT] Epoch 911:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0825 (0.0825)  orig_norm: 0.6092 (0.6092)  iter: 0.2591s  data: 0.0656s\n",
      "[PT] Epoch 911:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0792 (0.0792)  orig_norm: 0.6610 (0.7298)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 911:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 911\n",
      "[PT] Epoch 912:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0897 (0.0897)  orig_norm: 0.5367 (0.5367)  iter: 0.2535s  data: 0.0622s\n",
      "[PT] Epoch 912:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0737 (0.0782)  orig_norm: 0.7625 (0.7347)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 912:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 912\n",
      "[PT] Epoch 913:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0666 (0.0666)  orig_norm: 0.4750 (0.4750)  iter: 0.2535s  data: 0.0588s\n",
      "[PT] Epoch 913:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0758 (0.0788)  orig_norm: 0.6093 (0.6686)  iter: 0.1823s  data: 0.0002s\n",
      "[PT] Epoch 913:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 913\n",
      "[PT] Epoch 914:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0705 (0.0705)  orig_norm: 0.5933 (0.5933)  iter: 0.2620s  data: 0.0657s\n",
      "[PT] Epoch 914:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0778 (0.0780)  orig_norm: 0.6370 (0.6786)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 914:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 914\n",
      "[PT] Epoch 915:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0809 (0.0809)  orig_norm: 0.8964 (0.8964)  iter: 0.2649s  data: 0.0684s\n",
      "[PT] Epoch 915:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0770 (0.0776)  orig_norm: 0.6337 (0.6610)  iter: 0.1819s  data: 0.0001s\n",
      "[PT] Epoch 915:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 915\n",
      "[PT] Epoch 916:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0839 (0.0839)  orig_norm: 0.7177 (0.7177)  iter: 0.2582s  data: 0.0629s\n",
      "[PT] Epoch 916:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0822 (0.0797)  orig_norm: 0.7111 (0.6766)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 916:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 916\n",
      "[PT] Epoch 917:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0796 (0.0796)  orig_norm: 0.6572 (0.6572)  iter: 0.2550s  data: 0.0593s\n",
      "[PT] Epoch 917:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0754 (0.0774)  orig_norm: 0.7142 (0.7410)  iter: 0.1816s  data: 0.0001s\n",
      "[PT] Epoch 917:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 917\n",
      "[PT] Epoch 918:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0845 (0.0845)  orig_norm: 0.5994 (0.5994)  iter: 0.2486s  data: 0.0578s\n",
      "[PT] Epoch 918:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0817 (0.0793)  orig_norm: 0.6418 (0.7085)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 918:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 918\n",
      "[PT] Epoch 919:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0998 (0.0998)  orig_norm: 0.5365 (0.5365)  iter: 0.2519s  data: 0.0599s\n",
      "[PT] Epoch 919:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0800)  orig_norm: 0.6736 (0.6845)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 919:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 919\n",
      "[PT] Epoch 920:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0754 (0.0754)  orig_norm: 0.6541 (0.6541)  iter: 0.2675s  data: 0.0674s\n",
      "[PT] Epoch 920:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0770 (0.0789)  orig_norm: 0.6125 (0.6497)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 920:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 920\n",
      "[PT] Epoch 921:  [ 0/92]  eta: 0:00:25  max_lr: 0.00001  last_loss: 0.0683 (0.0683)  orig_norm: 0.5769 (0.5769)  iter: 0.2725s  data: 0.0817s\n",
      "[PT] Epoch 921:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0754 (0.0772)  orig_norm: 0.6477 (0.7017)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 921:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 921\n",
      "[PT] Epoch 922:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0789 (0.0789)  orig_norm: 0.5004 (0.5004)  iter: 0.2556s  data: 0.0586s\n",
      "[PT] Epoch 922:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0745 (0.0794)  orig_norm: 0.6935 (0.6867)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 922:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 922\n",
      "[PT] Epoch 923:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0815 (0.0815)  orig_norm: 0.7382 (0.7382)  iter: 0.2474s  data: 0.0543s\n",
      "[PT] Epoch 923:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0771 (0.0784)  orig_norm: 0.7019 (0.6873)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 923:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 923\n",
      "[PT] Epoch 924:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0755 (0.0755)  orig_norm: 0.6221 (0.6221)  iter: 0.2625s  data: 0.0668s\n",
      "[PT] Epoch 924:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0805 (0.0798)  orig_norm: 0.6295 (0.6952)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 924:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 924\n",
      "[PT] Epoch 925:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0914 (0.0914)  orig_norm: 0.8292 (0.8292)  iter: 0.2615s  data: 0.0668s\n",
      "[PT] Epoch 925:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0774 (0.0781)  orig_norm: 0.6373 (0.6885)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 925:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 925\n",
      "[PT] Epoch 926:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0603 (0.0603)  orig_norm: 0.3993 (0.3993)  iter: 0.2646s  data: 0.0675s\n",
      "[PT] Epoch 926:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0743 (0.0786)  orig_norm: 0.6963 (0.7023)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 926:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 926\n",
      "[PT] Epoch 927:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0666 (0.0666)  orig_norm: 0.5826 (0.5826)  iter: 0.2614s  data: 0.0657s\n",
      "[PT] Epoch 927:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0805 (0.0790)  orig_norm: 0.6840 (0.7316)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 927:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 927\n",
      "[PT] Epoch 928:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0808 (0.0808)  orig_norm: 0.5804 (0.5804)  iter: 0.2483s  data: 0.0527s\n",
      "[PT] Epoch 928:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0762 (0.0790)  orig_norm: 0.7181 (0.7054)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 928:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 928\n",
      "[PT] Epoch 929:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0762 (0.0762)  orig_norm: 0.6803 (0.6803)  iter: 0.2589s  data: 0.0649s\n",
      "[PT] Epoch 929:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0774 (0.0786)  orig_norm: 0.6869 (0.6328)  iter: 0.1859s  data: 0.0002s\n",
      "[PT] Epoch 929:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 929\n",
      "[PT] Epoch 930:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0757 (0.0757)  orig_norm: 0.6838 (0.6838)  iter: 0.2609s  data: 0.0644s\n",
      "[PT] Epoch 930:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0749 (0.0779)  orig_norm: 0.6820 (0.7078)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 930:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 930\n",
      "[PT] Epoch 931:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0896 (0.0896)  orig_norm: 0.5844 (0.5844)  iter: 0.2596s  data: 0.0639s\n",
      "[PT] Epoch 931:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0809 (0.0785)  orig_norm: 0.7528 (0.6877)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 931:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 931\n",
      "[PT] Epoch 932:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0809 (0.0809)  orig_norm: 0.6269 (0.6269)  iter: 0.2547s  data: 0.0587s\n",
      "[PT] Epoch 932:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0749 (0.0793)  orig_norm: 0.6106 (0.6781)  iter: 0.1835s  data: 0.0002s\n",
      "[PT] Epoch 932:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 932\n",
      "[PT] Epoch 933:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0633 (0.0633)  orig_norm: 0.6785 (0.6785)  iter: 0.2551s  data: 0.0582s\n",
      "[PT] Epoch 933:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0792)  orig_norm: 0.6437 (0.7034)  iter: 0.1842s  data: 0.0001s\n",
      "[PT] Epoch 933:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 933\n",
      "[PT] Epoch 934:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0727 (0.0727)  orig_norm: 0.7703 (0.7703)  iter: 0.2451s  data: 0.0527s\n",
      "[PT] Epoch 934:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0791 (0.0793)  orig_norm: 0.6417 (0.7318)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 934:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 934\n",
      "[PT] Epoch 935:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0632 (0.0632)  orig_norm: 0.6027 (0.6027)  iter: 0.2585s  data: 0.0637s\n",
      "[PT] Epoch 935:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0755 (0.0770)  orig_norm: 0.6795 (0.6643)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 935:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 935\n",
      "[PT] Epoch 936:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0760 (0.0760)  orig_norm: 0.8119 (0.8119)  iter: 0.2421s  data: 0.0511s\n",
      "[PT] Epoch 936:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0818 (0.0824)  orig_norm: 0.6306 (0.7119)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 936:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 936\n",
      "[PT] Epoch 937:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0767 (0.0767)  orig_norm: 0.8777 (0.8777)  iter: 0.2601s  data: 0.0645s\n",
      "[PT] Epoch 937:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0743 (0.0770)  orig_norm: 0.6878 (0.6685)  iter: 0.1836s  data: 0.0002s\n",
      "[PT] Epoch 937:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 937\n",
      "[PT] Epoch 938:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0744 (0.0744)  orig_norm: 0.7871 (0.7871)  iter: 0.2559s  data: 0.0585s\n",
      "[PT] Epoch 938:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0787 (0.0784)  orig_norm: 0.7008 (0.7014)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 938:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 938\n",
      "[PT] Epoch 939:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0698 (0.0698)  orig_norm: 0.7569 (0.7569)  iter: 0.2485s  data: 0.0550s\n",
      "[PT] Epoch 939:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0808 (0.0802)  orig_norm: 0.5942 (0.6527)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 939:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 939\n",
      "[PT] Epoch 940:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0778 (0.0778)  orig_norm: 0.5401 (0.5401)  iter: 0.2693s  data: 0.0755s\n",
      "[PT] Epoch 940:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0760 (0.0786)  orig_norm: 0.6224 (0.6533)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 940:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 940\n",
      "[PT] Epoch 941:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0624 (0.0624)  orig_norm: 0.7003 (0.7003)  iter: 0.2530s  data: 0.0585s\n",
      "[PT] Epoch 941:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0793 (0.0798)  orig_norm: 0.6227 (0.6389)  iter: 0.1818s  data: 0.0001s\n",
      "[PT] Epoch 941:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 941\n",
      "[PT] Epoch 942:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0675 (0.0675)  orig_norm: 0.7721 (0.7721)  iter: 0.2593s  data: 0.0598s\n",
      "[PT] Epoch 942:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0826 (0.0796)  orig_norm: 0.6105 (0.6693)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 942:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 942\n",
      "[PT] Epoch 943:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0775 (0.0775)  orig_norm: 1.2904 (1.2904)  iter: 0.2557s  data: 0.0599s\n",
      "[PT] Epoch 943:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0767 (0.0790)  orig_norm: 0.6755 (0.7176)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 943:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 943\n",
      "[PT] Epoch 944:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0869 (0.0869)  orig_norm: 0.6984 (0.6984)  iter: 0.2606s  data: 0.0636s\n",
      "[PT] Epoch 944:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0748 (0.0778)  orig_norm: 0.6505 (0.6712)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 944:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 944\n",
      "[PT] Epoch 945:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0611 (0.0611)  orig_norm: 0.8418 (0.8418)  iter: 0.2571s  data: 0.0607s\n",
      "[PT] Epoch 945:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0773 (0.0779)  orig_norm: 0.6532 (0.7049)  iter: 0.1821s  data: 0.0001s\n",
      "[PT] Epoch 945:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 945\n",
      "[PT] Epoch 946:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0680 (0.0680)  orig_norm: 0.5401 (0.5401)  iter: 0.2577s  data: 0.0641s\n",
      "[PT] Epoch 946:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0737 (0.0785)  orig_norm: 0.5454 (0.6445)  iter: 0.1825s  data: 0.0001s\n",
      "[PT] Epoch 946:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 946\n",
      "[PT] Epoch 947:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0755 (0.0755)  orig_norm: 0.7305 (0.7305)  iter: 0.2574s  data: 0.0604s\n",
      "[PT] Epoch 947:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0790 (0.0795)  orig_norm: 0.5794 (0.6895)  iter: 0.1824s  data: 0.0001s\n",
      "[PT] Epoch 947:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 947\n",
      "[PT] Epoch 948:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0630 (0.0630)  orig_norm: 0.4596 (0.4596)  iter: 0.2623s  data: 0.0664s\n",
      "[PT] Epoch 948:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0749 (0.0780)  orig_norm: 0.6753 (0.7232)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 948:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 948\n",
      "[PT] Epoch 949:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0728 (0.0728)  orig_norm: 0.5911 (0.5911)  iter: 0.2537s  data: 0.0611s\n",
      "[PT] Epoch 949:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0745 (0.0805)  orig_norm: 0.6554 (0.7271)  iter: 0.1834s  data: 0.0001s\n",
      "[PT] Epoch 949:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 949\n",
      "[PT] Epoch 950:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0834 (0.0834)  orig_norm: 0.8149 (0.8149)  iter: 0.2484s  data: 0.0539s\n",
      "[PT] Epoch 950:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0762 (0.0803)  orig_norm: 0.6125 (0.7094)  iter: 0.1833s  data: 0.0002s\n",
      "[PT] Epoch 950:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 950\n",
      "[PT] Epoch 951:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0900 (0.0900)  orig_norm: 0.6683 (0.6683)  iter: 0.2530s  data: 0.0595s\n",
      "[PT] Epoch 951:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0771 (0.0782)  orig_norm: 0.7292 (0.7241)  iter: 0.1846s  data: 0.0002s\n",
      "[PT] Epoch 951:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 951\n",
      "[PT] Epoch 952:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0921 (0.0921)  orig_norm: 1.3156 (1.3156)  iter: 0.2462s  data: 0.0542s\n",
      "[PT] Epoch 952:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0806 (0.0804)  orig_norm: 0.6774 (0.7410)  iter: 0.1829s  data: 0.0001s\n",
      "[PT] Epoch 952:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 952\n",
      "[PT] Epoch 953:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0799 (0.0799)  orig_norm: 0.6166 (0.6166)  iter: 0.2575s  data: 0.0596s\n",
      "[PT] Epoch 953:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0772 (0.0784)  orig_norm: 0.6110 (0.7118)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 953:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 953\n",
      "[PT] Epoch 954:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0760 (0.0760)  orig_norm: 0.9652 (0.9652)  iter: 0.2593s  data: 0.0641s\n",
      "[PT] Epoch 954:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0742 (0.0774)  orig_norm: 0.6519 (0.7134)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 954:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 954\n",
      "[PT] Epoch 955:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0749 (0.0749)  orig_norm: 0.4979 (0.4979)  iter: 0.2514s  data: 0.0558s\n",
      "[PT] Epoch 955:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0777 (0.0789)  orig_norm: 0.6442 (0.6652)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 955:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 955\n",
      "[PT] Epoch 956:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0638 (0.0638)  orig_norm: 0.5176 (0.5176)  iter: 0.2607s  data: 0.0646s\n",
      "[PT] Epoch 956:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0796 (0.0788)  orig_norm: 0.6456 (0.6736)  iter: 0.1820s  data: 0.0002s\n",
      "[PT] Epoch 956:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 956\n",
      "[PT] Epoch 957:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0902 (0.0902)  orig_norm: 0.7397 (0.7397)  iter: 0.2608s  data: 0.0654s\n",
      "[PT] Epoch 957:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0751 (0.0782)  orig_norm: 0.6270 (0.6819)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 957:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 957\n",
      "[PT] Epoch 958:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0819 (0.0819)  orig_norm: 0.6131 (0.6131)  iter: 0.2537s  data: 0.0588s\n",
      "[PT] Epoch 958:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0772 (0.0775)  orig_norm: 0.6562 (0.6470)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 958:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 958\n",
      "[PT] Epoch 959:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0740 (0.0740)  orig_norm: 0.6695 (0.6695)  iter: 0.2520s  data: 0.0592s\n",
      "[PT] Epoch 959:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0777 (0.0777)  orig_norm: 0.6203 (0.7083)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 959:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 959\n",
      "[PT] Epoch 960:  [ 0/92]  eta: 0:00:25  max_lr: 0.00001  last_loss: 0.0667 (0.0667)  orig_norm: 0.5667 (0.5667)  iter: 0.2767s  data: 0.0800s\n",
      "[PT] Epoch 960:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0804 (0.0802)  orig_norm: 0.6548 (0.7151)  iter: 0.1839s  data: 0.0002s\n",
      "[PT] Epoch 960:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 960\n",
      "[PT] Epoch 961:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0692 (0.0692)  orig_norm: 0.8627 (0.8627)  iter: 0.2599s  data: 0.0614s\n",
      "[PT] Epoch 961:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0749 (0.0777)  orig_norm: 0.7125 (0.7025)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 961:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 961\n",
      "[PT] Epoch 962:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0680 (0.0680)  orig_norm: 0.5043 (0.5043)  iter: 0.2628s  data: 0.0676s\n",
      "[PT] Epoch 962:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0791 (0.0774)  orig_norm: 0.6496 (0.7006)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 962:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 962\n",
      "[PT] Epoch 963:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0926 (0.0926)  orig_norm: 0.7159 (0.7159)  iter: 0.2593s  data: 0.0639s\n",
      "[PT] Epoch 963:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0783 (0.0773)  orig_norm: 0.7387 (0.7359)  iter: 0.1833s  data: 0.0001s\n",
      "[PT] Epoch 963:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 963\n",
      "[PT] Epoch 964:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0662 (0.0662)  orig_norm: 0.5779 (0.5779)  iter: 0.2591s  data: 0.0635s\n",
      "[PT] Epoch 964:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0796 (0.0790)  orig_norm: 0.6469 (0.6578)  iter: 0.1838s  data: 0.0002s\n",
      "[PT] Epoch 964:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 964\n",
      "[PT] Epoch 965:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0803 (0.0803)  orig_norm: 0.6413 (0.6413)  iter: 0.2602s  data: 0.0632s\n",
      "[PT] Epoch 965:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0753 (0.0779)  orig_norm: 0.6144 (0.6535)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 965:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 965\n",
      "[PT] Epoch 966:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0866 (0.0866)  orig_norm: 0.5304 (0.5304)  iter: 0.2563s  data: 0.0611s\n",
      "[PT] Epoch 966:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0786 (0.0788)  orig_norm: 0.6812 (0.6917)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 966:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 966\n",
      "[PT] Epoch 967:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0732 (0.0732)  orig_norm: 0.8856 (0.8856)  iter: 0.2580s  data: 0.0613s\n",
      "[PT] Epoch 967:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0742 (0.0764)  orig_norm: 0.7046 (0.6880)  iter: 0.1831s  data: 0.0001s\n",
      "[PT] Epoch 967:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 967\n",
      "[PT] Epoch 968:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0754 (0.0754)  orig_norm: 0.5611 (0.5611)  iter: 0.2550s  data: 0.0606s\n",
      "[PT] Epoch 968:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0754 (0.0778)  orig_norm: 0.6634 (0.7062)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 968:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 968\n",
      "[PT] Epoch 969:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0745 (0.0745)  orig_norm: 0.8105 (0.8105)  iter: 0.2602s  data: 0.0652s\n",
      "[PT] Epoch 969:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0740 (0.0773)  orig_norm: 0.5866 (0.7255)  iter: 0.1834s  data: 0.0002s\n",
      "[PT] Epoch 969:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 969\n",
      "[PT] Epoch 970:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0650 (0.0650)  orig_norm: 0.7256 (0.7256)  iter: 0.2617s  data: 0.0652s\n",
      "[PT] Epoch 970:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0765 (0.0791)  orig_norm: 0.6606 (0.7599)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 970:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 970\n",
      "[PT] Epoch 971:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0852 (0.0852)  orig_norm: 0.7191 (0.7191)  iter: 0.2588s  data: 0.0644s\n",
      "[PT] Epoch 971:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0808 (0.0790)  orig_norm: 0.7588 (0.7279)  iter: 0.1835s  data: 0.0001s\n",
      "[PT] Epoch 971:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 971\n",
      "[PT] Epoch 972:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0778 (0.0778)  orig_norm: 0.7335 (0.7335)  iter: 0.2588s  data: 0.0643s\n",
      "[PT] Epoch 972:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0774 (0.0794)  orig_norm: 0.6353 (0.6840)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 972:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 972\n",
      "[PT] Epoch 973:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0750 (0.0750)  orig_norm: 0.5401 (0.5401)  iter: 0.2516s  data: 0.0570s\n",
      "[PT] Epoch 973:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0744 (0.0775)  orig_norm: 0.6840 (0.6850)  iter: 0.1828s  data: 0.0001s\n",
      "[PT] Epoch 973:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 973\n",
      "[PT] Epoch 974:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0801 (0.0801)  orig_norm: 0.8386 (0.8386)  iter: 0.2505s  data: 0.0576s\n",
      "[PT] Epoch 974:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0808 (0.0790)  orig_norm: 0.6786 (0.6945)  iter: 0.1822s  data: 0.0001s\n",
      "[PT] Epoch 974:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 974\n",
      "[PT] Epoch 975:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0697 (0.0697)  orig_norm: 0.7815 (0.7815)  iter: 0.2654s  data: 0.0715s\n",
      "[PT] Epoch 975:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0796 (0.0772)  orig_norm: 0.6202 (0.6547)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 975:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 975\n",
      "[PT] Epoch 976:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0771 (0.0771)  orig_norm: 0.6848 (0.6848)  iter: 0.2527s  data: 0.0588s\n",
      "[PT] Epoch 976:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0772 (0.0797)  orig_norm: 0.6882 (0.6765)  iter: 0.1814s  data: 0.0001s\n",
      "[PT] Epoch 976:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 976\n",
      "[PT] Epoch 977:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0760 (0.0760)  orig_norm: 0.5890 (0.5890)  iter: 0.2576s  data: 0.0640s\n",
      "[PT] Epoch 977:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0778 (0.0774)  orig_norm: 0.6696 (0.6743)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 977:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 977\n",
      "[PT] Epoch 978:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0783 (0.0783)  orig_norm: 0.7057 (0.7057)  iter: 0.2560s  data: 0.0646s\n",
      "[PT] Epoch 978:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0750 (0.0776)  orig_norm: 0.5998 (0.6912)  iter: 0.1826s  data: 0.0001s\n",
      "[PT] Epoch 978:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 978\n",
      "[PT] Epoch 979:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0789 (0.0789)  orig_norm: 0.5303 (0.5303)  iter: 0.2393s  data: 0.0460s\n",
      "[PT] Epoch 979:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0788 (0.0792)  orig_norm: 0.6419 (0.6620)  iter: 0.1832s  data: 0.0001s\n",
      "[PT] Epoch 979:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 979\n",
      "[PT] Epoch 980:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0747 (0.0747)  orig_norm: 0.7753 (0.7753)  iter: 0.2566s  data: 0.0640s\n",
      "[PT] Epoch 980:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0755 (0.0780)  orig_norm: 0.5305 (0.6360)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 980:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 980\n",
      "[PT] Epoch 981:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0732 (0.0732)  orig_norm: 0.5980 (0.5980)  iter: 0.2594s  data: 0.0650s\n",
      "[PT] Epoch 981:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0785 (0.0788)  orig_norm: 0.5387 (0.6746)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 981:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 981\n",
      "[PT] Epoch 982:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0614 (0.0614)  orig_norm: 0.3994 (0.3994)  iter: 0.2578s  data: 0.0621s\n",
      "[PT] Epoch 982:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0784 (0.0791)  orig_norm: 0.6235 (0.6552)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 982:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 982\n",
      "[PT] Epoch 983:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0866 (0.0866)  orig_norm: 0.8261 (0.8261)  iter: 0.2475s  data: 0.0538s\n",
      "[PT] Epoch 983:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0771 (0.0788)  orig_norm: 0.6628 (0.7069)  iter: 0.1811s  data: 0.0001s\n",
      "[PT] Epoch 983:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 983\n",
      "[PT] Epoch 984:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0927 (0.0927)  orig_norm: 0.4981 (0.4981)  iter: 0.2527s  data: 0.0574s\n",
      "[PT] Epoch 984:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0780 (0.0781)  orig_norm: 0.6323 (0.7023)  iter: 0.1826s  data: 0.0002s\n",
      "[PT] Epoch 984:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 984\n",
      "[PT] Epoch 985:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0798 (0.0798)  orig_norm: 0.5524 (0.5524)  iter: 0.2574s  data: 0.0610s\n",
      "[PT] Epoch 985:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0780 (0.0783)  orig_norm: 0.5992 (0.6818)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 985:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 985\n",
      "[PT] Epoch 986:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0731 (0.0731)  orig_norm: 0.7638 (0.7638)  iter: 0.2700s  data: 0.0780s\n",
      "[PT] Epoch 986:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0779 (0.0775)  orig_norm: 0.7374 (0.7179)  iter: 0.1830s  data: 0.0002s\n",
      "[PT] Epoch 986:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 986\n",
      "[PT] Epoch 987:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0720 (0.0720)  orig_norm: 0.6841 (0.6841)  iter: 0.2595s  data: 0.0641s\n",
      "[PT] Epoch 987:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0733 (0.0774)  orig_norm: 0.5761 (0.6482)  iter: 0.1822s  data: 0.0002s\n",
      "[PT] Epoch 987:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 987\n",
      "[PT] Epoch 988:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0697 (0.0697)  orig_norm: 0.5532 (0.5532)  iter: 0.2569s  data: 0.0626s\n",
      "[PT] Epoch 988:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0756 (0.0782)  orig_norm: 0.5842 (0.7153)  iter: 0.1823s  data: 0.0001s\n",
      "[PT] Epoch 988:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 988\n",
      "[PT] Epoch 989:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0874 (0.0874)  orig_norm: 0.6092 (0.6092)  iter: 0.2586s  data: 0.0598s\n",
      "[PT] Epoch 989:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0791 (0.0792)  orig_norm: 0.6221 (0.7174)  iter: 0.1817s  data: 0.0001s\n",
      "[PT] Epoch 989:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 989\n",
      "[PT] Epoch 990:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0795 (0.0795)  orig_norm: 0.5274 (0.5274)  iter: 0.2567s  data: 0.0612s\n",
      "[PT] Epoch 990:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0741 (0.0754)  orig_norm: 0.5870 (0.6748)  iter: 0.1827s  data: 0.0001s\n",
      "[PT] Epoch 990:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 990\n",
      "[PT] Epoch 991:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0807 (0.0807)  orig_norm: 0.5500 (0.5500)  iter: 0.2555s  data: 0.0626s\n",
      "[PT] Epoch 991:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0780 (0.0798)  orig_norm: 0.6478 (0.6684)  iter: 0.1830s  data: 0.0001s\n",
      "[PT] Epoch 991:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 991\n",
      "[PT] Epoch 992:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0798 (0.0798)  orig_norm: 0.6532 (0.6532)  iter: 0.2656s  data: 0.0666s\n",
      "[PT] Epoch 992:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0747 (0.0775)  orig_norm: 0.5447 (0.6581)  iter: 0.1845s  data: 0.0001s\n",
      "[PT] Epoch 992:   Total time:      0:00:08   (0.095 s / it)\n",
      "Finished training epoch 992\n",
      "[PT] Epoch 993:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0774 (0.0774)  orig_norm: 0.5165 (0.5165)  iter: 0.2696s  data: 0.0701s\n",
      "[PT] Epoch 993:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0792 (0.0779)  orig_norm: 0.6458 (0.6753)  iter: 0.1824s  data: 0.0002s\n",
      "[PT] Epoch 993:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 993\n",
      "[PT] Epoch 994:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0799 (0.0799)  orig_norm: 1.3414 (1.3414)  iter: 0.2586s  data: 0.0596s\n",
      "[PT] Epoch 994:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0747 (0.0765)  orig_norm: 0.5934 (0.6671)  iter: 0.1832s  data: 0.0002s\n",
      "[PT] Epoch 994:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 994\n",
      "[PT] Epoch 995:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0637 (0.0637)  orig_norm: 0.4686 (0.4686)  iter: 0.2578s  data: 0.0662s\n",
      "[PT] Epoch 995:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0769 (0.0771)  orig_norm: 0.7232 (0.7488)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 995:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 995\n",
      "[PT] Epoch 996:  [ 0/92]  eta: 0:00:23  max_lr: 0.00001  last_loss: 0.0823 (0.0823)  orig_norm: 0.7006 (0.7006)  iter: 0.2606s  data: 0.0655s\n",
      "[PT] Epoch 996:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0799 (0.0781)  orig_norm: 0.5976 (0.6461)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 996:   Total time:      0:00:08   (0.094 s / it)\n",
      "Finished training epoch 996\n",
      "[PT] Epoch 997:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0927 (0.0927)  orig_norm: 1.0287 (1.0287)  iter: 0.2412s  data: 0.0506s\n",
      "[PT] Epoch 997:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0777 (0.0784)  orig_norm: 0.6301 (0.7274)  iter: 0.1820s  data: 0.0001s\n",
      "[PT] Epoch 997:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 997\n",
      "[PT] Epoch 998:  [ 0/92]  eta: 0:00:22  max_lr: 0.00001  last_loss: 0.0731 (0.0731)  orig_norm: 0.7274 (0.7274)  iter: 0.2423s  data: 0.0471s\n",
      "[PT] Epoch 998:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0784 (0.0777)  orig_norm: 0.7410 (0.7010)  iter: 0.1813s  data: 0.0001s\n",
      "[PT] Epoch 998:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 998\n",
      "[PT] Epoch 999:  [ 0/92]  eta: 0:00:24  max_lr: 0.00001  last_loss: 0.0976 (0.0976)  orig_norm: 0.9199 (0.9199)  iter: 0.2613s  data: 0.0677s\n",
      "[PT] Epoch 999:  [45/92]  eta: 0:00:08  max_lr: 0.00001  last_loss: 0.0768 (0.0781)  orig_norm: 0.6329 (0.7212)  iter: 0.1815s  data: 0.0001s\n",
      "[PT] Epoch 999:   Total time:      0:00:08   (0.093 s / it)\n",
      "Finished training epoch 999\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "pre_train_save_dir = '/home/chong.tian/hc701/checkpoint_pre_train/still_pre_train'\n",
    "fine_tune_save_dir = '/home/chong.tian/hc701/checkpoint_pre_train/for_fine_tune'\n",
    "\n",
    "stats = pre_train_epochs(1000, tb_lg, itrt_train, iters_train, model=model_without_ddp, optimizer=optimizer, device=device)\n",
    "\n",
    "torch.save(model_without_ddp.state_dict(with_config=True), os.path.join(pre_train_save_dir, f'pre_train_model_{datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}.pth'))\n",
    "torch.save(model_without_ddp.sparse_encoder.sp_cnn.state_dict(), os.path.join(fine_tune_save_dir, f'fine_tune_model_{datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import copy\n",
    "\n",
    "res50 = timm.create_model('resnet50', pretrained=True,num_classes=5)\n",
    "\n",
    "model = copy.deepcopy(res50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.load('/home/chong.tian/hc701/checkpoint_fine_tune/centerlized_resnet50_42/20230324_113426/centerlized_resnet50_72_20230324_113426.pth')\n",
    "b = torch.load('/home/chong.tian/hc701/checkpoint_pre_train/for_fine_tune/fine_tune_model_2023-03-24-08-42-37.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0783, device='cuda:3') \n",
      " tensor(0.0045, device='cuda:0') \n",
      " tensor(0.2878)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "count = 0\n",
    "for p1,p2,p3 in zip(a.values(), b.values(),c.values()):\n",
    "    count += 1\n",
    "    if count == 9:\n",
    "        print(p1.mean(),'\\n',p2.mean(),'\\n',p3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 512, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([])\n",
      "torch.Size([2048, 1024, 1, 1])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([])\n",
      "torch.Size([5, 2048])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for p1 in b.values():\n",
    "    print(p1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.485, 0.456, 0.406)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGENET_DEFAULT_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "from typing import List\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import dist\n",
    "import encoder\n",
    "from decoder import LightDecoder\n",
    "from models import build_sparse_encoder\n",
    "from sampler import DistInfiniteBatchSampler, worker_init_fn\n",
    "from spark import SparK\n",
    "from utils import arg_util, misc, lamb\n",
    "from utils.imagenet import build_imagenet_pretrain\n",
    "from utils.lr_control import lr_wd_annealing, get_param_groups\n",
    "\n",
    "seed = 42\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/chong.tian/hc701/HC701-PROJECT')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from hc701fed.dataset.EyePACS_and_APTOS import Eye_APTOS\n",
    "from hc701fed.dataset.messidor import MESSIDOR\n",
    "\n",
    "from hc701fed.transform.transforms import compose\n",
    "from hc701fed.dataset.messidor import MESSIDOR\n",
    "\n",
    "\n",
    "PATH_DATA = '/home/chong.tian/hc701'\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    interpolation = InterpolationMode.BICUBIC\n",
    "except:\n",
    "    import PIL\n",
    "    interpolation = PIL.Image.BICUBIC\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: Image.fromarray(x)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.67, 1.0), interpolation=interpolation),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3778, 0.2800, 0.2310], std=[0.2892, 0.1946, 0.2006]),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: Image.fromarray(x)),\n",
    "    transforms.Resize(224, interpolation=interpolation),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3778, 0.2800, 0.2310], std=[0.2892, 0.1946, 0.2006]),\n",
    "])\n",
    "\n",
    "Eye_APTOS_data_dir_options = {\n",
    "    'EyePACS': os.path.join(PATH_DATA, 'preprocessed/eyepacs'),\n",
    "    'APTOS': os.path.join(PATH_DATA, 'preprocessed/aptos'),\n",
    "}\n",
    "\n",
    "MESSIDOR_data_dir_options = {\n",
    "    'messidor2': os.path.join(PATH_DATA, 'preprocessed/messidor2'),\n",
    "    'messidor_pairs' : os.path.join(PATH_DATA, 'preprocessed/messidor/messidor_pairs'),\n",
    "    'messidor_Etienne' : os.path.join(PATH_DATA, 'preprocessed/messidor/messidor_Etienne'),\n",
    "    'messidor_Brest-without_dilation' : os.path.join(PATH_DATA, 'preprocessed/messidor/messidor_Brest-without_dilation')\n",
    "}\n",
    "\n",
    "APTOS_train = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['APTOS'], mode='train', transform_=train_transforms)\n",
    "EyePACS_train = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['EyePACS'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_2_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor2'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_pairs_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_Etienne_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], mode='train', transform_=train_transforms)\n",
    "MESSIDOR_Brest_train = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], mode='train', transform_=train_transforms)\n",
    "\n",
    "APTOS_Val = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['APTOS'], mode='val', transform_=train_transforms)\n",
    "EyePACS_Val = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['EyePACS'], mode='val', transform_=train_transforms)\n",
    "MESSIDOR_2_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor2'], mode='val', transform_=train_transforms)\n",
    "MESSIDOR_pairs_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], mode='val', transform_=train_transforms)\n",
    "MESSIDOR_Etienne_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], mode='val', transform_=train_transforms)\n",
    "MESSIDOR_Brest_Val = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], mode='val', transform_=train_transforms)\n",
    "\n",
    "APTOS_test = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['APTOS'], mode='test', transform_=train_transforms)\n",
    "EyePACS_test = Eye_APTOS(data_dir=Eye_APTOS_data_dir_options['EyePACS'], mode='test', transform_=train_transforms)\n",
    "MESSIDOR_2_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor2'], mode='test', transform_=train_transforms)\n",
    "MESSIDOR_pairs_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_pairs'], mode='test', transform_=train_transforms)\n",
    "MESSIDOR_Etienne_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Etienne'], mode='test', transform_=train_transforms)\n",
    "MESSIDOR_Brest_test = MESSIDOR(data_dir=MESSIDOR_data_dir_options['messidor_Brest-without_dilation'], mode='test', transform_=train_transforms)\n",
    "\n",
    "# use all data as training data\n",
    "train_datasets = ConcatDataset([APTOS_train, EyePACS_train, MESSIDOR_2_train, MESSIDOR_pairs_train, MESSIDOR_Etienne_train, MESSIDOR_Brest_train])\n",
    "\n",
    "val_datasets = ConcatDataset([APTOS_Val, EyePACS_Val, MESSIDOR_2_Val, MESSIDOR_pairs_Val, MESSIDOR_Etienne_Val, MESSIDOR_Brest_Val])\n",
    "\n",
    "test_datasets = ConcatDataset([APTOS_test, EyePACS_test, MESSIDOR_2_test, MESSIDOR_pairs_test, MESSIDOR_Etienne_test, MESSIDOR_Brest_test])\n",
    "\n",
    "all_datasets = ConcatDataset([train_datasets, val_datasets, test_datasets])\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "data_loader_train = DataLoader(dataset=train_datasets, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "data_loader_val = DataLoader(dataset=val_datasets, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "data_loader_test = DataLoader(dataset=test_datasets, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "itrt_train, iters_train = iter(data_loader_train), len(data_loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loader = DataLoader(dataset=all_datasets, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
